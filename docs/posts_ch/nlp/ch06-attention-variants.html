<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ying Zha">
<meta name="dcterms.date" content="2026-01-25">
<meta name="description" content="æ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´ï¼šä»åŠ æ€§åˆ°ä¹˜æ€§ã€ä»å…¨å±€åˆ°å±€éƒ¨ã€ä»è½¯åˆ°ç¡¬ï¼ŒLuongçš„ç³»ç»Ÿæ€§æ¢ç´¢ä¸æ•ˆç‡-è¡¨è¾¾åŠ›æƒè¡¡ã€‚">

<title>ç¬¬6ç« ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“æ¼”è¿› â€“ Tech Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-1b3db88def35042d172274863c1cdcf0.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-6ee47bd5d569ce80d002539aadcc850f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Force refresh if cache is stale -->

<script>

(function() {

  var SITE_VERSION = '2025-11-14-v2'; // Update this to force all users to refresh

  var stored = localStorage.getItem('site_version');

  if (stored !== SITE_VERSION) {

    localStorage.setItem('site_version', SITE_VERSION);

    if (stored !== null) {

      // Not first visit, force reload from server

      window.location.reload(true);

    }

  }

})();

</script>

<script>

// Default to dark scheme on first visit (no prior preference stored)

try {

  var key = 'quarto-color-scheme';

  if (window && window.localStorage && window.localStorage.getItem(key) === null) {

    window.localStorage.setItem(key, 'alternate');

  }

} catch (e) {

  // ignore storage errors (privacy mode, etc.)

}

</script>

<!-- Aggressive cache prevention for HTML pages -->

<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate, max-age=0">

<meta http-equiv="Pragma" content="no-cache">

<meta http-equiv="Expires" content="0">

<meta name="revisit-after" content="1 days">

<meta name="robots" content="noarchive">




  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tech Notes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../home.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts_en.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tags.html"> 
<span class="menu-text">Tags</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ä»ä¸Šä¸€ç« è¯´èµ·" id="toc-ä»ä¸Šä¸€ç« è¯´èµ·" class="nav-link active" data-scroll-target="#ä»ä¸Šä¸€ç« è¯´èµ·"><span class="header-section-number">1</span> ä»ä¸Šä¸€ç« è¯´èµ·</a></li>
  <li><a href="#é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ" id="toc-é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ" class="nav-link" data-scroll-target="#é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ"><span class="header-section-number">2</span> é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ</a>
  <ul class="collapse">
  <li><a href="#é—®é¢˜çš„ç²¾ç¡®å®šä¹‰" id="toc-é—®é¢˜çš„ç²¾ç¡®å®šä¹‰" class="nav-link" data-scroll-target="#é—®é¢˜çš„ç²¾ç¡®å®šä¹‰"><span class="header-section-number">2.1</span> é—®é¢˜çš„ç²¾ç¡®å®šä¹‰</a></li>
  <li><a href="#æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ" id="toc-æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ" class="nav-link" data-scroll-target="#æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ"><span class="header-section-number">2.2</span> æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆï¼Ÿ</a></li>
  </ul></li>
  <li><a href="#æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰" id="toc-æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰" class="nav-link" data-scroll-target="#æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰"><span class="header-section-number">3</span> æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰</a>
  <ul class="collapse">
  <li><a href="#luong-attentionä¹˜æ€§æ›¿ä»£åŠ æ€§" id="toc-luong-attentionä¹˜æ€§æ›¿ä»£åŠ æ€§" class="nav-link" data-scroll-target="#luong-attentionä¹˜æ€§æ›¿ä»£åŠ æ€§"><span class="header-section-number">3.1</span> Luong Attentionï¼šä¹˜æ€§æ›¿ä»£åŠ æ€§</a></li>
  <li><a href="#ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”" id="toc-ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”" class="nav-link" data-scroll-target="#ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”"><span class="header-section-number">3.2</span> ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”</a></li>
  <li><a href="#å¦ä¸€ä¸ªå…³é”®å·®å¼‚æ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®" id="toc-å¦ä¸€ä¸ªå…³é”®å·®å¼‚æ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®" class="nav-link" data-scroll-target="#å¦ä¸€ä¸ªå…³é”®å·®å¼‚æ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®"><span class="header-section-number">3.3</span> å¦ä¸€ä¸ªå…³é”®å·®å¼‚ï¼šæ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®</a></li>
  </ul></li>
  <li><a href="#æŠ€æœ¯ç»†èŠ‚" id="toc-æŠ€æœ¯ç»†èŠ‚" class="nav-link" data-scroll-target="#æŠ€æœ¯ç»†èŠ‚"><span class="header-section-number">4</span> æŠ€æœ¯ç»†èŠ‚</a>
  <ul class="collapse">
  <li><a href="#luong-attentionçš„ä¸‰ç§å˜ä½“" id="toc-luong-attentionçš„ä¸‰ç§å˜ä½“" class="nav-link" data-scroll-target="#luong-attentionçš„ä¸‰ç§å˜ä½“"><span class="header-section-number">4.1</span> Luong Attentionçš„ä¸‰ç§å˜ä½“</a></li>
  <li><a href="#å®Œæ•´æ•°å€¼ç¤ºä¾‹å¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°" id="toc-å®Œæ•´æ•°å€¼ç¤ºä¾‹å¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°" class="nav-link" data-scroll-target="#å®Œæ•´æ•°å€¼ç¤ºä¾‹å¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°"><span class="header-section-number">4.2</span> å®Œæ•´æ•°å€¼ç¤ºä¾‹ï¼šå¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°</a></li>
  <li><a href="#global-vs-local-attention" id="toc-global-vs-local-attention" class="nav-link" data-scroll-target="#global-vs-local-attention"><span class="header-section-number">4.3</span> Global vs Local Attention</a></li>
  <li><a href="#hard-attention-vs-soft-attention" id="toc-hard-attention-vs-soft-attention" class="nav-link" data-scroll-target="#hard-attention-vs-soft-attention"><span class="header-section-number">4.4</span> Hard Attention vs Soft Attention</a></li>
  <li><a href="#å¤æ‚åº¦åˆ†æ" id="toc-å¤æ‚åº¦åˆ†æ" class="nav-link" data-scroll-target="#å¤æ‚åº¦åˆ†æ"><span class="header-section-number">4.5</span> å¤æ‚åº¦åˆ†æ</a></li>
  </ul></li>
  <li><a href="#å·¥ç¨‹å®è·µ" id="toc-å·¥ç¨‹å®è·µ" class="nav-link" data-scroll-target="#å·¥ç¨‹å®è·µ"><span class="header-section-number">5</span> å·¥ç¨‹å®è·µ</a>
  <ul class="collapse">
  <li><a href="#å®ç°luong-attention" id="toc-å®ç°luong-attention" class="nav-link" data-scroll-target="#å®ç°luong-attention"><span class="header-section-number">5.1</span> å®ç°Luong Attention</a></li>
  <li><a href="#å®ç°local-attention" id="toc-å®ç°local-attention" class="nav-link" data-scroll-target="#å®ç°local-attention"><span class="header-section-number">5.2</span> å®ç°Local Attention</a></li>
  <li><a href="#å¯¹æ¯”å®éªŒ" id="toc-å¯¹æ¯”å®éªŒ" class="nav-link" data-scroll-target="#å¯¹æ¯”å®éªŒ"><span class="header-section-number">5.3</span> å¯¹æ¯”å®éªŒ</a></li>
  </ul></li>
  <li><a href="#æ·±å…¥ç†è§£" id="toc-æ·±å…¥ç†è§£" class="nav-link" data-scroll-target="#æ·±å…¥ç†è§£"><span class="header-section-number">6</span> æ·±å…¥ç†è§£</a>
  <ul class="collapse">
  <li><a href="#ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œç†è®ºè§†è§’" id="toc-ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œç†è®ºè§†è§’" class="nav-link" data-scroll-target="#ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œç†è®ºè§†è§’"><span class="header-section-number">6.1</span> ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œï¼Ÿâ€”â€”ç†è®ºè§†è§’</a></li>
  <li><a href="#ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾scaled-dot-productçš„é¢„å…†" id="toc-ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾scaled-dot-productçš„é¢„å…†" class="nav-link" data-scroll-target="#ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾scaled-dot-productçš„é¢„å…†"><span class="header-section-number">6.2</span> ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾ï¼Ÿâ€”â€”Scaled Dot-Productçš„é¢„å…†</a></li>
  <li><a href="#æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶" id="toc-æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶" class="nav-link" data-scroll-target="#æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶"><span class="header-section-number">6.3</span> æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶</a></li>
  <li><a href="#å¼€æ”¾ç ”ç©¶é—®é¢˜" id="toc-å¼€æ”¾ç ”ç©¶é—®é¢˜" class="nav-link" data-scroll-target="#å¼€æ”¾ç ”ç©¶é—®é¢˜"><span class="header-section-number">6.4</span> å¼€æ”¾ç ”ç©¶é—®é¢˜</a></li>
  </ul></li>
  <li><a href="#å±€é™æ€§ä¸å±•æœ›" id="toc-å±€é™æ€§ä¸å±•æœ›" class="nav-link" data-scroll-target="#å±€é™æ€§ä¸å±•æœ›"><span class="header-section-number">7</span> å±€é™æ€§ä¸å±•æœ›</a>
  <ul class="collapse">
  <li><a href="#æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™" id="toc-æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™" class="nav-link" data-scroll-target="#æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™"><span class="header-section-number">7.1</span> æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™</a></li>
  <li><a href="#è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆ" id="toc-è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆ" class="nav-link" data-scroll-target="#è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆ"><span class="header-section-number">7.2</span> è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆï¼Ÿ</a></li>
  </ul></li>
  <li><a href="#æœ¬ç« å°ç»“" id="toc-æœ¬ç« å°ç»“" class="nav-link" data-scroll-target="#æœ¬ç« å°ç»“"><span class="header-section-number">8</span> æœ¬ç« å°ç»“</a>
  <ul class="collapse">
  <li><a href="#å…³é”®å…¬å¼é€ŸæŸ¥" id="toc-å…³é”®å…¬å¼é€ŸæŸ¥" class="nav-link" data-scroll-target="#å…³é”®å…¬å¼é€ŸæŸ¥"><span class="header-section-number">8.1</span> å…³é”®å…¬å¼é€ŸæŸ¥</a></li>
  </ul></li>
  <li><a href="#æ€è€ƒé¢˜" id="toc-æ€è€ƒé¢˜" class="nav-link" data-scroll-target="#æ€è€ƒé¢˜"><span class="header-section-number">9</span> æ€è€ƒé¢˜</a></li>
  <li><a href="#å»¶ä¼¸é˜…è¯»" id="toc-å»¶ä¼¸é˜…è¯»" class="nav-link" data-scroll-target="#å»¶ä¼¸é˜…è¯»"><span class="header-section-number">10</span> å»¶ä¼¸é˜…è¯»</a>
  <ul class="collapse">
  <li><a href="#æ ¸å¿ƒè®ºæ–‡å¿…è¯»" id="toc-æ ¸å¿ƒè®ºæ–‡å¿…è¯»" class="nav-link" data-scroll-target="#æ ¸å¿ƒè®ºæ–‡å¿…è¯»"><span class="header-section-number">10.1</span> æ ¸å¿ƒè®ºæ–‡ï¼ˆå¿…è¯»ï¼‰</a></li>
  <li><a href="#ç†è®ºåŸºç¡€" id="toc-ç†è®ºåŸºç¡€" class="nav-link" data-scroll-target="#ç†è®ºåŸºç¡€"><span class="header-section-number">10.2</span> ç†è®ºåŸºç¡€</a></li>
  <li><a href="#åç»­å‘å±•" id="toc-åç»­å‘å±•" class="nav-link" data-scroll-target="#åç»­å‘å±•"><span class="header-section-number">10.3</span> åç»­å‘å±•</a></li>
  <li><a href="#æŠ€æœ¯æŠ¥å‘Š" id="toc-æŠ€æœ¯æŠ¥å‘Š" class="nav-link" data-scroll-target="#æŠ€æœ¯æŠ¥å‘Š"><span class="header-section-number">10.4</span> æŠ€æœ¯æŠ¥å‘Š</a></li>
  </ul></li>
  <li><a href="#å†å²æ³¨è„š" id="toc-å†å²æ³¨è„š" class="nav-link" data-scroll-target="#å†å²æ³¨è„š"><span class="header-section-number">11</span> å†å²æ³¨è„š</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">ç¬¬6ç« ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“æ¼”è¿›</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">ä»åŠ æ€§åˆ°ä¹˜æ€§ã€ä»å…¨å±€åˆ°å±€éƒ¨ã€ä»è½¯åˆ°ç¡¬</p>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">Attention</div>
    <div class="quarto-category">Luong</div>
    <div class="quarto-category">æœºå™¨ç¿»è¯‘</div>
    <div class="quarto-category">Seq2Seq</div>
  </div>
  </div>

<div>
  <div class="description">
    æ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´ï¼šä»åŠ æ€§åˆ°ä¹˜æ€§ã€ä»å…¨å±€åˆ°å±€éƒ¨ã€ä»è½¯åˆ°ç¡¬ï¼ŒLuongçš„ç³»ç»Ÿæ€§æ¢ç´¢ä¸æ•ˆç‡-è¡¨è¾¾åŠ›æƒè¡¡ã€‚
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ying Zha </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 25, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><strong>æ ¸å¿ƒé—®é¢˜</strong>ï¼šBahdanauçš„åŠ æ€§æ³¨æ„åŠ›è™½ç„¶æœ‰æ•ˆï¼Œä½†æ˜¯å¦æœ‰æ›´ç®€æ´ã€æ›´é«˜æ•ˆçš„æ³¨æ„åŠ›è®¡ç®—æ–¹å¼ï¼Ÿä¸åŒçš„è®¾è®¡é€‰æ‹©ä¼šå¸¦æ¥æ€æ ·çš„æƒè¡¡ï¼Ÿ</p>
<p><strong>å†å²åæ ‡</strong>ï¼š2015 | Luong, Pham, Manning | æ³¨æ„åŠ›æœºåˆ¶çš„ç³»ç»Ÿæ€§æ¢ç´¢</p>
</blockquote>
<hr>
<section id="ä»ä¸Šä¸€ç« è¯´èµ·" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="ä»ä¸Šä¸€ç« è¯´èµ·"><span class="header-section-number">1</span> ä»ä¸Šä¸€ç« è¯´èµ·</h2>
<p>ä¸Šä¸€ç« æˆ‘ä»¬è§è¯äº†Attentionæœºåˆ¶çš„è¯ç”Ÿã€‚Bahdanauç­‰äººé€šè¿‡è®©è§£ç å™¨åœ¨æ¯ä¸€æ­¥éƒ½èƒ½â€å›å¤´çœ‹â€ç¼–ç å™¨çš„æ‰€æœ‰ä½ç½®ï¼Œå½»åº•æ‰“ç ´äº†Seq2Seqçš„ä¿¡æ¯ç“¶é¢ˆã€‚è¿™ä¸ªçªç ´æ€§çš„æƒ³æ³•è¿…é€Ÿåœ¨æœºå™¨ç¿»è¯‘é¢†åŸŸå¼•å‘äº†è¿é”ååº”â€”â€”å¦‚æœAttentionå¦‚æ­¤æœ‰æ•ˆï¼Œæ˜¯å¦è¿˜æœ‰å…¶ä»–æ–¹å¼æ¥è®¡ç®—â€æ³¨æ„åŠ›â€ï¼Ÿ</p>
<p>Bahdanauçš„è®¾è®¡ä½¿ç”¨äº†ä¸€ä¸ª<strong>åŠ æ€§</strong>çš„å¯¹é½å‡½æ•°ï¼šå…ˆå°†è§£ç å™¨çŠ¶æ€å’Œç¼–ç å™¨çŠ¶æ€åˆ†åˆ«ç»è¿‡çº¿æ€§å˜æ¢ï¼Œç„¶åç›¸åŠ ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªå•å±‚ç½‘ç»œå¾—åˆ°æ ‡é‡åˆ†æ•°ã€‚è¿™ä¸ªè®¾è®¡æœ‰æ•ˆï¼Œä½†è®¡ç®—é‡ä¸å°â€”â€”æ¯æ¬¡è®¡ç®—å¯¹é½åˆ†æ•°éƒ½éœ€è¦ä¸€ä¸ªå‰é¦ˆç½‘ç»œã€‚ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æµ®ç°ï¼šèƒ½å¦ç”¨æ›´ç®€å•çš„æ“ä½œï¼Œæ¯”å¦‚ç›´æ¥è®¡ç®—å‘é‡çš„ç‚¹ç§¯ï¼Œæ¥è¡¡é‡ä¸¤ä¸ªçŠ¶æ€çš„ç›¸å…³æ€§ï¼Ÿ</p>
<p>2015å¹´ï¼Œæ–¯å¦ç¦å¤§å­¦çš„Luongã€Phamå’ŒManningå‘è¡¨äº†ä¸€ç¯‡ç³»ç»Ÿæ€§çš„ç ”ç©¶ï¼Œæ¢ç´¢äº†å¤šç§æ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“ã€‚ä»–ä»¬ä¸ä»…æå‡ºäº†è®¡ç®—æ•ˆç‡æ›´é«˜çš„<strong>ä¹˜æ€§æ³¨æ„åŠ›ï¼ˆmultiplicative attentionï¼‰</strong>ï¼Œè¿˜æ¢è®¨äº†<strong>å…¨å±€æ³¨æ„åŠ›</strong>ä¸<strong>å±€éƒ¨æ³¨æ„åŠ›</strong>çš„æƒè¡¡ã€ä¸åŒå¯¹é½å‡½æ•°çš„å¯¹æ¯”ï¼Œä»¥åŠæ³¨æ„åŠ›åœ¨è§£ç å™¨ä¸­çš„æœ€ä½³ä½¿ç”¨ä½ç½®ã€‚</p>
<blockquote class="blockquote">
<p>ğŸ’¡ <strong>æœ¬ç« æ ¸å¿ƒæ´å¯Ÿ</strong>ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´è¿œæ¯”æƒ³è±¡ä¸­ä¸°å¯Œã€‚<strong>åŠ æ€§ vs ä¹˜æ€§</strong>å†³å®šäº†è¡¨è¾¾èƒ½åŠ›ä¸è®¡ç®—æ•ˆç‡çš„æƒè¡¡ï¼›<strong>å…¨å±€ vs å±€éƒ¨</strong>å†³å®šäº†é•¿åºåˆ—å¤„ç†çš„ç­–ç•¥ï¼›<strong>è½¯ vs ç¡¬</strong>å†³å®šäº†ç«¯åˆ°ç«¯å¯è®­ç»ƒæ€§ã€‚ç†è§£è¿™äº›è®¾è®¡é€‰æ‹©ï¼Œæ˜¯ç†è§£åæ¥Transformerä¸­Scaled Dot-Product Attentionçš„å…³é”®ã€‚</p>
</blockquote>
<hr>
</section>
<section id="é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆ"><span class="header-section-number">2</span> é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ</h2>
<section id="é—®é¢˜çš„ç²¾ç¡®å®šä¹‰" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="é—®é¢˜çš„ç²¾ç¡®å®šä¹‰"><span class="header-section-number">2.1</span> é—®é¢˜çš„ç²¾ç¡®å®šä¹‰</h3>
<p>Bahdanau Attentionè™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨å®è·µä¸­é¢ä¸´å‡ ä¸ªè®¾è®¡é—®é¢˜ï¼š</p>
<p><strong>è®¡ç®—æ•ˆç‡é—®é¢˜</strong>ï¼šåŠ æ€§æ³¨æ„åŠ›éœ€è¦ä¸ºæ¯å¯¹ï¼ˆè§£ç å™¨çŠ¶æ€ï¼Œç¼–ç å™¨çŠ¶æ€ï¼‰è®¡ç®—ä¸€ä¸ªå‰é¦ˆç½‘ç»œçš„è¾“å‡ºï¼š</p>
<p><span class="math display">\[
e_{ij} = \mathbf{v}_a^\top \tanh(\mathbf{W}_a \mathbf{s}_{i-1} + \mathbf{U}_a \mathbf{h}_j)
\]</span></p>
<p>è¿™æ¶‰åŠä¸¤ä¸ªçŸ©é˜µä¹˜æ³•ï¼ˆ<span class="math inline">\(\mathbf{W}_a \mathbf{s}\)</span> å’Œ <span class="math inline">\(\mathbf{U}_a \mathbf{h}\)</span>ï¼‰ã€ä¸€ä¸ªéçº¿æ€§æ¿€æ´»ï¼ˆ<span class="math inline">\(\tanh\)</span>ï¼‰ã€ä¸€ä¸ªå‘é‡ç‚¹ç§¯ï¼ˆ<span class="math inline">\(\mathbf{v}_a^\top (\cdot)\)</span>ï¼‰ã€‚å½“åºåˆ—å¾ˆé•¿æ—¶ï¼Œè¿™ä¸ªè®¡ç®—é‡æ˜¯å¯è§‚çš„ã€‚</p>
<p><strong>è®¾è®¡ç©ºé—´æœªå……åˆ†æ¢ç´¢</strong>ï¼šBahdanauåšäº†ä¸€ç³»åˆ—è®¾è®¡é€‰æ‹©â€”â€”ä½¿ç”¨åŠ æ€§å¯¹é½ã€åœ¨æ¯ä¸ªè§£ç æ­¥ä¹‹å‰è®¡ç®—æ³¨æ„åŠ›ã€å…³æ³¨æ‰€æœ‰æºä½ç½®â€”â€”ä½†è¿™äº›é€‰æ‹©æ˜¯å¦æœ€ä¼˜ï¼Ÿæœ‰æ²¡æœ‰æ›´å¥½çš„æ›¿ä»£æ–¹æ¡ˆï¼Ÿ</p>
<p><strong>é•¿åºåˆ—çš„æŒ‘æˆ˜</strong>ï¼šå¯¹äºå¾ˆé•¿çš„æºåºåˆ—ï¼Œè®¡ç®—å¯¹æ‰€æœ‰ä½ç½®çš„æ³¨æ„åŠ›å¯èƒ½æ˜¯æµªè´¹çš„ã€‚ç›´è§‰ä¸Šï¼Œåœ¨ç¿»è¯‘æŸä¸ªè¯æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦å…³æ³¨æºåºåˆ—çš„ä¸€å°éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯å…¨éƒ¨ã€‚èƒ½å¦åªè®¡ç®—â€å±€éƒ¨â€çš„æ³¨æ„åŠ›ï¼Ÿ</p>
</section>
<section id="æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆ"><span class="header-section-number">2.2</span> æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆï¼Ÿ</h3>
<p>ä¸€ä¸ªç³»ç»Ÿæ€§çš„æ¢ç´¢åº”è¯¥å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š</p>
<ol type="1">
<li><strong>å¯¹é½å‡½æ•°</strong>ï¼šé™¤äº†åŠ æ€§ï¼Œè¿˜æœ‰å“ªäº›æ–¹å¼è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ç›¸å…³æ€§ï¼Ÿå®ƒä»¬çš„è¡¨è¾¾èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡å¦‚ä½•æƒè¡¡ï¼Ÿ</li>
<li><strong>æ³¨æ„åŠ›èŒƒå›´</strong>ï¼šæ˜¯å¦éœ€è¦å…³æ³¨æ‰€æœ‰ä½ç½®ï¼Ÿèƒ½å¦åªå…³æ³¨ä¸€ä¸ªå±€éƒ¨çª—å£ï¼Ÿ</li>
<li><strong>ä½¿ç”¨ä½ç½®</strong>ï¼šæ³¨æ„åŠ›åº”è¯¥åœ¨è§£ç çš„å“ªä¸ªé˜¶æ®µä½¿ç”¨ï¼Ÿæ˜¯åœ¨è®¡ç®—è§£ç å™¨çŠ¶æ€ä¹‹å‰ï¼Œè¿˜æ˜¯ä¹‹åï¼Ÿ</li>
<li><strong>è½¯ vs ç¡¬</strong>ï¼šæ˜¯å¦å¯ä»¥ç”¨ç¡®å®šæ€§çš„â€ç¡¬â€é€‰æ‹©æ›¿ä»£æ¦‚ç‡åˆ†å¸ƒçš„â€è½¯â€é€‰æ‹©ï¼Ÿ</li>
</ol>
<hr>
</section>
</section>
<section id="æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰"><span class="header-section-number">3</span> æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰</h2>
<section id="luong-attentionä¹˜æ€§æ›¿ä»£åŠ æ€§" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="luong-attentionä¹˜æ€§æ›¿ä»£åŠ æ€§"><span class="header-section-number">3.1</span> Luong Attentionï¼šä¹˜æ€§æ›¿ä»£åŠ æ€§</h3>
<p>Luongç­‰äººæå‡ºçš„æ ¸å¿ƒæ”¹è¿›æ˜¯ç”¨<strong>ä¹˜æ€§ï¼ˆmultiplicativeï¼‰</strong>æ“ä½œæ›¿ä»£åŠ æ€§æ“ä½œæ¥è®¡ç®—å¯¹é½åˆ†æ•°ã€‚æœ€ç®€å•çš„å½¢å¼æ˜¯ç›´æ¥è®¡ç®—ç‚¹ç§¯ï¼š</p>
<p><span class="math display">\[
e_{ij} = \mathbf{s}_i^\top \mathbf{h}_j
\]</span></p>
<p>è¿™è¢«ç§°ä¸º<strong>ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆdot-product attentionï¼‰</strong>ã€‚ä¸Bahdanauçš„åŠ æ€§æ³¨æ„åŠ›ç›¸æ¯”ï¼Œå®ƒæ²¡æœ‰ä»»ä½•å¯å­¦ä¹ å‚æ•°â€”â€”åªæ˜¯ä¸¤ä¸ªå‘é‡çš„å†…ç§¯ã€‚</p>
<p>ç›´è§‰ä¸Šï¼Œç‚¹ç§¯è¡¡é‡çš„æ˜¯ä¸¤ä¸ªå‘é‡çš„â€ç›¸ä¼¼åº¦â€ã€‚å¦‚æœè§£ç å™¨çŠ¶æ€ <span class="math inline">\(\mathbf{s}_i\)</span> å’Œç¼–ç å™¨çŠ¶æ€ <span class="math inline">\(\mathbf{h}_j\)</span> æŒ‡å‘ç›¸ä¼¼çš„æ–¹å‘ï¼Œç‚¹ç§¯å°±å¤§ï¼›å¦‚æœå®ƒä»¬æ­£äº¤ï¼Œç‚¹ç§¯å°±æ˜¯é›¶ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼šæ‰¾åˆ°ä¸å½“å‰è§£ç çŠ¶æ€æœ€â€ç›¸å…³â€çš„ç¼–ç ä½ç½®ã€‚</p>
</section>
<section id="ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”"><span class="header-section-number">3.2</span> ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”</h3>
<p>Luongçš„è®ºæ–‡ç³»ç»Ÿæ¯”è¾ƒäº†ä¸‰ç§å¯¹é½å‡½æ•°ï¼š</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>åç§°</th>
<th>å…¬å¼</th>
<th>å‚æ•°</th>
<th>è®¡ç®—æ•ˆç‡</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Dot</strong></td>
<td><span class="math inline">\(\mathbf{s}^\top \mathbf{h}\)</span></td>
<td>æ— </td>
<td>æœ€å¿«</td>
</tr>
<tr class="even">
<td><strong>General</strong></td>
<td><span class="math inline">\(\mathbf{s}^\top \mathbf{W}_a \mathbf{h}\)</span></td>
<td><span class="math inline">\(\mathbf{W}_a\)</span></td>
<td>ä¸­ç­‰</td>
</tr>
<tr class="odd">
<td><strong>Concat</strong></td>
<td><span class="math inline">\(\mathbf{v}_a^\top \tanh(\mathbf{W}_a [\mathbf{s}; \mathbf{h}])\)</span></td>
<td><span class="math inline">\(\mathbf{v}_a, \mathbf{W}_a\)</span></td>
<td>æœ€æ…¢</td>
</tr>
</tbody>
</table>
<p><strong>Dotï¼ˆç‚¹ç§¯ï¼‰</strong>ï¼šæœ€ç®€å•ï¼Œè®¡ç®—æœ€å¿«ï¼Œä½†è¦æ±‚è§£ç å™¨å’Œç¼–ç å™¨çš„éšè—ç»´åº¦å¿…é¡»ç›¸åŒã€‚</p>
<p><strong>Generalï¼ˆä¸€èˆ¬å½¢å¼ï¼‰</strong>ï¼šå¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„çŸ©é˜µ <span class="math inline">\(\mathbf{W}_a\)</span>ï¼Œå¯ä»¥å¤„ç†ä¸åŒç»´åº¦çš„çŠ¶æ€ï¼Œä¹Ÿå¢åŠ äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚è¿™å®é™…ä¸Šæ˜¯åœ¨é—®ï¼šâ€œ<span class="math inline">\(\mathbf{s}\)</span> å’Œ <span class="math inline">\(\mathbf{W}_a \mathbf{h}\)</span>ï¼ˆ<span class="math inline">\(\mathbf{h}\)</span> çš„ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼‰æœ‰å¤šç›¸ä¼¼ï¼Ÿâ€</p>
<p><strong>Concatï¼ˆæ‹¼æ¥ï¼‰</strong>ï¼šè¿™å°±æ˜¯Bahdanauçš„åŠ æ€§æ³¨æ„åŠ›ï¼Œå°†ä¸¤ä¸ªå‘é‡æ‹¼æ¥åé€šè¿‡ä¸€ä¸ªå•å±‚ç½‘ç»œã€‚è¡¨è¾¾èƒ½åŠ›æœ€å¼ºï¼Œä½†è®¡ç®—æœ€æ…¢ã€‚</p>
</section>
<section id="å¦ä¸€ä¸ªå…³é”®å·®å¼‚æ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="å¦ä¸€ä¸ªå…³é”®å·®å¼‚æ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®"><span class="header-section-number">3.3</span> å¦ä¸€ä¸ªå…³é”®å·®å¼‚ï¼šæ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®</h3>
<p>é™¤äº†å¯¹é½å‡½æ•°çš„ä¸åŒï¼ŒLuongè¿˜æŒ‡å‡ºäº†å¦ä¸€ä¸ªé‡è¦å·®å¼‚ï¼š<strong>æ³¨æ„åŠ›åº”è¯¥åœ¨è§£ç å™¨çš„ä»€ä¹ˆä½ç½®ä½¿ç”¨ï¼Ÿ</strong></p>
<p><strong>Bahdanauçš„æ–¹å¼</strong>ï¼šå…ˆè®¡ç®—æ³¨æ„åŠ›ï¼Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡ <span class="math inline">\(\mathbf{c}_i\)</span>ï¼Œç„¶åå°† <span class="math inline">\(\mathbf{c}_i\)</span> å’Œä¸Šä¸€æ­¥è¾“å‡º <span class="math inline">\(y_{i-1}\)</span> ä¸€èµ·è¾“å…¥RNNï¼Œè®¡ç®—æ–°çš„éšè—çŠ¶æ€ <span class="math inline">\(\mathbf{s}_i\)</span>ã€‚</p>
<p><span class="math display">\[
\mathbf{s}_i = f(\mathbf{s}_{i-1}, y_{i-1}, \mathbf{c}_i)
\]</span></p>
<p><strong>Luongçš„æ–¹å¼</strong>ï¼šå…ˆç”¨RNNè®¡ç®—æ–°çš„éšè—çŠ¶æ€ <span class="math inline">\(\mathbf{s}_i\)</span>ï¼Œç„¶ååŸºäº <span class="math inline">\(\mathbf{s}_i\)</span> è®¡ç®—æ³¨æ„åŠ›ï¼Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡ <span class="math inline">\(\mathbf{c}_i\)</span>ï¼Œæœ€åå°†ä¸¤è€…ç»“åˆç”Ÿæˆè¾“å‡ºã€‚</p>
<p><span class="math display">\[
\mathbf{s}_i = f(\mathbf{s}_{i-1}, y_{i-1})
\]</span> <span class="math display">\[
\mathbf{c}_i = \text{Attention}(\mathbf{s}_i, \mathbf{H})
\]</span> <span class="math display">\[
\tilde{\mathbf{s}}_i = \tanh(\mathbf{W}_c [\mathbf{c}_i; \mathbf{s}_i])
\]</span></p>
<p>è¿™çœ‹èµ·æ¥æ˜¯ä¸ªç»†èŠ‚å·®å¼‚ï¼Œä½†Luongçš„æ–¹å¼æ›´åŠ æ¨¡å—åŒ–â€”â€”RNNå’ŒAttentionæ˜¯åˆ†ç¦»çš„ï¼Œä¾¿äºåˆ†æå’Œè°ƒè¯•ã€‚</p>
<hr>
</section>
</section>
<section id="æŠ€æœ¯ç»†èŠ‚" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="æŠ€æœ¯ç»†èŠ‚"><span class="header-section-number">4</span> æŠ€æœ¯ç»†èŠ‚</h2>
<section id="luong-attentionçš„ä¸‰ç§å˜ä½“" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="luong-attentionçš„ä¸‰ç§å˜ä½“"><span class="header-section-number">4.1</span> Luong Attentionçš„ä¸‰ç§å˜ä½“</h3>
<p>è®©æˆ‘ä»¬è¯¦ç»†çœ‹çœ‹ä¸‰ç§å¯¹é½å‡½æ•°çš„æ•°å­¦å½¢å¼å’Œå®ç°ã€‚</p>
<p><strong>å˜ä½“1ï¼šDot-Product Attention</strong></p>
<p><span class="math display">\[
\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{s}_i^\top \mathbf{h}_j
\]</span></p>
<p>è¿™æ˜¯æœ€ç®€å•çš„å½¢å¼ã€‚ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯å¯ä»¥ç”¨çŸ©é˜µä¹˜æ³•é«˜æ•ˆå®ç°ï¼šå¦‚æœæˆ‘ä»¬æœ‰æ‰€æœ‰ç¼–ç å™¨çŠ¶æ€ç»„æˆçš„çŸ©é˜µ <span class="math inline">\(\mathbf{H} \in \mathbb{R}^{T_x \times d}\)</span>ï¼Œé‚£ä¹ˆæ‰€æœ‰å¯¹é½åˆ†æ•°å¯ä»¥ä¸€æ¬¡è®¡ç®—ï¼š</p>
<p><span class="math display">\[
\mathbf{e}_i = \mathbf{H} \mathbf{s}_i \in \mathbb{R}^{T_x}
\]</span></p>
<p><strong>å˜ä½“2ï¼šGeneral Attention</strong></p>
<p><span class="math display">\[
\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{s}_i^\top \mathbf{W}_a \mathbf{h}_j
\]</span></p>
<p>å…¶ä¸­ <span class="math inline">\(\mathbf{W}_a \in \mathbb{R}^{d_s \times d_h}\)</span> æ˜¯å¯å­¦ä¹ å‚æ•°ã€‚è¿™å…è®¸è§£ç å™¨å’Œç¼–ç å™¨æœ‰ä¸åŒçš„éšè—ç»´åº¦ï¼ŒåŒæ—¶è®©æ¨¡å‹å­¦ä¹ ä¸€ä¸ªâ€ç›¸ä¼¼åº¦åº¦é‡â€ã€‚</p>
<p><strong>å˜ä½“3ï¼šConcat Attentionï¼ˆä¸Bahdanauç±»ä¼¼ï¼‰</strong></p>
<p><span class="math display">\[
\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{v}_a^\top \tanh(\mathbf{W}_a [\mathbf{s}_i; \mathbf{h}_j])
\]</span></p>
<p>å…¶ä¸­ <span class="math inline">\([\mathbf{s}_i; \mathbf{h}_j]\)</span> è¡¨ç¤ºå‘é‡æ‹¼æ¥ã€‚è¿™æ˜¯æœ€å…·è¡¨è¾¾èƒ½åŠ›çš„å½¢å¼ï¼Œå› ä¸ºå®ƒå¯ä»¥å­¦ä¹ ä»»æ„çš„å¯¹é½å‡½æ•°ã€‚</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Algorithm: Luong Attention Variants (Luong et al., 2015)
</div>
</div>
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> luong_attention(decoder_state, encoder_outputs, method<span class="op">=</span><span class="st">'dot'</span>, W_a<span class="op">=</span><span class="va">None</span>, v_a<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong æ³¨æ„åŠ›æœºåˆ¶çš„ä¸‰ç§å˜ä½“</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    å‚æ•°:</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: è§£ç å™¨å½“å‰éšè—çŠ¶æ€ [batch, dec_hidden]</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: ç¼–ç å™¨æ‰€æœ‰éšè—çŠ¶æ€ [batch, src_len, enc_hidden]</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">        method: 'dot', 'general', æˆ– 'concat'</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">        W_a: å¯å­¦ä¹ å‚æ•°ï¼ˆgeneralå’Œconcatéœ€è¦ï¼‰</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">        v_a: å¯å­¦ä¹ å‚æ•°ï¼ˆconcatéœ€è¦ï¼‰</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    è¿”å›:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">        context: ä¸Šä¸‹æ–‡å‘é‡ [batch, enc_hidden]</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">        attention_weights: æ³¨æ„åŠ›æƒé‡ [batch, src_len]</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> method <span class="op">==</span> <span class="st">'dot'</span>:</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç‚¹ç§¯: s^T h</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [batch, dec_hidden] @ [batch, enc_hidden, src_len] -&gt; [batch, src_len]</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                          encoder_outputs.transpose(<span class="dv">1</span>, <span class="dv">2</span>)).squeeze(<span class="dv">1</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸€èˆ¬å½¢å¼: s^T W h</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…ˆè®¡ç®— W @ h: [batch, src_len, dec_hidden]</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        transformed <span class="op">=</span> encoder_outputs <span class="op">@</span> W_a.T</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                          transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)).squeeze(<span class="dv">1</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‹¼æ¥å½¢å¼: v^T tanh(W [s; h])</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‰©å±• decoder_state åˆ°æ‰€æœ‰ä½ç½®</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        s_expanded <span class="op">=</span> decoder_state.unsqueeze(<span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, encoder_outputs.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        concat <span class="op">=</span> torch.cat([s_expanded, encoder_outputs], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> v_a <span class="op">@</span> torch.tanh(concat <span class="op">@</span> W_a.T).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> scores.squeeze(<span class="dv">1</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Softmax å½’ä¸€åŒ–</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åŠ æƒæ±‚å’Œ</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>    context <span class="op">=</span> torch.bmm(attention_weights.unsqueeze(<span class="dv">1</span>), encoder_outputs).squeeze(<span class="dv">1</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> context, attention_weights</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Source: Luong, Pham, &amp; Manning (2015) â€œEffective Approaches to Attention-based Neural Machine Translationâ€, EMNLP 2015. <a href="https://arxiv.org/abs/1508.04025">arXiv:1508.04025</a></em></p>
</div>
</div>
</section>
<section id="å®Œæ•´æ•°å€¼ç¤ºä¾‹å¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="å®Œæ•´æ•°å€¼ç¤ºä¾‹å¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°"><span class="header-section-number">4.2</span> å®Œæ•´æ•°å€¼ç¤ºä¾‹ï¼šå¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°</h3>
<p>è®©æˆ‘ä»¬ç”¨åŒä¸€ç»„æ•°æ®ï¼Œæ¯”è¾ƒä¸‰ç§å¯¹é½å‡½æ•°è®¡ç®—å‡ºçš„åˆ†æ•°ã€‚</p>
<p><strong>è®¾å®š</strong>ï¼š</p>
<ul>
<li>è§£ç å™¨çŠ¶æ€ï¼š<span class="math inline">\(\mathbf{s} = [0.5, -0.3, 0.8, 0.2]^\top\)</span></li>
<li>ç¼–ç å™¨çŠ¶æ€ï¼ˆ3ä¸ªä½ç½®ï¼‰ï¼š
<ul>
<li><span class="math inline">\(\mathbf{h}_1 = [0.2, 0.4, 0.1, -0.3]^\top\)</span></li>
<li><span class="math inline">\(\mathbf{h}_2 = [0.6, -0.1, 0.7, 0.3]^\top\)</span></li>
<li><span class="math inline">\(\mathbf{h}_3 = [-0.2, 0.5, 0.3, 0.1]^\top\)</span></li>
</ul></li>
</ul>
<p><strong>Dot-Product è®¡ç®—</strong>ï¼š</p>
<p><span class="math display">\[
e_1 = \mathbf{s}^\top \mathbf{h}_1 = 0.5 \times 0.2 + (-0.3) \times 0.4 + 0.8 \times 0.1 + 0.2 \times (-0.3)
\]</span> <span class="math display">\[
= 0.10 - 0.12 + 0.08 - 0.06 = 0.00
\]</span></p>
<p><span class="math display">\[
e_2 = \mathbf{s}^\top \mathbf{h}_2 = 0.5 \times 0.6 + (-0.3) \times (-0.1) + 0.8 \times 0.7 + 0.2 \times 0.3
\]</span> <span class="math display">\[
= 0.30 + 0.03 + 0.56 + 0.06 = 0.95
\]</span></p>
<p><span class="math display">\[
e_3 = \mathbf{s}^\top \mathbf{h}_3 = 0.5 \times (-0.2) + (-0.3) \times 0.5 + 0.8 \times 0.3 + 0.2 \times 0.1
\]</span> <span class="math display">\[
= -0.10 - 0.15 + 0.24 + 0.02 = 0.01
\]</span></p>
<p><strong>Softmax å½’ä¸€åŒ–</strong>ï¼š</p>
<p><span class="math display">\[
\alpha_1 = \frac{e^{0.00}}{e^{0.00} + e^{0.95} + e^{0.01}} = \frac{1.00}{1.00 + 2.59 + 1.01} = \frac{1.00}{4.60} \approx 0.22
\]</span></p>
<p><span class="math display">\[
\alpha_2 = \frac{e^{0.95}}{4.60} = \frac{2.59}{4.60} \approx 0.56
\]</span></p>
<p><span class="math display">\[
\alpha_3 = \frac{e^{0.01}}{4.60} = \frac{1.01}{4.60} \approx 0.22
\]</span></p>
<p><strong>è§£è¯»</strong>ï¼šä½¿ç”¨ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œæ¨¡å‹å°†56%çš„æ³¨æ„åŠ›æ”¾åœ¨ä½ç½®2ï¼Œè¿™æ˜¯å› ä¸º <span class="math inline">\(\mathbf{h}_2\)</span> ä¸ <span class="math inline">\(\mathbf{s}\)</span> çš„ç‚¹ç§¯æœ€å¤§â€”â€”å®ƒä»¬åœ¨å‘é‡ç©ºé—´ä¸­æœ€â€ç›¸ä¼¼â€ã€‚</p>
<p><strong>General Attention è®¡ç®—</strong>ï¼ˆå‡è®¾ <span class="math inline">\(\mathbf{W}_a\)</span> æ˜¯å•ä½çŸ©é˜µï¼‰ï¼š</p>
<p>å½“ <span class="math inline">\(\mathbf{W}_a = \mathbf{I}\)</span> æ—¶ï¼ŒGeneralé€€åŒ–ä¸ºDot-Productã€‚åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ<span class="math inline">\(\mathbf{W}_a\)</span> å¯ä»¥å­¦ä¹ ä¸€ä¸ªå˜æ¢ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå‘ç°æ›´å¤æ‚çš„ç›¸å…³æ€§æ¨¡å¼ã€‚</p>
</section>
<section id="global-vs-local-attention" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="global-vs-local-attention"><span class="header-section-number">4.3</span> Global vs Local Attention</h3>
<p>Luongè¿˜æå‡ºäº†å¦ä¸€ä¸ªé‡è¦çš„è®¾è®¡é€‰æ‹©ï¼š<strong>æ³¨æ„åŠ›çš„èŒƒå›´</strong>ã€‚</p>
<p><strong>Global Attention</strong>ï¼šå…³æ³¨æ‰€æœ‰æºä½ç½®ã€‚è¿™æ˜¯Bahdanauçš„åšæ³•ï¼Œä¹Ÿæ˜¯ä¸Šé¢è®¨è®ºçš„é»˜è®¤æ–¹å¼ã€‚</p>
<p><span class="math display">\[
\mathbf{c}_i = \sum_{j=1}^{T_x} \alpha_{ij} \mathbf{h}_j
\]</span></p>
<p><strong>Local Attention</strong>ï¼šåªå…³æ³¨æºåºåˆ—çš„ä¸€ä¸ª<strong>çª—å£</strong>ã€‚</p>
<p>æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¯ä¸ªè§£ç æ­¥ï¼Œå…ˆé¢„æµ‹ä¸€ä¸ªå¯¹é½ä½ç½® <span class="math inline">\(p_i\)</span>ï¼Œç„¶ååªè®¡ç®—ä»¥ <span class="math inline">\(p_i\)</span> ä¸ºä¸­å¿ƒã€å®½åº¦ä¸º <span class="math inline">\(2D+1\)</span> çš„çª—å£å†…çš„æ³¨æ„åŠ›ã€‚</p>
<p><span class="math display">\[
\mathbf{c}_i = \sum_{j=p_i-D}^{p_i+D} \alpha_{ij} \mathbf{h}_j
\]</span></p>
<p>å¯¹é½ä½ç½® <span class="math inline">\(p_i\)</span> å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼ç¡®å®šï¼š</p>
<p><strong>Local-mï¼ˆå•è°ƒï¼‰</strong>ï¼šå‡è®¾æºå’Œç›®æ ‡å¤§è‡´å¯¹é½ï¼Œç®€å•è®¾ç½® <span class="math inline">\(p_i = i\)</span>ã€‚</p>
<p><strong>Local-pï¼ˆé¢„æµ‹ï¼‰</strong>ï¼šå­¦ä¹ ä¸€ä¸ªå‡½æ•°æ¥é¢„æµ‹ <span class="math inline">\(p_i\)</span>ï¼š</p>
<p><span class="math display">\[
p_i = T_x \cdot \sigma(\mathbf{v}_p^\top \tanh(\mathbf{W}_p \mathbf{s}_i))
\]</span></p>
<p>å…¶ä¸­ <span class="math inline">\(\sigma\)</span> æ˜¯sigmoidå‡½æ•°ï¼Œç¡®ä¿ <span class="math inline">\(p_i \in [0, T_x]\)</span>ã€‚</p>
<p>ä¸ºäº†è®©æ³¨æ„åŠ›åœ¨çª—å£ä¸­å¿ƒé™„è¿‘æ›´é›†ä¸­ï¼ŒLocal Attentionè¿˜å¼•å…¥äº†ä¸€ä¸ªé«˜æ–¯åç½®ï¼š</p>
<p><span class="math display">\[
\alpha_{ij} = \text{align}(\mathbf{s}_i, \mathbf{h}_j) \cdot \exp\left(-\frac{(j - p_i)^2}{2\sigma^2}\right)
\]</span></p>
<div id="fig-global-local" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-global-local-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-6/original/fig-global-local-attention.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-global-local-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Luongè®ºæ–‡ä¸­çš„Global vs Local Attentionå¯¹æ¯”ã€‚å·¦è¾¹æ˜¯Global Attentionï¼šè§£ç å™¨çŠ¶æ€ <span class="math inline">\(h_t\)</span> ä¸æ‰€æœ‰æºä½ç½®è®¡ç®—æ³¨æ„åŠ›ï¼Œç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡ <span class="math inline">\(c_t\)</span>ã€‚å³è¾¹æ˜¯Local Attentionï¼šå…ˆé¢„æµ‹å¯¹é½ä½ç½® <span class="math inline">\(p_t\)</span>ï¼Œåªè®¡ç®—çª—å£ <span class="math inline">\([p_t - D, p_t + D]\)</span> å†…çš„æ³¨æ„åŠ›ã€‚
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Luong, Pham, &amp; Manning (2015) â€œEffective Approaches to Attention-based Neural Machine Translationâ€, Figure 2 &amp; 3. <a href="https://arxiv.org/abs/1508.04025">arXiv:1508.04025</a></em></p>
</div>
</section>
<section id="hard-attention-vs-soft-attention" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="hard-attention-vs-soft-attention"><span class="header-section-number">4.4</span> Hard Attention vs Soft Attention</h3>
<p>é™¤äº†Global/Localçš„åŒºåˆ†ï¼Œè¿˜æœ‰å¦ä¸€ä¸ªé‡è¦ç»´åº¦ï¼š<strong>è½¯æ³¨æ„åŠ›ï¼ˆSoft Attentionï¼‰</strong> vs <strong>ç¡¬æ³¨æ„åŠ›ï¼ˆHard Attentionï¼‰</strong>ã€‚</p>
<p><strong>Soft Attention</strong>ï¼šè®¡ç®—æ‰€æœ‰ä½ç½®çš„æ³¨æ„åŠ›æƒé‡ï¼ˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼‰ï¼Œç„¶ååŠ æƒæ±‚å’Œã€‚è¿™æ˜¯æˆ‘ä»¬ä¸€ç›´åœ¨è®¨è®ºçš„æ–¹å¼ã€‚</p>
<p><span class="math display">\[
\mathbf{c}_i = \sum_j \alpha_{ij} \mathbf{h}_j = \mathbb{E}_{p(j | \mathbf{s}_i, \mathbf{H})}[\mathbf{h}_j]
\]</span></p>
<p><strong>Hard Attention</strong>ï¼šä»æ³¨æ„åŠ›åˆ†å¸ƒä¸­<strong>é‡‡æ ·</strong>ä¸€ä¸ªä½ç½® <span class="math inline">\(j^*\)</span>ï¼Œåªä½¿ç”¨é‚£ä¸ªä½ç½®çš„ä¿¡æ¯ã€‚</p>
<p><span class="math display">\[
j^* \sim \text{Categorical}(\alpha_{i1}, \alpha_{i2}, \ldots, \alpha_{iT_x})
\]</span> <span class="math display">\[
\mathbf{c}_i = \mathbf{h}_{j^*}
\]</span></p>
<p>ä¸¤è€…çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº<strong>å¯å¾®åˆ†æ€§</strong>ã€‚</p>
<p><strong>Soft Attention æ˜¯å¯å¾®åˆ†çš„</strong>ï¼šåŠ æƒæ±‚å’Œæ˜¯ä¸€ä¸ªè¿ç»­æ“ä½œï¼Œæ¢¯åº¦å¯ä»¥é€šè¿‡ <span class="math inline">\(\alpha_{ij}\)</span> æµå‘å¯¹é½å‡½æ•°çš„å‚æ•°ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç”¨æ ‡å‡†çš„åå‘ä¼ æ’­è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚</p>
<p><strong>Hard Attention ä¸å¯å¾®åˆ†</strong>ï¼šé‡‡æ ·æ“ä½œæ˜¯ç¦»æ•£çš„ï¼Œæ¢¯åº¦æ— æ³•ç›´æ¥é€šè¿‡ã€‚è¦è®­ç»ƒHard Attentionï¼Œéœ€è¦ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚REINFORCEï¼‰ï¼Œç”¨æœŸæœ›æ¢¯åº¦çš„è’™ç‰¹å¡æ´›ä¼°è®¡æ¥è¿‘ä¼¼ã€‚è¿™å¸¦æ¥äº†é«˜æ–¹å·®å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Hard Attentionçš„è®­ç»ƒå›°éš¾
</div>
</div>
<div class="callout-body-container callout-body">
<p>Hard Attentionè™½ç„¶åœ¨æ¦‚å¿µä¸Šæ›´æ¥è¿‘äººç±»çš„â€æ³¨æ„â€ï¼ˆæˆ‘ä»¬çœŸçš„åªçœ‹ä¸€ä¸ªåœ°æ–¹ï¼Œè€Œä¸æ˜¯æ¨¡ç³Šåœ°çœ‹æ‰€æœ‰åœ°æ–¹ï¼‰ï¼Œä½†å®ƒçš„è®­ç»ƒéœ€è¦å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼š</p>
<p><span class="math display">\[
\nabla_\theta J = \mathbb{E}_{j^* \sim p(j|\theta)} \left[ \nabla_\theta \log p(j^* | \theta) \cdot R(j^*) \right]
\]</span></p>
<p>å…¶ä¸­ <span class="math inline">\(R(j^*)\)</span> æ˜¯é€‰æ‹©ä½ç½® <span class="math inline">\(j^*\)</span> å¸¦æ¥çš„â€å¥–åŠ±â€ã€‚è¿™ä¸ªæ¢¯åº¦ä¼°è®¡çš„æ–¹å·®å¾ˆå¤§ï¼Œéœ€è¦å¤§é‡é‡‡æ ·æ‰èƒ½ç¨³å®šã€‚</p>
<p>å®è·µä¸­ï¼Œ<strong>Soft Attentionå‡ ä¹æ€»æ˜¯æ›´å¥½çš„é€‰æ‹©</strong>ï¼Œå› ä¸ºï¼š</p>
<ol type="1">
<li>ç«¯åˆ°ç«¯å¯å¾®åˆ†ï¼Œè®­ç»ƒç®€å•</li>
<li>æ¢¯åº¦ä¼°è®¡æ²¡æœ‰æ–¹å·®é—®é¢˜</li>
<li>å¯ä»¥åŒæ—¶åˆ©ç”¨å¤šä¸ªä½ç½®çš„ä¿¡æ¯</li>
</ol>
</div>
</div>
</section>
<section id="å¤æ‚åº¦åˆ†æ" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="å¤æ‚åº¦åˆ†æ"><span class="header-section-number">4.5</span> å¤æ‚åº¦åˆ†æ</h3>
<p>ä¸åŒæ³¨æ„åŠ›å˜ä½“çš„è®¡ç®—å¤æ‚åº¦ï¼š</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 38%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>å˜ä½“</th>
<th>å¯¹é½è®¡ç®—</th>
<th>æ€»å¤æ‚åº¦</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Global + Dot</strong></td>
<td><span class="math inline">\(O(T_x \cdot d)\)</span> per step</td>
<td><span class="math inline">\(O(T_x \cdot T_y \cdot d)\)</span></td>
</tr>
<tr class="even">
<td><strong>Global + General</strong></td>
<td><span class="math inline">\(O(T_x \cdot d^2)\)</span> per step</td>
<td><span class="math inline">\(O(T_x \cdot T_y \cdot d^2)\)</span></td>
</tr>
<tr class="odd">
<td><strong>Global + Concat</strong></td>
<td><span class="math inline">\(O(T_x \cdot d^2)\)</span> per step</td>
<td><span class="math inline">\(O(T_x \cdot T_y \cdot d^2)\)</span></td>
</tr>
<tr class="even">
<td><strong>Local</strong></td>
<td><span class="math inline">\(O(D \cdot d)\)</span> per step</td>
<td><span class="math inline">\(O(D \cdot T_y \cdot d)\)</span></td>
</tr>
</tbody>
</table>
<p>å…¶ä¸­ <span class="math inline">\(T_x\)</span> æ˜¯æºåºåˆ—é•¿åº¦ï¼Œ<span class="math inline">\(T_y\)</span> æ˜¯ç›®æ ‡åºåˆ—é•¿åº¦ï¼Œ<span class="math inline">\(d\)</span> æ˜¯éšè—ç»´åº¦ï¼Œ<span class="math inline">\(D\)</span> æ˜¯å±€éƒ¨çª—å£å¤§å°ã€‚</p>
<p>Local Attentionçš„ä¼˜åŠ¿åœ¨é•¿åºåˆ—æ—¶å°¤ä¸ºæ˜æ˜¾ï¼šå½“ <span class="math inline">\(T_x = 1000\)</span> è€Œ <span class="math inline">\(D = 50\)</span> æ—¶ï¼Œè®¡ç®—é‡å‡å°‘äº†20å€ã€‚</p>
<hr>
</section>
</section>
<section id="å·¥ç¨‹å®è·µ" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="å·¥ç¨‹å®è·µ"><span class="header-section-number">5</span> å·¥ç¨‹å®è·µ</h2>
<section id="å®ç°luong-attention" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="å®ç°luong-attention"><span class="header-section-number">5.1</span> å®ç°Luong Attention</h3>
<div id="f1fdc0c4" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LuongAttention(nn.Module):</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒä¸‰ç§å¯¹é½æ–¹å¼</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, enc_hidden_dim, dec_hidden_dim, method<span class="op">=</span><span class="st">'dot'</span>):</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.method <span class="op">=</span> method</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_hidden_dim <span class="op">=</span> enc_hidden_dim</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dec_hidden_dim <span class="op">=</span> dec_hidden_dim</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim <span class="op">+</span> dec_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v_a <span class="op">=</span> nn.Linear(dec_hidden_dim, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, decoder_state, encoder_outputs, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: [batch, dec_hidden]</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: [batch, src_len, enc_hidden]</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="co">        mask: [batch, src_len], Trueè¡¨ç¤ºpaddingä½ç½®</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        batch_size, src_len, _ <span class="op">=</span> encoder_outputs.shape</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'dot'</span>:</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ç‚¹ç§¯: s^T h</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># éœ€è¦ dec_hidden == enc_hidden</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> torch.bmm(</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>                decoder_state.unsqueeze(<span class="dv">1</span>),  <span class="co"># [batch, 1, dec_hidden]</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>                encoder_outputs.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># [batch, enc_hidden, src_len]</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>            ).squeeze(<span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ä¸€èˆ¬å½¢å¼: s^T W h</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># W å°† enc_hidden æ˜ å°„åˆ° dec_hidden</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            transformed <span class="op">=</span> <span class="va">self</span>.W_a(encoder_outputs)  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> torch.bmm(</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>                decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>                transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>            ).squeeze(<span class="dv">1</span>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ‹¼æ¥å½¢å¼: v^T tanh(W [s; h])</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>            decoder_expanded <span class="op">=</span> decoder_state.unsqueeze(<span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, src_len, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>            concat <span class="op">=</span> torch.cat([decoder_expanded, encoder_outputs], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>            energy <span class="op">=</span> torch.tanh(<span class="va">self</span>.W_a(concat))  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> <span class="va">self</span>.v_a(energy).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åº”ç”¨ mask</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> scores.masked_fill(mask, <span class="op">-</span><span class="fl">1e10</span>)</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Softmax</span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸Šä¸‹æ–‡å‘é‡</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> torch.bmm(</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>            attention_weights.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>            encoder_outputs</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> context, attention_weights</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="å®ç°local-attention" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="å®ç°local-attention"><span class="header-section-number">5.2</span> å®ç°Local Attention</h3>
<div id="9a405fd0" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LocalAttention(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong çš„ Local Attentionï¼ˆé¢„æµ‹å‹ï¼‰</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, enc_hidden_dim, dec_hidden_dim, window_size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.window_size <span class="op">=</span> window_size  <span class="co"># D: çª—å£åŠå¾„</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_hidden_dim <span class="op">=</span> enc_hidden_dim</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½ç½®é¢„æµ‹ç½‘ç»œ</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_p <span class="op">=</span> nn.Linear(dec_hidden_dim, dec_hidden_dim)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v_p <span class="op">=</span> nn.Linear(dec_hidden_dim, <span class="dv">1</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¯¹é½å‡½æ•°ï¼ˆä½¿ç”¨ generalï¼‰</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é«˜æ–¯æ ‡å‡†å·®</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigma <span class="op">=</span> window_size <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, decoder_state, encoder_outputs, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: [batch, dec_hidden]</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: [batch, src_len, enc_hidden]</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        batch_size, src_len, _ <span class="op">=</span> encoder_outputs.shape</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> decoder_state.device</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: é¢„æµ‹å¯¹é½ä½ç½® p</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p = S * sigmoid(v^T tanh(W_p s))</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> src_len <span class="op">*</span> torch.sigmoid(</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v_p(torch.tanh(<span class="va">self</span>.W_p(decoder_state)))</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch]</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: è®¡ç®—æ‰€æœ‰ä½ç½®çš„å¯¹é½åˆ†æ•°</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>        transformed <span class="op">=</span> <span class="va">self</span>.W_a(encoder_outputs)  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>            decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>            transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 3: åº”ç”¨é«˜æ–¯çª—å£</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç”Ÿæˆä½ç½®ç´¢å¼• [0, 1, 2, ..., src_len-1]</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> torch.arange(src_len, device<span class="op">=</span>device).<span class="bu">float</span>()</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> positions.unsqueeze(<span class="dv">0</span>).expand(batch_size, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é«˜æ–¯æƒé‡: exp(-(j - p)^2 / (2 * sigma^2))</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>        gaussian <span class="op">=</span> torch.exp(<span class="op">-</span>((positions <span class="op">-</span> p.unsqueeze(<span class="dv">1</span>)) <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.sigma <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 4: çª—å£maskï¼ˆåªä¿ç•™ [p-D, p+D] èŒƒå›´å†…çš„ä½ç½®ï¼‰</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>        window_mask <span class="op">=</span> (positions <span class="op">&gt;=</span> (p.unsqueeze(<span class="dv">1</span>) <span class="op">-</span> <span class="va">self</span>.window_size)) <span class="op">&amp;</span> <span class="op">\</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>                      (positions <span class="op">&lt;=</span> (p.unsqueeze(<span class="dv">1</span>) <span class="op">+</span> <span class="va">self</span>.window_size))</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åº”ç”¨çª—å£mask</span></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> scores.masked_fill(<span class="op">~</span>window_mask, <span class="op">-</span><span class="fl">1e10</span>)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 5: Softmax + é«˜æ–¯åŠ æƒ</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">*</span> gaussian</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é‡æ–°å½’ä¸€åŒ–</span></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> attention_weights <span class="op">/</span> (attention_weights.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸Šä¸‹æ–‡å‘é‡</span></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> torch.bmm(</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>            attention_weights.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>            encoder_outputs</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> context, attention_weights, p</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="å¯¹æ¯”å®éªŒ" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="å¯¹æ¯”å®éªŒ"><span class="header-section-number">5.3</span> å¯¹æ¯”å®éªŒ</h3>
<div id="b2e8eee4" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># åˆ›å»ºæµ‹è¯•æ•°æ®</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>src_len <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>enc_hidden <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dec_hidden <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>encoder_outputs <span class="op">=</span> torch.randn(batch_size, src_len, enc_hidden)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>decoder_state <span class="op">=</span> torch.randn(batch_size, dec_hidden)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># æµ‹è¯•ä¸‰ç§ Luong Attention</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">'dot'</span>, <span class="st">'general'</span>, <span class="st">'concat'</span>]:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    attn <span class="op">=</span> LuongAttention(enc_hidden, dec_hidden, method<span class="op">=</span>method)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    context, weights <span class="op">=</span> attn(decoder_state, encoder_outputs)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>method<span class="sc">:8s}</span><span class="ss">: context shape = </span><span class="sc">{</span>context<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, weights sum = </span><span class="sc">{</span>weights<span class="sc">.</span><span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># æµ‹è¯• Local Attention</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>local_attn <span class="op">=</span> LocalAttention(enc_hidden, dec_hidden, window_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>context, weights, p <span class="op">=</span> local_attn(decoder_state, encoder_outputs)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'local'</span><span class="sc">:8s}</span><span class="ss">: context shape = </span><span class="sc">{</span>context<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, predicted p = </span><span class="sc">{</span>p<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>dot     : context shape = torch.Size([2, 64]), weights sum = tensor([1., 1.])
general : context shape = torch.Size([2, 64]), weights sum = tensor([1.0000, 1.0000], grad_fn=&lt;SumBackward1&gt;)
concat  : context shape = torch.Size([2, 64]), weights sum = tensor([1., 1.], grad_fn=&lt;SumBackward1&gt;)
local   : context shape = torch.Size([2, 64]), predicted p = [4.633298397064209, 5.614270210266113]</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="æ·±å…¥ç†è§£" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="æ·±å…¥ç†è§£"><span class="header-section-number">6</span> æ·±å…¥ç†è§£</h2>
<section id="ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œç†è®ºè§†è§’" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œç†è®ºè§†è§’"><span class="header-section-number">6.1</span> ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œï¼Ÿâ€”â€”ç†è®ºè§†è§’</h3>
<p>ç‚¹ç§¯æ³¨æ„åŠ›çš„æœ‰æ•ˆæ€§å¯ä»¥ä»å¤šä¸ªè§’åº¦ç†è§£ã€‚</p>
<p><strong>ä½™å¼¦ç›¸ä¼¼åº¦è§†è§’</strong>ï¼šå½“å‘é‡è¢«å½’ä¸€åŒ–åï¼Œç‚¹ç§¯å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦ï¼š</p>
<p><span class="math display">\[
\mathbf{s}^\top \mathbf{h} = \|\mathbf{s}\| \|\mathbf{h}\| \cos(\theta)
\]</span></p>
<p>ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯è¡¡é‡ä¸¤ä¸ªå‘é‡â€æ–¹å‘ä¸€è‡´æ€§â€çš„ç»å…¸æŒ‡æ ‡ã€‚ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šå­¦ä¹ è®©ç›¸å…³çš„çŠ¶æ€æŒ‡å‘ç›¸ä¼¼çš„æ–¹å‘ã€‚</p>
<p><strong>æ ¸æ–¹æ³•è§†è§’</strong>ï¼šç‚¹ç§¯å¯ä»¥çœ‹ä½œä¸€ä¸ªçº¿æ€§æ ¸ï¼ˆlinear kernelï¼‰ã€‚åœ¨æ ¸æ–¹æ³•çš„æ¡†æ¶ä¸‹ï¼Œæ³¨æ„åŠ›æƒé‡å®é™…ä¸Šæ˜¯åœ¨ä¸€ä¸ªç‰¹å¾ç©ºé—´ä¸­è®¡ç®—ç›¸ä¼¼åº¦ã€‚General Attentionå¼•å…¥çš„å¯å­¦ä¹ çŸ©é˜µ <span class="math inline">\(\mathbf{W}_a\)</span> ç›¸å½“äºå­¦ä¹ ä¸€ä¸ªMahalanobisè·ç¦»ã€‚</p>
<p><strong>ä¿¡æ¯æ£€ç´¢è§†è§’</strong>ï¼šç‚¹ç§¯æ³¨æ„åŠ›å¯ä»¥ç±»æ¯”ä¸ºå‘é‡ç©ºé—´æ¨¡å‹ä¸­çš„æŸ¥è¯¢-æ–‡æ¡£åŒ¹é…ã€‚è§£ç å™¨çŠ¶æ€æ˜¯â€æŸ¥è¯¢â€ï¼Œç¼–ç å™¨çŠ¶æ€æ˜¯â€æ–‡æ¡£â€ï¼Œç‚¹ç§¯è¡¡é‡æŸ¥è¯¢ä¸æ–‡æ¡£çš„ç›¸å…³æ€§ã€‚</p>
</section>
<section id="ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾scaled-dot-productçš„é¢„å…†" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾scaled-dot-productçš„é¢„å…†"><span class="header-section-number">6.2</span> ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾ï¼Ÿâ€”â€”Scaled Dot-Productçš„é¢„å…†</h3>
<p>Luongçš„è®ºæ–‡æ²¡æœ‰è®¨è®ºè¿™ä¸ªé—®é¢˜ï¼Œä½†åæ¥çš„Transformerè®ºæ–‡ï¼ˆVaswani et al., 2017ï¼‰æŒ‡å‡ºäº†ç‚¹ç§¯æ³¨æ„åŠ›çš„ä¸€ä¸ªæ½œåœ¨é—®é¢˜ï¼š</p>
<p>å½“å‘é‡ç»´åº¦ <span class="math inline">\(d\)</span> å¾ˆå¤§æ—¶ï¼Œç‚¹ç§¯çš„æ–¹å·®ä¼šå¾ˆå¤§ã€‚å‡è®¾ <span class="math inline">\(\mathbf{s}\)</span> å’Œ <span class="math inline">\(\mathbf{h}\)</span> çš„æ¯ä¸ªåˆ†é‡éƒ½æ˜¯ç‹¬ç«‹çš„ã€å‡å€¼ä¸º0ã€æ–¹å·®ä¸º1çš„éšæœºå˜é‡ï¼Œé‚£ä¹ˆï¼š</p>
<p><span class="math display">\[
\text{Var}(\mathbf{s}^\top \mathbf{h}) = d
\]</span></p>
<p>å½“ <span class="math inline">\(d = 512\)</span> æ—¶ï¼Œç‚¹ç§¯çš„æ ‡å‡†å·®æ˜¯ <span class="math inline">\(\sqrt{512} \approx 22.6\)</span>ã€‚è¿™æ„å‘³ç€ç‚¹ç§¯å¯èƒ½äº§ç”Ÿå¾ˆå¤§çš„æ­£å€¼æˆ–è´Ÿå€¼ï¼Œå¯¼è‡´softmaxè¾“å‡ºæ¥è¿‘one-hotåˆ†å¸ƒï¼Œæ¢¯åº¦å˜å¾—å¾ˆå°ã€‚</p>
<p>è§£å†³æ–¹æ¡ˆæ˜¯<strong>ç¼©æ”¾</strong>ï¼š</p>
<p><span class="math display">\[
\text{score}(\mathbf{s}, \mathbf{h}) = \frac{\mathbf{s}^\top \mathbf{h}}{\sqrt{d}}
\]</span></p>
<p>è¿™å°±æ˜¯Transformerä¸­çš„<strong>Scaled Dot-Product Attention</strong>ã€‚Luongçš„è®ºæ–‡ä½¿ç”¨çš„ç»´åº¦è¾ƒå°ï¼ˆ500å·¦å³ï¼‰ï¼Œé—®é¢˜ä¸å¤ªæ˜æ˜¾ï¼›ä½†åœ¨Transformerçš„å¤§ç»´åº¦è®¾ç½®ä¸‹ï¼Œç¼©æ”¾å˜å¾—å¿…è¦ã€‚</p>
</section>
<section id="æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶"><span class="header-section-number">6.3</span> æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶</h3>
<p><strong>Dot-Product Attentionçš„å±€é™</strong>ï¼š</p>
<ol type="1">
<li><strong>ç»´åº¦å¿…é¡»åŒ¹é…</strong>ï¼šè§£ç å™¨å’Œç¼–ç å™¨çš„éšè—ç»´åº¦å¿…é¡»ç›¸åŒï¼Œå¦åˆ™æ— æ³•è®¡ç®—ç‚¹ç§¯</li>
<li><strong>è¡¨è¾¾èƒ½åŠ›æœ‰é™</strong>ï¼šæ— æ³•å­¦ä¹ å¤æ‚çš„ç›¸å…³æ€§æ¨¡å¼ï¼Œåªèƒ½æ•æ‰â€æ–¹å‘ç›¸ä¼¼â€çš„å…³ç³»</li>
</ol>
<p><strong>Local Attentionçš„å±€é™</strong>ï¼š</p>
<ol type="1">
<li><strong>éœ€è¦é¢„æµ‹å¯¹é½ä½ç½®</strong>ï¼šå¦‚æœä½ç½®é¢„æµ‹é”™è¯¯ï¼Œä¼šé”™è¿‡é‡è¦ä¿¡æ¯</li>
<li><strong>ä¸é€‚åˆéå•è°ƒå¯¹é½</strong>ï¼šå¯¹äºè¯­åºå·®å¼‚å¤§çš„è¯­è¨€å¯¹ï¼Œå±€éƒ¨çª—å£å¯èƒ½è¦†ç›–ä¸åˆ°æ­£ç¡®ä½ç½®</li>
<li><strong>çª—å£å¤§å°æ˜¯è¶…å‚æ•°</strong>ï¼šé€‰æ‹©ä¸å½“ä¼šå½±å“æ€§èƒ½</li>
</ol>
<p><strong>General/Concatçš„å±€é™</strong>ï¼š</p>
<ol type="1">
<li><strong>è®¡ç®—å¼€é”€</strong>ï¼šé¢å¤–çš„çŸ©é˜µä¹˜æ³•å¢åŠ äº†è®¡ç®—é‡</li>
<li><strong>è¿‡æ‹Ÿåˆé£é™©</strong>ï¼šæ›´å¤šå‚æ•°å¯èƒ½å¯¼è‡´åœ¨å°æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆ</li>
</ol>
</section>
<section id="å¼€æ”¾ç ”ç©¶é—®é¢˜" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="å¼€æ”¾ç ”ç©¶é—®é¢˜"><span class="header-section-number">6.4</span> å¼€æ”¾ç ”ç©¶é—®é¢˜</h3>
<ol type="1">
<li><p><strong>å¯¹é½å‡½æ•°çš„æœ€ä¼˜é€‰æ‹©</strong>ï¼šåœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹åº”è¯¥é€‰æ‹©å“ªç§å¯¹é½å‡½æ•°ï¼Ÿæ˜¯å¦æœ‰ç†è®ºæŒ‡å¯¼ï¼Ÿ</p></li>
<li><p><strong>åŠ¨æ€çª—å£</strong>ï¼šLocal Attentionä½¿ç”¨å›ºå®šçª—å£å¤§å°ï¼Œèƒ½å¦æ ¹æ®å†…å®¹åŠ¨æ€è°ƒæ•´ï¼Ÿ</p></li>
<li><p><strong>å¤šç²’åº¦æ³¨æ„åŠ›</strong>ï¼šèƒ½å¦åŒæ—¶ä½¿ç”¨å…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›ï¼Œåœ¨ä¸åŒç²’åº¦ä¸Šæ•è·ä¿¡æ¯ï¼Ÿ</p></li>
</ol>
<hr>
</section>
</section>
<section id="å±€é™æ€§ä¸å±•æœ›" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="å±€é™æ€§ä¸å±•æœ›"><span class="header-section-number">7</span> å±€é™æ€§ä¸å±•æœ›</h2>
<section id="æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™"><span class="header-section-number">7.1</span> æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™</h3>
<p><strong>1. æ³¨æ„åŠ›ä»ç„¶æ˜¯RNNçš„â€é™„å±å“â€</strong></p>
<p>æ— è®ºæ˜¯Bahdanauè¿˜æ˜¯Luongçš„æ³¨æ„åŠ›ï¼Œéƒ½æ˜¯Seq2Seqæ¶æ„çš„å¢å¼ºç»„ä»¶ã€‚ç¼–ç å’Œè§£ç çš„æ ¸å¿ƒä»ç„¶ä¾èµ–RNNã€‚è¿™æ„å‘³ç€ï¼š</p>
<ul>
<li>é¡ºåºè®¡ç®—æ— æ³•é¿å…ï¼šRNNå¿…é¡»é€æ­¥å¤„ç†åºåˆ—</li>
<li>é•¿è·ç¦»ä¾èµ–ä»ç„¶å›°éš¾ï¼šè™½ç„¶Attentionæä¾›äº†æ·å¾„ï¼Œä½†RNNæœ¬èº«çš„é—®é¢˜æ²¡æœ‰è§£å†³</li>
</ul>
<p><strong>2. æ³¨æ„åŠ›åªåœ¨ç¼–ç å™¨-è§£ç å™¨ä¹‹é—´</strong></p>
<p>å½“å‰çš„Attentionåªè®©è§£ç å™¨å…³æ³¨ç¼–ç å™¨ã€‚ä½†ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼š<strong>ç¼–ç å™¨å†…éƒ¨çš„å„ä¸ªä½ç½®èƒ½å¦ç›¸äº’å…³æ³¨ï¼Ÿ</strong> ä¸€ä¸ªè¯çš„ç†è§£å¯èƒ½ä¾èµ–äºåŒä¸€å¥è¯ä¸­çš„å…¶ä»–è¯ï¼Œè€Œå½“å‰çš„æ¶æ„æ²¡æœ‰æä¾›è¿™ç§æœºåˆ¶ã€‚</p>
<p><strong>3. ä½ç½®ä¿¡æ¯æ˜¯éšå¼çš„</strong></p>
<p>Attentionæœ¬èº«ä¸åŒ…å«ä½ç½®ä¿¡æ¯ã€‚ä½ç½®ä¿¡æ¯å®Œå…¨ä¾èµ–RNNçš„é¡ºåºå¤„ç†æ¥éšå¼ç¼–ç ã€‚å¦‚æœæŠ›å¼ƒRNNï¼Œä½ç½®ä¿¡æ¯å°†å®Œå…¨ä¸¢å¤±ã€‚</p>
</section>
<section id="è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆ" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆ"><span class="header-section-number">7.2</span> è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆï¼Ÿ</h3>
<p>Luongçš„å·¥ä½œå®Œæˆäº†å¯¹Seq2Seq Attentionçš„ç³»ç»Ÿæ€§æ¢ç´¢ï¼Œç¡®ç«‹äº†ä¸€äº›æœ€ä½³å®è·µï¼ˆå¦‚ç‚¹ç§¯æ³¨æ„åŠ›çš„æ•ˆç‡ä¼˜åŠ¿ï¼‰ã€‚ä½†æ›´æ·±å±‚çš„é—®é¢˜æµ®ç°ï¼š</p>
<p><strong>èƒ½å¦è®©Attentionç‹¬ç«‹äºRNNï¼Ÿ</strong></p>
<p>å¦‚æœAttentionå¦‚æ­¤æœ‰æ•ˆï¼Œä¸ºä»€ä¹ˆè¿˜éœ€è¦RNNï¼Ÿèƒ½å¦è®¾è®¡ä¸€ä¸ªå®Œå…¨åŸºäºAttentionçš„æ¶æ„ï¼Ÿ</p>
<p><strong>èƒ½å¦è®©åºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®ç›¸äº’å…³æ³¨ï¼Ÿ</strong></p>
<p>å½“å‰çš„Attentionæ˜¯â€è·¨åºåˆ—â€çš„ï¼ˆè§£ç å™¨å…³æ³¨ç¼–ç å™¨ï¼‰ã€‚å¦‚æœè®©åŒä¸€åºåˆ—å†…çš„ä½ç½®ç›¸äº’å…³æ³¨â€”â€”è¿™å°±æ˜¯<strong>Self-Attention</strong>â€”â€”ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ</p>
<p>è¿™äº›é—®é¢˜çš„ç­”æ¡ˆï¼Œå°†åœ¨æ¥ä¸‹æ¥çš„ä¸¤ç« æ­æ™“ï¼šç¬¬7ç« å°†ä»‹ç»Self-Attentionçš„è¯ç”Ÿï¼Œç¬¬8ç« å°†ä»‹ç»é©å‘½æ€§çš„Transformeræ¶æ„â€”â€”â€œAttention Is All You Needâ€ã€‚</p>
<blockquote class="blockquote">
<p>ä»åŠ æ€§åˆ°ä¹˜æ€§ï¼Œä»å…¨å±€åˆ°å±€éƒ¨ï¼ŒLuongçš„æ¢ç´¢ä¸ºAttentionæœºåˆ¶å»ºç«‹äº†ç†è®ºå’Œå®è·µçš„åŸºç¡€ã€‚ä½†çœŸæ­£çš„é©å‘½è¿˜åœ¨åé¢ï¼šå½“ç ”ç©¶è€…æ„è¯†åˆ°<strong>æ³¨æ„åŠ›æœ¬èº«å°±å¯ä»¥æˆä¸ºæ¶æ„çš„æ ¸å¿ƒ</strong>ï¼Œæ·±åº¦å­¦ä¹ çš„å†å²ç¿»å¼€äº†æ–°çš„ä¸€é¡µã€‚</p>
</blockquote>
<hr>
</section>
</section>
<section id="æœ¬ç« å°ç»“" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="æœ¬ç« å°ç»“"><span class="header-section-number">8</span> æœ¬ç« å°ç»“</h2>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>æ ¸å¿ƒè¦ç‚¹
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>é—®é¢˜</strong>ï¼šBahdanauçš„åŠ æ€§æ³¨æ„åŠ›æœ‰æ•ˆä½†è®¡ç®—è¾ƒæ…¢ï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´è¿˜æœ‰å¾ˆå¤šæœªæ¢ç´¢çš„é€‰æ‹©</li>
<li><strong>æ´å¯Ÿ</strong>ï¼šç‚¹ç§¯æ³¨æ„åŠ›å¯ä»¥ç”¨ç®€å•çš„å‘é‡å†…ç§¯è®¡ç®—ç›¸å…³æ€§ï¼Œå¤§å¹…æé«˜è®¡ç®—æ•ˆç‡ï¼›å±€éƒ¨æ³¨æ„åŠ›å¯ä»¥å‡å°‘é•¿åºåˆ—çš„è®¡ç®—å¼€é”€</li>
<li><strong>æ–¹æ³•</strong>ï¼šLuongç³»ç»Ÿæ¯”è¾ƒäº†dot/general/concatä¸‰ç§å¯¹é½å‡½æ•°ï¼Œä»¥åŠglobal/localä¸¤ç§èŒƒå›´ç­–ç•¥</li>
<li><strong>æ„ä¹‰</strong>ï¼šç¡®ç«‹äº†ç‚¹ç§¯æ³¨æ„åŠ›çš„æ•ˆç‡ä¼˜åŠ¿ï¼Œä¸ºåæ¥Transformerçš„Scaled Dot-Product Attentionå¥ å®šåŸºç¡€</li>
</ul>
</div>
</div>
<section id="å…³é”®å…¬å¼é€ŸæŸ¥" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="å…³é”®å…¬å¼é€ŸæŸ¥"><span class="header-section-number">8.1</span> å…³é”®å…¬å¼é€ŸæŸ¥</h3>
<p><strong>Dot-Product Attention</strong>ï¼š</p>
<p><span class="math display">\[
\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{s}^\top \mathbf{h}
\]</span></p>
<p><strong>General Attention</strong>ï¼š</p>
<p><span class="math display">\[
\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{s}^\top \mathbf{W}_a \mathbf{h}
\]</span></p>
<p><strong>Concat (Additive) Attention</strong>ï¼š</p>
<p><span class="math display">\[
\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{v}_a^\top \tanh(\mathbf{W}_a [\mathbf{s}; \mathbf{h}])
\]</span></p>
<p><strong>Local Attentionä½ç½®é¢„æµ‹</strong>ï¼š</p>
<p><span class="math display">\[
p_i = T_x \cdot \sigma(\mathbf{v}_p^\top \tanh(\mathbf{W}_p \mathbf{s}_i))
\]</span></p>
<hr>
</section>
</section>
<section id="æ€è€ƒé¢˜" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="æ€è€ƒé¢˜"><span class="header-section-number">9</span> æ€è€ƒé¢˜</h2>
<ol type="1">
<li><p><strong>[æ¦‚å¿µç†è§£]</strong> ç‚¹ç§¯æ³¨æ„åŠ›å’ŒåŠ æ€§æ³¨æ„åŠ›åœ¨è¡¨è¾¾èƒ½åŠ›ä¸Šæœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿè®¾è®¡ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œå±•ç¤ºåŠ æ€§æ³¨æ„åŠ›èƒ½å­¦ä¹ è€Œç‚¹ç§¯æ³¨æ„åŠ›æ— æ³•å­¦ä¹ çš„ç›¸å…³æ€§æ¨¡å¼ã€‚</p></li>
<li><p><strong>[æ•°å­¦æ¨å¯¼]</strong> è¯æ˜ï¼šå½“ <span class="math inline">\(\mathbf{W}_a\)</span> æ˜¯å•ä½çŸ©é˜µæ—¶ï¼ŒGeneral Attentioné€€åŒ–ä¸ºDot-Product Attentionã€‚æ›´ä¸€èˆ¬åœ°ï¼Œå¦‚æœ <span class="math inline">\(\mathbf{W}_a = \mathbf{U}\mathbf{V}^\top\)</span>ï¼ˆç§©-<span class="math inline">\(r\)</span>åˆ†è§£ï¼‰ï¼Œè¿™å¯¹æ³¨æ„åŠ›æ¨¡å¼æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ</p></li>
<li><p><strong><a href="#å·¥ç¨‹å®è·µ">å·¥ç¨‹å®è·µ</a></strong> å®ç°ä¸€ä¸ªæ”¯æŒå¤šå¤´ï¼ˆmulti-headï¼‰çš„Luong Attentionã€‚æ¯ä¸ªå¤´ä½¿ç”¨ä¸åŒçš„ <span class="math inline">\(\mathbf{W}_a\)</span>ï¼Œæœ€åæ‹¼æ¥æ‰€æœ‰å¤´çš„è¾“å‡ºã€‚å¯¹æ¯”å•å¤´å’Œå¤šå¤´åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</p></li>
<li><p><strong>[æ‰¹åˆ¤æ€è€ƒ]</strong> Local Attentionå‡è®¾å¯¹é½æ˜¯å¤§è‡´å•è°ƒçš„ï¼ˆæºå’Œç›®æ ‡çš„ä½ç½®å¯¹åº”ï¼‰ã€‚å¯¹äºå“ªäº›è¯­è¨€å¯¹æˆ–ä»»åŠ¡ï¼Œè¿™ä¸ªå‡è®¾ä¼šä¸¥é‡å¤±æ•ˆï¼Ÿèƒ½å¦è®¾è®¡ä¸€ç§â€éå•è°ƒå±€éƒ¨æ³¨æ„åŠ›â€ï¼Ÿ</p></li>
<li><p><strong>[å¼€æ”¾é—®é¢˜]</strong> Hard Attentionè™½ç„¶è®­ç»ƒå›°éš¾ï¼Œä½†å®ƒæœ‰ä¸€ä¸ªä¼˜åŠ¿ï¼šç¨€ç–æ€§å¯ä»¥æé«˜å¯è§£é‡Šæ€§ã€‚æœ‰æ²¡æœ‰æ–¹æ³•æ—¢ä¿æŒSoft Attentionçš„å¯å¾®åˆ†æ€§ï¼Œåˆèƒ½è·å¾—æ¥è¿‘Hard Attentionçš„ç¨€ç–æ€§ï¼Ÿï¼ˆæç¤ºï¼šè€ƒè™‘ç¨€ç–softmaxã€Gumbel-softmaxï¼‰</p></li>
</ol>
<hr>
</section>
<section id="å»¶ä¼¸é˜…è¯»" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="å»¶ä¼¸é˜…è¯»"><span class="header-section-number">10</span> å»¶ä¼¸é˜…è¯»</h2>
<section id="æ ¸å¿ƒè®ºæ–‡å¿…è¯»" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="æ ¸å¿ƒè®ºæ–‡å¿…è¯»"><span class="header-section-number">10.1</span> æ ¸å¿ƒè®ºæ–‡ï¼ˆå¿…è¯»ï¼‰</h3>
<ul>
<li><strong>[Luong et al., 2015] Effective Approaches to Attention-based Neural Machine Translation</strong>
<ul>
<li>æœ¬ç« çš„æ ¸å¿ƒè®ºæ–‡ï¼Œç³»ç»Ÿæ¯”è¾ƒä¸åŒæ³¨æ„åŠ›å˜ä½“</li>
<li>é‡ç‚¹è¯»ï¼šSection 3ï¼ˆGlobal vs Localï¼‰ã€Section 4ï¼ˆå®éªŒå¯¹æ¯”ï¼‰</li>
<li>arXiv: <a href="https://arxiv.org/abs/1508.04025">1508.04025</a></li>
</ul></li>
</ul>
</section>
<section id="ç†è®ºåŸºç¡€" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="ç†è®ºåŸºç¡€"><span class="header-section-number">10.2</span> ç†è®ºåŸºç¡€</h3>
<ul>
<li><strong>[Bahdanau et al., 2015] Neural Machine Translation by Jointly Learning to Align and Translate</strong>
<ul>
<li>ä¸Šä¸€ç« çš„æ ¸å¿ƒï¼ŒAttentionçš„å¼€å±±ä¹‹ä½œ</li>
<li>arXiv: <a href="https://arxiv.org/abs/1409.0473">1409.0473</a></li>
</ul></li>
</ul>
</section>
<section id="åç»­å‘å±•" class="level3" data-number="10.3">
<h3 data-number="10.3" class="anchored" data-anchor-id="åç»­å‘å±•"><span class="header-section-number">10.3</span> åç»­å‘å±•</h3>
<ul>
<li><strong>[Vaswani et al., 2017] Attention Is All You Need</strong>
<ul>
<li>æå‡ºScaled Dot-Product Attentionå’ŒMulti-Head Attention</li>
<li>å®Œå…¨æŠ›å¼ƒRNNï¼Œåªç”¨Attentionæ„å»ºæ¨¡å‹</li>
<li>arXiv: <a href="https://arxiv.org/abs/1706.03762">1706.03762</a></li>
</ul></li>
<li><strong>[Xu et al., 2015] Show, Attend and Tell</strong>
<ul>
<li>Hard Attentionåœ¨å›¾åƒæè¿°ä¸­çš„åº”ç”¨</li>
<li>å¯¹æ¯”Softå’ŒHard Attentionçš„æ•ˆæœ</li>
<li>arXiv: <a href="https://arxiv.org/abs/1502.03044">1502.03044</a></li>
</ul></li>
</ul>
</section>
<section id="æŠ€æœ¯æŠ¥å‘Š" class="level3" data-number="10.4">
<h3 data-number="10.4" class="anchored" data-anchor-id="æŠ€æœ¯æŠ¥å‘Š"><span class="header-section-number">10.4</span> æŠ€æœ¯æŠ¥å‘Š</h3>
<ul>
<li><strong>[Britz et al., 2017] Massive Exploration of Neural Machine Translation Architectures</strong>
<ul>
<li>å¤§è§„æ¨¡å¯¹æ¯”NMTçš„å„ç§è®¾è®¡é€‰æ‹©</li>
<li>åŒ…æ‹¬æ³¨æ„åŠ›å˜ä½“çš„å®è¯å¯¹æ¯”</li>
<li>arXiv: <a href="https://arxiv.org/abs/1703.03906">1703.03906</a></li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="å†å²æ³¨è„š" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="å†å²æ³¨è„š"><span class="header-section-number">11</span> å†å²æ³¨è„š</h2>
<p>Luongçš„è®ºæ–‡å‘è¡¨äº2015å¹´EMNLPï¼Œè·ç¦»Bahdanauçš„è®ºæ–‡ä»…ä¸€å¹´ã€‚åœ¨è¿™çŸ­çŸ­ä¸€å¹´é‡Œï¼ŒAttentionè¿…é€Ÿæˆä¸ºNMTçš„æ ‡å‡†é…ç½®ï¼Œå„ç§å˜ä½“å±‚å‡ºä¸ç©·ã€‚Luongçš„å·¥ä½œä¹‹æ‰€ä»¥é‡è¦ï¼Œä¸ä»…åœ¨äºæå‡ºäº†æ–°çš„å˜ä½“ï¼Œæ›´åœ¨äºå®ƒ<strong>ç³»ç»Ÿæ€§åœ°æ¯”è¾ƒå’Œæ€»ç»“</strong>äº†å½“æ—¶çš„å„ç§æ–¹æ³•ï¼Œä¸ºåæ¥è€…æä¾›äº†æ¸…æ™°çš„è®¾è®¡æŒ‡å—ã€‚</p>
<p>æœ‰è¶£çš„æ˜¯ï¼ŒLuongè®ºæ–‡ä¸­æåˆ°çš„ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆDot-Productï¼‰å› ä¸ºè¿‡äºç®€å•è€Œæ²¡æœ‰å—åˆ°å¤ªå¤šå…³æ³¨ã€‚å½“æ—¶çš„ä¸»æµä»ç„¶æ˜¯å‚æ•°åŒ–çš„å¯¹é½å‡½æ•°ã€‚ä½†ä¸¤å¹´åï¼Œå½“Transformerè®ºæ–‡æå‡ºâ€Scaled Dot-Product Attentionâ€æ—¶ï¼Œç‚¹ç§¯æ³¨æ„åŠ›ç»ˆäºç™»ä¸Šäº†å†å²èˆå°çš„ä¸­å¤®â€”â€”å®ƒä¸ä»…ç®€å•é«˜æ•ˆï¼Œè€Œä¸”åœ¨å¤§è§„æ¨¡è®¾ç½®ä¸‹ä¸æ›´å¤æ‚çš„å¯¹é½å‡½æ•°è¡¨ç°ç›¸å½“ã€‚</p>
<p>ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼ŒLuongçš„è®ºæ–‡æ˜¯Attentionå‘å±•å²ä¸Šçš„ä¸€ä¸ªâ€ä¸­åœºä¼‘æ¯â€â€”â€”å®ƒæ€»ç»“äº†ç¬¬ä¸€é˜¶æ®µçš„æ¢ç´¢ï¼Œä¸ºç¬¬äºŒé˜¶æ®µï¼ˆSelf-Attentionå’ŒTransformerï¼‰çš„é©å‘½é“ºå¹³äº†é“è·¯ã€‚</p>


<!-- -->

</section>

</main> <!-- /main -->
ï»¿<script>

// Simple EN / ä¸­æ–‡ language toggle for posts; robust via meta[quarto:offset]

(function() {

  const KEY = 'siteLang'; // 'en' | 'zh'

  const defaultLang = 'en';

  const POSTS_EN = 'posts_en.html';

  const POSTS_ZH = 'posts_zh.html';

  const TAGS = 'tags.html';



  function currentLang() { try { return localStorage.getItem(KEY) || defaultLang; } catch(e) { return defaultLang; } }

  function setLang(v) { try { localStorage.setItem(KEY, v); } catch(e) {} }

  function offset() {

    const meta = document.querySelector('meta[name="quarto:offset"]');

    const off = meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

    return off;

  }

  function targetFor(lang) { return lang === 'zh' ? POSTS_ZH : POSTS_EN; }

  function goToLang(lang) {

    const off = offset();

    const path = window.location.pathname;

    setLang(lang);

    if (path.endsWith('/' + TAGS) || path.endsWith(TAGS)) {

      window.location.href = off + TAGS;

    } else {

      window.location.href = off + targetFor(lang);

    }

  }

  function updateNavbarPostsLink() {

    const off = offset();

    const href = off + targetFor(currentLang());

    const links = document.querySelectorAll('header .navbar a.nav-link');

    links.forEach((a) => {

      const h = a.getAttribute('href') || '';

      if (h.endsWith(POSTS_EN) || h.endsWith(POSTS_ZH)) a.setAttribute('href', href);

    });

  }

  function mountToggle() {

    const tools = document.querySelector('.quarto-navbar-tools');

    if (!tools) return;

    const wrapper = document.createElement('div');

    wrapper.style.display = 'inline-flex';

    wrapper.style.alignItems = 'center';

    wrapper.style.gap = '0.35rem';

    wrapper.style.marginLeft = '0.35rem';



    const en = document.createElement('a');

    en.href = '';

    en.textContent = 'EN';

    en.className = 'quarto-navigation-tool px-1';

    en.onclick = function(){ goToLang('en'); return false; };



    const sep = document.createElement('span');

    sep.textContent = '|';

    sep.style.opacity = '0.6';



    const zh = document.createElement('a');

    zh.href = '';

    zh.textContent = 'ä¸­æ–‡';

    zh.className = 'quarto-navigation-tool px-1';

    zh.onclick = function(){ goToLang('zh'); return false; };



    const lang = currentLang();

    (lang === 'en' ? en : zh).style.fontWeight = '700';



    wrapper.appendChild(en);

    wrapper.appendChild(sep);

    wrapper.appendChild(zh);

    tools.appendChild(wrapper);

    updateNavbarPostsLink();

  }

  document.addEventListener('DOMContentLoaded', mountToggle);

})();

</script>

<script>

(function(){

  function offset(){

    var meta = document.querySelector('meta[name="quarto:offset"]');

    return meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

  }

  document.addEventListener('DOMContentLoaded', function(){

    var brand = document.querySelector('header .navbar a.navbar-brand');

    if (brand) {

      brand.setAttribute('href', offset() + 'home.html');

    }

  });

})();

</script>



<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "ç¬¬6ç« ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“æ¼”è¿›"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "ä»åŠ æ€§åˆ°ä¹˜æ€§ã€ä»å…¨å±€åˆ°å±€éƒ¨ã€ä»è½¯åˆ°ç¡¬"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ying Zha"</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2026-01-25"</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [NLP, Attention, Luong, æœºå™¨ç¿»è¯‘, Seq2Seq]</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="an">tags:</span><span class="co"> [ä¹˜æ€§æ³¨æ„åŠ›, ç‚¹ç§¯æ³¨æ„åŠ›, Global Attention, Local Attention, Hard Attention, Soft Attention]</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "æ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´ï¼šä»åŠ æ€§åˆ°ä¹˜æ€§ã€ä»å…¨å±€åˆ°å±€éƒ¨ã€ä»è½¯åˆ°ç¡¬ï¼ŒLuongçš„ç³»ç»Ÿæ€§æ¢ç´¢ä¸æ•ˆç‡-è¡¨è¾¾åŠ›æƒè¡¡ã€‚"</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">    css: styles.css</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-cap-location: bottom</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **æ ¸å¿ƒé—®é¢˜**ï¼šBahdanauçš„åŠ æ€§æ³¨æ„åŠ›è™½ç„¶æœ‰æ•ˆï¼Œä½†æ˜¯å¦æœ‰æ›´ç®€æ´ã€æ›´é«˜æ•ˆçš„æ³¨æ„åŠ›è®¡ç®—æ–¹å¼ï¼Ÿä¸åŒçš„è®¾è®¡é€‰æ‹©ä¼šå¸¦æ¥æ€æ ·çš„æƒè¡¡ï¼Ÿ</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **å†å²åæ ‡**ï¼š2015 </span><span class="pp">|</span><span class="at"> Luong, Pham, Manning </span><span class="pp">|</span><span class="at"> æ³¨æ„åŠ›æœºåˆ¶çš„ç³»ç»Ÿæ€§æ¢ç´¢</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## ä»ä¸Šä¸€ç« è¯´èµ·</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>ä¸Šä¸€ç« æˆ‘ä»¬è§è¯äº†Attentionæœºåˆ¶çš„è¯ç”Ÿã€‚Bahdanauç­‰äººé€šè¿‡è®©è§£ç å™¨åœ¨æ¯ä¸€æ­¥éƒ½èƒ½"å›å¤´çœ‹"ç¼–ç å™¨çš„æ‰€æœ‰ä½ç½®ï¼Œå½»åº•æ‰“ç ´äº†Seq2Seqçš„ä¿¡æ¯ç“¶é¢ˆã€‚è¿™ä¸ªçªç ´æ€§çš„æƒ³æ³•è¿…é€Ÿåœ¨æœºå™¨ç¿»è¯‘é¢†åŸŸå¼•å‘äº†è¿é”ååº”â€”â€”å¦‚æœAttentionå¦‚æ­¤æœ‰æ•ˆï¼Œæ˜¯å¦è¿˜æœ‰å…¶ä»–æ–¹å¼æ¥è®¡ç®—"æ³¨æ„åŠ›"ï¼Ÿ</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>Bahdanauçš„è®¾è®¡ä½¿ç”¨äº†ä¸€ä¸ª**åŠ æ€§**çš„å¯¹é½å‡½æ•°ï¼šå…ˆå°†è§£ç å™¨çŠ¶æ€å’Œç¼–ç å™¨çŠ¶æ€åˆ†åˆ«ç»è¿‡çº¿æ€§å˜æ¢ï¼Œç„¶åç›¸åŠ ï¼Œæœ€åé€šè¿‡ä¸€ä¸ªå•å±‚ç½‘ç»œå¾—åˆ°æ ‡é‡åˆ†æ•°ã€‚è¿™ä¸ªè®¾è®¡æœ‰æ•ˆï¼Œä½†è®¡ç®—é‡ä¸å°â€”â€”æ¯æ¬¡è®¡ç®—å¯¹é½åˆ†æ•°éƒ½éœ€è¦ä¸€ä¸ªå‰é¦ˆç½‘ç»œã€‚ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æµ®ç°ï¼šèƒ½å¦ç”¨æ›´ç®€å•çš„æ“ä½œï¼Œæ¯”å¦‚ç›´æ¥è®¡ç®—å‘é‡çš„ç‚¹ç§¯ï¼Œæ¥è¡¡é‡ä¸¤ä¸ªçŠ¶æ€çš„ç›¸å…³æ€§ï¼Ÿ</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>2015å¹´ï¼Œæ–¯å¦ç¦å¤§å­¦çš„Luongã€Phamå’ŒManningå‘è¡¨äº†ä¸€ç¯‡ç³»ç»Ÿæ€§çš„ç ”ç©¶ï¼Œæ¢ç´¢äº†å¤šç§æ³¨æ„åŠ›æœºåˆ¶çš„å˜ä½“ã€‚ä»–ä»¬ä¸ä»…æå‡ºäº†è®¡ç®—æ•ˆç‡æ›´é«˜çš„**ä¹˜æ€§æ³¨æ„åŠ›ï¼ˆmultiplicative attentionï¼‰**ï¼Œè¿˜æ¢è®¨äº†**å…¨å±€æ³¨æ„åŠ›**ä¸**å±€éƒ¨æ³¨æ„åŠ›**çš„æƒè¡¡ã€ä¸åŒå¯¹é½å‡½æ•°çš„å¯¹æ¯”ï¼Œä»¥åŠæ³¨æ„åŠ›åœ¨è§£ç å™¨ä¸­çš„æœ€ä½³ä½¿ç”¨ä½ç½®ã€‚</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ğŸ’¡ **æœ¬ç« æ ¸å¿ƒæ´å¯Ÿ**ï¼šæ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´è¿œæ¯”æƒ³è±¡ä¸­ä¸°å¯Œã€‚**åŠ æ€§ vs ä¹˜æ€§**å†³å®šäº†è¡¨è¾¾èƒ½åŠ›ä¸è®¡ç®—æ•ˆç‡çš„æƒè¡¡ï¼›**å…¨å±€ vs å±€éƒ¨**å†³å®šäº†é•¿åºåˆ—å¤„ç†çš„ç­–ç•¥ï¼›**è½¯ vs ç¡¬**å†³å®šäº†ç«¯åˆ°ç«¯å¯è®­ç»ƒæ€§ã€‚ç†è§£è¿™äº›è®¾è®¡é€‰æ‹©ï¼Œæ˜¯ç†è§£åæ¥Transformerä¸­Scaled Dot-Product Attentionçš„å…³é”®ã€‚</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="fu">## é—®é¢˜çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a><span class="fu">### é—®é¢˜çš„ç²¾ç¡®å®šä¹‰</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>Bahdanau Attentionè™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨å®è·µä¸­é¢ä¸´å‡ ä¸ªè®¾è®¡é—®é¢˜ï¼š</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>**è®¡ç®—æ•ˆç‡é—®é¢˜**ï¼šåŠ æ€§æ³¨æ„åŠ›éœ€è¦ä¸ºæ¯å¯¹ï¼ˆè§£ç å™¨çŠ¶æ€ï¼Œç¼–ç å™¨çŠ¶æ€ï¼‰è®¡ç®—ä¸€ä¸ªå‰é¦ˆç½‘ç»œçš„è¾“å‡ºï¼š</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>e_{ij} = \mathbf{v}_a^\top \tanh(\mathbf{W}_a \mathbf{s}_{i-1} + \mathbf{U}_a \mathbf{h}_j)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>è¿™æ¶‰åŠä¸¤ä¸ªçŸ©é˜µä¹˜æ³•ï¼ˆ$\mathbf{W}_a \mathbf{s}$ å’Œ $\mathbf{U}_a \mathbf{h}$ï¼‰ã€ä¸€ä¸ªéçº¿æ€§æ¿€æ´»ï¼ˆ$\tanh$ï¼‰ã€ä¸€ä¸ªå‘é‡ç‚¹ç§¯ï¼ˆ$\mathbf{v}_a^\top (\cdot)$ï¼‰ã€‚å½“åºåˆ—å¾ˆé•¿æ—¶ï¼Œè¿™ä¸ªè®¡ç®—é‡æ˜¯å¯è§‚çš„ã€‚</span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>**è®¾è®¡ç©ºé—´æœªå……åˆ†æ¢ç´¢**ï¼šBahdanauåšäº†ä¸€ç³»åˆ—è®¾è®¡é€‰æ‹©â€”â€”ä½¿ç”¨åŠ æ€§å¯¹é½ã€åœ¨æ¯ä¸ªè§£ç æ­¥ä¹‹å‰è®¡ç®—æ³¨æ„åŠ›ã€å…³æ³¨æ‰€æœ‰æºä½ç½®â€”â€”ä½†è¿™äº›é€‰æ‹©æ˜¯å¦æœ€ä¼˜ï¼Ÿæœ‰æ²¡æœ‰æ›´å¥½çš„æ›¿ä»£æ–¹æ¡ˆï¼Ÿ</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>**é•¿åºåˆ—çš„æŒ‘æˆ˜**ï¼šå¯¹äºå¾ˆé•¿çš„æºåºåˆ—ï¼Œè®¡ç®—å¯¹æ‰€æœ‰ä½ç½®çš„æ³¨æ„åŠ›å¯èƒ½æ˜¯æµªè´¹çš„ã€‚ç›´è§‰ä¸Šï¼Œåœ¨ç¿»è¯‘æŸä¸ªè¯æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦å…³æ³¨æºåºåˆ—çš„ä¸€å°éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯å…¨éƒ¨ã€‚èƒ½å¦åªè®¡ç®—"å±€éƒ¨"çš„æ³¨æ„åŠ›ï¼Ÿ</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="fu">### æˆ‘ä»¬éœ€è¦ä»€ä¹ˆæ ·çš„è§£å†³æ–¹æ¡ˆï¼Ÿ</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>ä¸€ä¸ªç³»ç»Ÿæ€§çš„æ¢ç´¢åº”è¯¥å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**å¯¹é½å‡½æ•°**ï¼šé™¤äº†åŠ æ€§ï¼Œè¿˜æœ‰å“ªäº›æ–¹å¼è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ç›¸å…³æ€§ï¼Ÿå®ƒä»¬çš„è¡¨è¾¾èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡å¦‚ä½•æƒè¡¡ï¼Ÿ</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**æ³¨æ„åŠ›èŒƒå›´**ï¼šæ˜¯å¦éœ€è¦å…³æ³¨æ‰€æœ‰ä½ç½®ï¼Ÿèƒ½å¦åªå…³æ³¨ä¸€ä¸ªå±€éƒ¨çª—å£ï¼Ÿ</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**ä½¿ç”¨ä½ç½®**ï¼šæ³¨æ„åŠ›åº”è¯¥åœ¨è§£ç çš„å“ªä¸ªé˜¶æ®µä½¿ç”¨ï¼Ÿæ˜¯åœ¨è®¡ç®—è§£ç å™¨çŠ¶æ€ä¹‹å‰ï¼Œè¿˜æ˜¯ä¹‹åï¼Ÿ</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**è½¯ vs ç¡¬**ï¼šæ˜¯å¦å¯ä»¥ç”¨ç¡®å®šæ€§çš„"ç¡¬"é€‰æ‹©æ›¿ä»£æ¦‚ç‡åˆ†å¸ƒçš„"è½¯"é€‰æ‹©ï¼Ÿ</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a><span class="fu">## æ ¸å¿ƒæ€æƒ³ä¸ç›´è§‰</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### Luong Attentionï¼šä¹˜æ€§æ›¿ä»£åŠ æ€§</span></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>Luongç­‰äººæå‡ºçš„æ ¸å¿ƒæ”¹è¿›æ˜¯ç”¨**ä¹˜æ€§ï¼ˆmultiplicativeï¼‰**æ“ä½œæ›¿ä»£åŠ æ€§æ“ä½œæ¥è®¡ç®—å¯¹é½åˆ†æ•°ã€‚æœ€ç®€å•çš„å½¢å¼æ˜¯ç›´æ¥è®¡ç®—ç‚¹ç§¯ï¼š</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>e_{ij} = \mathbf{s}_i^\top \mathbf{h}_j</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>è¿™è¢«ç§°ä¸º**ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆdot-product attentionï¼‰**ã€‚ä¸Bahdanauçš„åŠ æ€§æ³¨æ„åŠ›ç›¸æ¯”ï¼Œå®ƒæ²¡æœ‰ä»»ä½•å¯å­¦ä¹ å‚æ•°â€”â€”åªæ˜¯ä¸¤ä¸ªå‘é‡çš„å†…ç§¯ã€‚</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>ç›´è§‰ä¸Šï¼Œç‚¹ç§¯è¡¡é‡çš„æ˜¯ä¸¤ä¸ªå‘é‡çš„"ç›¸ä¼¼åº¦"ã€‚å¦‚æœè§£ç å™¨çŠ¶æ€ $\mathbf{s}_i$ å’Œç¼–ç å™¨çŠ¶æ€ $\mathbf{h}_j$ æŒ‡å‘ç›¸ä¼¼çš„æ–¹å‘ï¼Œç‚¹ç§¯å°±å¤§ï¼›å¦‚æœå®ƒä»¬æ­£äº¤ï¼Œç‚¹ç§¯å°±æ˜¯é›¶ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼šæ‰¾åˆ°ä¸å½“å‰è§£ç çŠ¶æ€æœ€"ç›¸å…³"çš„ç¼–ç ä½ç½®ã€‚</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### ä¸‰ç§å¯¹é½å‡½æ•°çš„å¯¹æ¯”</span></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>Luongçš„è®ºæ–‡ç³»ç»Ÿæ¯”è¾ƒäº†ä¸‰ç§å¯¹é½å‡½æ•°ï¼š</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> åç§° <span class="pp">|</span> å…¬å¼ <span class="pp">|</span> å‚æ•° <span class="pp">|</span> è®¡ç®—æ•ˆç‡ <span class="pp">|</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|------|------|----------|</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Dot** <span class="pp">|</span> $\mathbf{s}^\top \mathbf{h}$ <span class="pp">|</span> æ—  <span class="pp">|</span> æœ€å¿« <span class="pp">|</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **General** <span class="pp">|</span> $\mathbf{s}^\top \mathbf{W}_a \mathbf{h}$ <span class="pp">|</span> $\mathbf{W}_a$ <span class="pp">|</span> ä¸­ç­‰ <span class="pp">|</span></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Concat** <span class="pp">|</span> $\mathbf{v}_a^\top \tanh(\mathbf{W}_a <span class="co">[</span><span class="ot">\mathbf{s}; \mathbf{h}</span><span class="co">]</span>)$ <span class="pp">|</span> $\mathbf{v}_a, \mathbf{W}_a$ <span class="pp">|</span> æœ€æ…¢ <span class="pp">|</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>**Dotï¼ˆç‚¹ç§¯ï¼‰**ï¼šæœ€ç®€å•ï¼Œè®¡ç®—æœ€å¿«ï¼Œä½†è¦æ±‚è§£ç å™¨å’Œç¼–ç å™¨çš„éšè—ç»´åº¦å¿…é¡»ç›¸åŒã€‚</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>**Generalï¼ˆä¸€èˆ¬å½¢å¼ï¼‰**ï¼šå¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„çŸ©é˜µ $\mathbf{W}_a$ï¼Œå¯ä»¥å¤„ç†ä¸åŒç»´åº¦çš„çŠ¶æ€ï¼Œä¹Ÿå¢åŠ äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚è¿™å®é™…ä¸Šæ˜¯åœ¨é—®ï¼š"$\mathbf{s}$ å’Œ $\mathbf{W}_a \mathbf{h}$ï¼ˆ$\mathbf{h}$ çš„ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼‰æœ‰å¤šç›¸ä¼¼ï¼Ÿ"</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>**Concatï¼ˆæ‹¼æ¥ï¼‰**ï¼šè¿™å°±æ˜¯Bahdanauçš„åŠ æ€§æ³¨æ„åŠ›ï¼Œå°†ä¸¤ä¸ªå‘é‡æ‹¼æ¥åé€šè¿‡ä¸€ä¸ªå•å±‚ç½‘ç»œã€‚è¡¨è¾¾èƒ½åŠ›æœ€å¼ºï¼Œä½†è®¡ç®—æœ€æ…¢ã€‚</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a><span class="fu">### å¦ä¸€ä¸ªå…³é”®å·®å¼‚ï¼šæ³¨æ„åŠ›çš„ä½¿ç”¨ä½ç½®</span></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>é™¤äº†å¯¹é½å‡½æ•°çš„ä¸åŒï¼ŒLuongè¿˜æŒ‡å‡ºäº†å¦ä¸€ä¸ªé‡è¦å·®å¼‚ï¼š**æ³¨æ„åŠ›åº”è¯¥åœ¨è§£ç å™¨çš„ä»€ä¹ˆä½ç½®ä½¿ç”¨ï¼Ÿ**</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>**Bahdanauçš„æ–¹å¼**ï¼šå…ˆè®¡ç®—æ³¨æ„åŠ›ï¼Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡ $\mathbf{c}_i$ï¼Œç„¶åå°† $\mathbf{c}_i$ å’Œä¸Šä¸€æ­¥è¾“å‡º $y_{i-1}$ ä¸€èµ·è¾“å…¥RNNï¼Œè®¡ç®—æ–°çš„éšè—çŠ¶æ€ $\mathbf{s}_i$ã€‚</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>\mathbf{s}_i = f(\mathbf{s}_{i-1}, y_{i-1}, \mathbf{c}_i)</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>**Luongçš„æ–¹å¼**ï¼šå…ˆç”¨RNNè®¡ç®—æ–°çš„éšè—çŠ¶æ€ $\mathbf{s}_i$ï¼Œç„¶ååŸºäº $\mathbf{s}_i$ è®¡ç®—æ³¨æ„åŠ›ï¼Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡ $\mathbf{c}_i$ï¼Œæœ€åå°†ä¸¤è€…ç»“åˆç”Ÿæˆè¾“å‡ºã€‚</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>\mathbf{s}_i = f(\mathbf{s}_{i-1}, y_{i-1})</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a>\mathbf{c}_i = \text{Attention}(\mathbf{s}_i, \mathbf{H})</span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>\tilde{\mathbf{s}}_i = \tanh(\mathbf{W}_c <span class="co">[</span><span class="ot">\mathbf{c}_i; \mathbf{s}_i</span><span class="co">]</span>)</span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>è¿™çœ‹èµ·æ¥æ˜¯ä¸ªç»†èŠ‚å·®å¼‚ï¼Œä½†Luongçš„æ–¹å¼æ›´åŠ æ¨¡å—åŒ–â€”â€”RNNå’ŒAttentionæ˜¯åˆ†ç¦»çš„ï¼Œä¾¿äºåˆ†æå’Œè°ƒè¯•ã€‚</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a><span class="fu">## æŠ€æœ¯ç»†èŠ‚</span></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a><span class="fu">### Luong Attentionçš„ä¸‰ç§å˜ä½“</span></span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>è®©æˆ‘ä»¬è¯¦ç»†çœ‹çœ‹ä¸‰ç§å¯¹é½å‡½æ•°çš„æ•°å­¦å½¢å¼å’Œå®ç°ã€‚</span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>**å˜ä½“1ï¼šDot-Product Attention**</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{s}_i^\top \mathbf{h}_j</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>è¿™æ˜¯æœ€ç®€å•çš„å½¢å¼ã€‚ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯å¯ä»¥ç”¨çŸ©é˜µä¹˜æ³•é«˜æ•ˆå®ç°ï¼šå¦‚æœæˆ‘ä»¬æœ‰æ‰€æœ‰ç¼–ç å™¨çŠ¶æ€ç»„æˆçš„çŸ©é˜µ $\mathbf{H} \in \mathbb{R}^{T_x \times d}$ï¼Œé‚£ä¹ˆæ‰€æœ‰å¯¹é½åˆ†æ•°å¯ä»¥ä¸€æ¬¡è®¡ç®—ï¼š</span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>\mathbf{e}_i = \mathbf{H} \mathbf{s}_i \in \mathbb{R}^{T_x}</span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>**å˜ä½“2ï¼šGeneral Attention**</span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{s}_i^\top \mathbf{W}_a \mathbf{h}_j</span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a>å…¶ä¸­ $\mathbf{W}_a \in \mathbb{R}^{d_s \times d_h}$ æ˜¯å¯å­¦ä¹ å‚æ•°ã€‚è¿™å…è®¸è§£ç å™¨å’Œç¼–ç å™¨æœ‰ä¸åŒçš„éšè—ç»´åº¦ï¼ŒåŒæ—¶è®©æ¨¡å‹å­¦ä¹ ä¸€ä¸ª"ç›¸ä¼¼åº¦åº¦é‡"ã€‚</span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a>**å˜ä½“3ï¼šConcat Attentionï¼ˆä¸Bahdanauç±»ä¼¼ï¼‰**</span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}_i, \mathbf{h}_j) = \mathbf{v}_a^\top \tanh(\mathbf{W}_a <span class="co">[</span><span class="ot">\mathbf{s}_i; \mathbf{h}_j</span><span class="co">]</span>)</span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a>å…¶ä¸­ $<span class="co">[</span><span class="ot">\mathbf{s}_i; \mathbf{h}_j</span><span class="co">]</span>$ è¡¨ç¤ºå‘é‡æ‹¼æ¥ã€‚è¿™æ˜¯æœ€å…·è¡¨è¾¾èƒ½åŠ›çš„å½¢å¼ï¼Œå› ä¸ºå®ƒå¯ä»¥å­¦ä¹ ä»»æ„çš„å¯¹é½å‡½æ•°ã€‚</span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a><span class="fu">## Algorithm: Luong Attention Variants (Luong et al., 2015)</span></span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> luong_attention(decoder_state, encoder_outputs, method<span class="op">=</span><span class="st">'dot'</span>, W_a<span class="op">=</span><span class="va">None</span>, v_a<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong æ³¨æ„åŠ›æœºåˆ¶çš„ä¸‰ç§å˜ä½“</span></span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a><span class="co">    å‚æ•°:</span></span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: è§£ç å™¨å½“å‰éšè—çŠ¶æ€ [batch, dec_hidden]</span></span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: ç¼–ç å™¨æ‰€æœ‰éšè—çŠ¶æ€ [batch, src_len, enc_hidden]</span></span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a><span class="co">        method: 'dot', 'general', æˆ– 'concat'</span></span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a><span class="co">        W_a: å¯å­¦ä¹ å‚æ•°ï¼ˆgeneralå’Œconcatéœ€è¦ï¼‰</span></span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a><span class="co">        v_a: å¯å­¦ä¹ å‚æ•°ï¼ˆconcatéœ€è¦ï¼‰</span></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a><span class="co">    è¿”å›:</span></span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a><span class="co">        context: ä¸Šä¸‹æ–‡å‘é‡ [batch, enc_hidden]</span></span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a><span class="co">        attention_weights: æ³¨æ„åŠ›æƒé‡ [batch, src_len]</span></span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> method <span class="op">==</span> <span class="st">'dot'</span>:</span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç‚¹ç§¯: s^T h</span></span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>        <span class="co"># [batch, dec_hidden] @ [batch, enc_hidden, src_len] -&gt; [batch, src_len]</span></span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a>                          encoder_outputs.transpose(<span class="dv">1</span>, <span class="dv">2</span>)).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸€èˆ¬å½¢å¼: s^T W h</span></span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å…ˆè®¡ç®— W @ h: [batch, src_len, dec_hidden]</span></span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a>        transformed <span class="op">=</span> encoder_outputs <span class="op">@</span> W_a.T</span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>                          transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‹¼æ¥å½¢å¼: v^T tanh(W [s; h])</span></span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a>        <span class="co"># æ‰©å±• decoder_state åˆ°æ‰€æœ‰ä½ç½®</span></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a>        s_expanded <span class="op">=</span> decoder_state.unsqueeze(<span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, encoder_outputs.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a>        concat <span class="op">=</span> torch.cat([s_expanded, encoder_outputs], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> v_a <span class="op">@</span> torch.tanh(concat <span class="op">@</span> W_a.T).transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> scores.squeeze(<span class="dv">1</span>)</span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Softmax å½’ä¸€åŒ–</span></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a>    attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a>    <span class="co"># åŠ æƒæ±‚å’Œ</span></span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a>    context <span class="op">=</span> torch.bmm(attention_weights.unsqueeze(<span class="dv">1</span>), encoder_outputs).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> context, attention_weights</span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>*Source: Luong, Pham, &amp; Manning (2015) "Effective Approaches to Attention-based Neural Machine Translation", EMNLP 2015. [arXiv:1508.04025](https://arxiv.org/abs/1508.04025)*</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a><span class="fu">### å®Œæ•´æ•°å€¼ç¤ºä¾‹ï¼šå¯¹æ¯”ä¸‰ç§å¯¹é½å‡½æ•°</span></span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>è®©æˆ‘ä»¬ç”¨åŒä¸€ç»„æ•°æ®ï¼Œæ¯”è¾ƒä¸‰ç§å¯¹é½å‡½æ•°è®¡ç®—å‡ºçš„åˆ†æ•°ã€‚</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a>**è®¾å®š**ï¼š</span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>è§£ç å™¨çŠ¶æ€ï¼š$\mathbf{s} = <span class="co">[</span><span class="ot">0.5, -0.3, 0.8, 0.2</span><span class="co">]</span>^\top$</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ç¼–ç å™¨çŠ¶æ€ï¼ˆ3ä¸ªä½ç½®ï¼‰ï¼š</span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\mathbf{h}_1 = <span class="co">[</span><span class="ot">0.2, 0.4, 0.1, -0.3</span><span class="co">]</span>^\top$</span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\mathbf{h}_2 = <span class="co">[</span><span class="ot">0.6, -0.1, 0.7, 0.3</span><span class="co">]</span>^\top$</span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>$\mathbf{h}_3 = <span class="co">[</span><span class="ot">-0.2, 0.5, 0.3, 0.1</span><span class="co">]</span>^\top$</span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a>**Dot-Product è®¡ç®—**ï¼š</span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a>e_1 = \mathbf{s}^\top \mathbf{h}_1 = 0.5 \times 0.2 + (-0.3) \times 0.4 + 0.8 \times 0.1 + 0.2 \times (-0.3)</span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a>= 0.10 - 0.12 + 0.08 - 0.06 = 0.00</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a>e_2 = \mathbf{s}^\top \mathbf{h}_2 = 0.5 \times 0.6 + (-0.3) \times (-0.1) + 0.8 \times 0.7 + 0.2 \times 0.3</span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>= 0.30 + 0.03 + 0.56 + 0.06 = 0.95</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>e_3 = \mathbf{s}^\top \mathbf{h}_3 = 0.5 \times (-0.2) + (-0.3) \times 0.5 + 0.8 \times 0.3 + 0.2 \times 0.1</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>= -0.10 - 0.15 + 0.24 + 0.02 = 0.01</span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>**Softmax å½’ä¸€åŒ–**ï¼š</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a>\alpha_1 = \frac{e^{0.00}}{e^{0.00} + e^{0.95} + e^{0.01}} = \frac{1.00}{1.00 + 2.59 + 1.01} = \frac{1.00}{4.60} \approx 0.22</span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a>\alpha_2 = \frac{e^{0.95}}{4.60} = \frac{2.59}{4.60} \approx 0.56</span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a>\alpha_3 = \frac{e^{0.01}}{4.60} = \frac{1.01}{4.60} \approx 0.22</span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a>**è§£è¯»**ï¼šä½¿ç”¨ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œæ¨¡å‹å°†56%çš„æ³¨æ„åŠ›æ”¾åœ¨ä½ç½®2ï¼Œè¿™æ˜¯å› ä¸º $\mathbf{h}_2$ ä¸ $\mathbf{s}$ çš„ç‚¹ç§¯æœ€å¤§â€”â€”å®ƒä»¬åœ¨å‘é‡ç©ºé—´ä¸­æœ€"ç›¸ä¼¼"ã€‚</span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a>**General Attention è®¡ç®—**ï¼ˆå‡è®¾ $\mathbf{W}_a$ æ˜¯å•ä½çŸ©é˜µï¼‰ï¼š</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a>å½“ $\mathbf{W}_a = \mathbf{I}$ æ—¶ï¼ŒGeneralé€€åŒ–ä¸ºDot-Productã€‚åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ$\mathbf{W}_a$ å¯ä»¥å­¦ä¹ ä¸€ä¸ªå˜æ¢ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå‘ç°æ›´å¤æ‚çš„ç›¸å…³æ€§æ¨¡å¼ã€‚</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a><span class="fu">### Global vs Local Attention</span></span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a>Luongè¿˜æå‡ºäº†å¦ä¸€ä¸ªé‡è¦çš„è®¾è®¡é€‰æ‹©ï¼š**æ³¨æ„åŠ›çš„èŒƒå›´**ã€‚</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a>**Global Attention**ï¼šå…³æ³¨æ‰€æœ‰æºä½ç½®ã€‚è¿™æ˜¯Bahdanauçš„åšæ³•ï¼Œä¹Ÿæ˜¯ä¸Šé¢è®¨è®ºçš„é»˜è®¤æ–¹å¼ã€‚</span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a>\mathbf{c}_i = \sum_{j=1}^{T_x} \alpha_{ij} \mathbf{h}_j</span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>**Local Attention**ï¼šåªå…³æ³¨æºåºåˆ—çš„ä¸€ä¸ª**çª—å£**ã€‚</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a>æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¯ä¸ªè§£ç æ­¥ï¼Œå…ˆé¢„æµ‹ä¸€ä¸ªå¯¹é½ä½ç½® $p_i$ï¼Œç„¶ååªè®¡ç®—ä»¥ $p_i$ ä¸ºä¸­å¿ƒã€å®½åº¦ä¸º $2D+1$ çš„çª—å£å†…çš„æ³¨æ„åŠ›ã€‚</span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a>\mathbf{c}_i = \sum_{j=p_i-D}^{p_i+D} \alpha_{ij} \mathbf{h}_j</span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a>å¯¹é½ä½ç½® $p_i$ å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼ç¡®å®šï¼š</span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a>**Local-mï¼ˆå•è°ƒï¼‰**ï¼šå‡è®¾æºå’Œç›®æ ‡å¤§è‡´å¯¹é½ï¼Œç®€å•è®¾ç½® $p_i = i$ã€‚</span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a>**Local-pï¼ˆé¢„æµ‹ï¼‰**ï¼šå­¦ä¹ ä¸€ä¸ªå‡½æ•°æ¥é¢„æµ‹ $p_i$ï¼š</span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a>p_i = T_x \cdot \sigma(\mathbf{v}_p^\top \tanh(\mathbf{W}_p \mathbf{s}_i))</span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a>å…¶ä¸­ $\sigma$ æ˜¯sigmoidå‡½æ•°ï¼Œç¡®ä¿ $p_i \in <span class="co">[</span><span class="ot">0, T_x</span><span class="co">]</span>$ã€‚</span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>ä¸ºäº†è®©æ³¨æ„åŠ›åœ¨çª—å£ä¸­å¿ƒé™„è¿‘æ›´é›†ä¸­ï¼ŒLocal Attentionè¿˜å¼•å…¥äº†ä¸€ä¸ªé«˜æ–¯åç½®ï¼š</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a>\alpha_{ij} = \text{align}(\mathbf{s}_i, \mathbf{h}_j) \cdot \exp\left(-\frac{(j - p_i)^2}{2\sigma^2}\right)</span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Luongè®ºæ–‡ä¸­çš„Global vs Local Attentionå¯¹æ¯”ã€‚å·¦è¾¹æ˜¯Global Attentionï¼šè§£ç å™¨çŠ¶æ€ $h_t$ ä¸æ‰€æœ‰æºä½ç½®è®¡ç®—æ³¨æ„åŠ›ï¼Œç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡ $c_t$ã€‚å³è¾¹æ˜¯Local Attentionï¼šå…ˆé¢„æµ‹å¯¹é½ä½ç½® $p_t$ï¼Œåªè®¡ç®—çª—å£ $[p_t - D, p_t + D]$ å†…çš„æ³¨æ„åŠ›ã€‚</span><span class="co">](figures/chapter-6/original/fig-global-local-attention.png)</span>{#fig-global-local width=80%}</span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>*Source: Luong, Pham, &amp; Manning (2015) "Effective Approaches to Attention-based Neural Machine Translation", Figure 2 &amp; 3. [arXiv:1508.04025](https://arxiv.org/abs/1508.04025)*</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hard Attention vs Soft Attention</span></span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>é™¤äº†Global/Localçš„åŒºåˆ†ï¼Œè¿˜æœ‰å¦ä¸€ä¸ªé‡è¦ç»´åº¦ï¼š**è½¯æ³¨æ„åŠ›ï¼ˆSoft Attentionï¼‰** vs **ç¡¬æ³¨æ„åŠ›ï¼ˆHard Attentionï¼‰**ã€‚</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>**Soft Attention**ï¼šè®¡ç®—æ‰€æœ‰ä½ç½®çš„æ³¨æ„åŠ›æƒé‡ï¼ˆä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼‰ï¼Œç„¶ååŠ æƒæ±‚å’Œã€‚è¿™æ˜¯æˆ‘ä»¬ä¸€ç›´åœ¨è®¨è®ºçš„æ–¹å¼ã€‚</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>\mathbf{c}_i = \sum_j \alpha_{ij} \mathbf{h}_j = \mathbb{E}_{p(j | \mathbf{s}_i, \mathbf{H})}<span class="co">[</span><span class="ot">\mathbf{h}_j</span><span class="co">]</span></span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a>**Hard Attention**ï¼šä»æ³¨æ„åŠ›åˆ†å¸ƒä¸­**é‡‡æ ·**ä¸€ä¸ªä½ç½® $j^*$ï¼Œåªä½¿ç”¨é‚£ä¸ªä½ç½®çš„ä¿¡æ¯ã€‚</span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>j^* \sim \text{Categorical}(\alpha_{i1}, \alpha_{i2}, \ldots, \alpha_{iT_x})</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>\mathbf{c}_i = \mathbf{h}_{j^*}</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>ä¸¤è€…çš„æ ¸å¿ƒåŒºåˆ«åœ¨äº**å¯å¾®åˆ†æ€§**ã€‚</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a>**Soft Attention æ˜¯å¯å¾®åˆ†çš„**ï¼šåŠ æƒæ±‚å’Œæ˜¯ä¸€ä¸ªè¿ç»­æ“ä½œï¼Œæ¢¯åº¦å¯ä»¥é€šè¿‡ $\alpha_{ij}$ æµå‘å¯¹é½å‡½æ•°çš„å‚æ•°ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ç”¨æ ‡å‡†çš„åå‘ä¼ æ’­è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚</span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>**Hard Attention ä¸å¯å¾®åˆ†**ï¼šé‡‡æ ·æ“ä½œæ˜¯ç¦»æ•£çš„ï¼Œæ¢¯åº¦æ— æ³•ç›´æ¥é€šè¿‡ã€‚è¦è®­ç»ƒHard Attentionï¼Œéœ€è¦ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚REINFORCEï¼‰ï¼Œç”¨æœŸæœ›æ¢¯åº¦çš„è’™ç‰¹å¡æ´›ä¼°è®¡æ¥è¿‘ä¼¼ã€‚è¿™å¸¦æ¥äº†é«˜æ–¹å·®å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hard Attentionçš„è®­ç»ƒå›°éš¾</span></span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>Hard Attentionè™½ç„¶åœ¨æ¦‚å¿µä¸Šæ›´æ¥è¿‘äººç±»çš„"æ³¨æ„"ï¼ˆæˆ‘ä»¬çœŸçš„åªçœ‹ä¸€ä¸ªåœ°æ–¹ï¼Œè€Œä¸æ˜¯æ¨¡ç³Šåœ°çœ‹æ‰€æœ‰åœ°æ–¹ï¼‰ï¼Œä½†å®ƒçš„è®­ç»ƒéœ€è¦å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼š</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>\nabla_\theta J = \mathbb{E}_{j^* \sim p(j|\theta)} \left[ \nabla_\theta \log p(j^* | \theta) \cdot R(j^*) \right]</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a>å…¶ä¸­ $R(j^*)$ æ˜¯é€‰æ‹©ä½ç½® $j^*$ å¸¦æ¥çš„"å¥–åŠ±"ã€‚è¿™ä¸ªæ¢¯åº¦ä¼°è®¡çš„æ–¹å·®å¾ˆå¤§ï¼Œéœ€è¦å¤§é‡é‡‡æ ·æ‰èƒ½ç¨³å®šã€‚</span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>å®è·µä¸­ï¼Œ**Soft Attentionå‡ ä¹æ€»æ˜¯æ›´å¥½çš„é€‰æ‹©**ï¼Œå› ä¸ºï¼š</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>ç«¯åˆ°ç«¯å¯å¾®åˆ†ï¼Œè®­ç»ƒç®€å•</span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>æ¢¯åº¦ä¼°è®¡æ²¡æœ‰æ–¹å·®é—®é¢˜</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>å¯ä»¥åŒæ—¶åˆ©ç”¨å¤šä¸ªä½ç½®çš„ä¿¡æ¯</span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a><span class="fu">### å¤æ‚åº¦åˆ†æ</span></span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>ä¸åŒæ³¨æ„åŠ›å˜ä½“çš„è®¡ç®—å¤æ‚åº¦ï¼š</span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> å˜ä½“ <span class="pp">|</span> å¯¹é½è®¡ç®— <span class="pp">|</span> æ€»å¤æ‚åº¦ <span class="pp">|</span></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|----------|----------|</span></span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Global + Dot** <span class="pp">|</span> $O(T_x \cdot d)$ per step <span class="pp">|</span> $O(T_x \cdot T_y \cdot d)$ <span class="pp">|</span></span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Global + General** <span class="pp">|</span> $O(T_x \cdot d^2)$ per step <span class="pp">|</span> $O(T_x \cdot T_y \cdot d^2)$ <span class="pp">|</span></span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Global + Concat** <span class="pp">|</span> $O(T_x \cdot d^2)$ per step <span class="pp">|</span> $O(T_x \cdot T_y \cdot d^2)$ <span class="pp">|</span></span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Local** <span class="pp">|</span> $O(D \cdot d)$ per step <span class="pp">|</span> $O(D \cdot T_y \cdot d)$ <span class="pp">|</span></span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a>å…¶ä¸­ $T_x$ æ˜¯æºåºåˆ—é•¿åº¦ï¼Œ$T_y$ æ˜¯ç›®æ ‡åºåˆ—é•¿åº¦ï¼Œ$d$ æ˜¯éšè—ç»´åº¦ï¼Œ$D$ æ˜¯å±€éƒ¨çª—å£å¤§å°ã€‚</span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a>Local Attentionçš„ä¼˜åŠ¿åœ¨é•¿åºåˆ—æ—¶å°¤ä¸ºæ˜æ˜¾ï¼šå½“ $T_x = 1000$ è€Œ $D = 50$ æ—¶ï¼Œè®¡ç®—é‡å‡å°‘äº†20å€ã€‚</span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a><span class="fu">## å·¥ç¨‹å®è·µ</span></span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### å®ç°Luong Attention</span></span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LuongAttention(nn.Module):</span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒä¸‰ç§å¯¹é½æ–¹å¼</span></span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, enc_hidden_dim, dec_hidden_dim, method<span class="op">=</span><span class="st">'dot'</span>):</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.method <span class="op">=</span> method</span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_hidden_dim <span class="op">=</span> enc_hidden_dim</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dec_hidden_dim <span class="op">=</span> dec_hidden_dim</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim <span class="op">+</span> dec_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v_a <span class="op">=</span> nn.Linear(dec_hidden_dim, <span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, decoder_state, encoder_outputs, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: [batch, dec_hidden]</span></span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: [batch, src_len, enc_hidden]</span></span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a><span class="co">        mask: [batch, src_len], Trueè¡¨ç¤ºpaddingä½ç½®</span></span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a>        batch_size, src_len, _ <span class="op">=</span> encoder_outputs.shape</span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'dot'</span>:</span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ç‚¹ç§¯: s^T h</span></span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a>            <span class="co"># éœ€è¦ dec_hidden == enc_hidden</span></span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> torch.bmm(</span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>                decoder_state.unsqueeze(<span class="dv">1</span>),  <span class="co"># [batch, 1, dec_hidden]</span></span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a>                encoder_outputs.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># [batch, enc_hidden, src_len]</span></span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a>            ).squeeze(<span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'general'</span>:</span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ä¸€èˆ¬å½¢å¼: s^T W h</span></span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a>            <span class="co"># W å°† enc_hidden æ˜ å°„åˆ° dec_hidden</span></span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a>            transformed <span class="op">=</span> <span class="va">self</span>.W_a(encoder_outputs)  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> torch.bmm(</span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a>                decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a>                transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a>            ).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.method <span class="op">==</span> <span class="st">'concat'</span>:</span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>            <span class="co"># æ‹¼æ¥å½¢å¼: v^T tanh(W [s; h])</span></span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>            decoder_expanded <span class="op">=</span> decoder_state.unsqueeze(<span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, src_len, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>            concat <span class="op">=</span> torch.cat([decoder_expanded, encoder_outputs], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>            energy <span class="op">=</span> torch.tanh(<span class="va">self</span>.W_a(concat))  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> <span class="va">self</span>.v_a(energy).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åº”ç”¨ mask</span></span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a>            scores <span class="op">=</span> scores.masked_fill(mask, <span class="op">-</span><span class="fl">1e10</span>)</span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Softmax</span></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸Šä¸‹æ–‡å‘é‡</span></span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> torch.bmm(</span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a>            attention_weights.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a>            encoder_outputs</span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> context, attention_weights</span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a><span class="fu">### å®ç°Local Attention</span></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LocalAttention(nn.Module):</span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a><span class="co">    Luong çš„ Local Attentionï¼ˆé¢„æµ‹å‹ï¼‰</span></span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, enc_hidden_dim, dec_hidden_dim, window_size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb6-453"><a href="#cb6-453" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-454"><a href="#cb6-454" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.window_size <span class="op">=</span> window_size  <span class="co"># D: çª—å£åŠå¾„</span></span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.enc_hidden_dim <span class="op">=</span> enc_hidden_dim</span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä½ç½®é¢„æµ‹ç½‘ç»œ</span></span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_p <span class="op">=</span> nn.Linear(dec_hidden_dim, dec_hidden_dim)</span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v_p <span class="op">=</span> nn.Linear(dec_hidden_dim, <span class="dv">1</span>)</span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a>        <span class="co"># å¯¹é½å‡½æ•°ï¼ˆä½¿ç”¨ generalï¼‰</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_a <span class="op">=</span> nn.Linear(enc_hidden_dim, dec_hidden_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é«˜æ–¯æ ‡å‡†å·®</span></span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigma <span class="op">=</span> window_size <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, decoder_state, encoder_outputs, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a><span class="co">        decoder_state: [batch, dec_hidden]</span></span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a><span class="co">        encoder_outputs: [batch, src_len, enc_hidden]</span></span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-472"><a href="#cb6-472" aria-hidden="true" tabindex="-1"></a>        batch_size, src_len, _ <span class="op">=</span> encoder_outputs.shape</span>
<span id="cb6-473"><a href="#cb6-473" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> decoder_state.device</span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: é¢„æµ‹å¯¹é½ä½ç½® p</span></span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a>        <span class="co"># p = S * sigmoid(v^T tanh(W_p s))</span></span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a>        p <span class="op">=</span> src_len <span class="op">*</span> torch.sigmoid(</span>
<span id="cb6-478"><a href="#cb6-478" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.v_p(torch.tanh(<span class="va">self</span>.W_p(decoder_state)))</span>
<span id="cb6-479"><a href="#cb6-479" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch]</span></span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: è®¡ç®—æ‰€æœ‰ä½ç½®çš„å¯¹é½åˆ†æ•°</span></span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a>        transformed <span class="op">=</span> <span class="va">self</span>.W_a(encoder_outputs)  <span class="co"># [batch, src_len, dec_hidden]</span></span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> torch.bmm(</span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a>            decoder_state.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a>            transformed.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 3: åº”ç”¨é«˜æ–¯çª—å£</span></span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ç”Ÿæˆä½ç½®ç´¢å¼• [0, 1, 2, ..., src_len-1]</span></span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> torch.arange(src_len, device<span class="op">=</span>device).<span class="bu">float</span>()</span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> positions.unsqueeze(<span class="dv">0</span>).expand(batch_size, <span class="op">-</span><span class="dv">1</span>)  <span class="co"># [batch, src_len]</span></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é«˜æ–¯æƒé‡: exp(-(j - p)^2 / (2 * sigma^2))</span></span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a>        gaussian <span class="op">=</span> torch.exp(<span class="op">-</span>((positions <span class="op">-</span> p.unsqueeze(<span class="dv">1</span>)) <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> <span class="va">self</span>.sigma <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 4: çª—å£maskï¼ˆåªä¿ç•™ [p-D, p+D] èŒƒå›´å†…çš„ä½ç½®ï¼‰</span></span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a>        window_mask <span class="op">=</span> (positions <span class="op">&gt;=</span> (p.unsqueeze(<span class="dv">1</span>) <span class="op">-</span> <span class="va">self</span>.window_size)) <span class="op">&amp;</span> <span class="op">\</span></span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a>                      (positions <span class="op">&lt;=</span> (p.unsqueeze(<span class="dv">1</span>) <span class="op">+</span> <span class="va">self</span>.window_size))</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a>        <span class="co"># åº”ç”¨çª—å£mask</span></span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>        scores <span class="op">=</span> scores.masked_fill(<span class="op">~</span>window_mask, <span class="op">-</span><span class="fl">1e10</span>)</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 5: Softmax + é«˜æ–¯åŠ æƒ</span></span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> F.softmax(scores, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">*</span> gaussian</span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a>        <span class="co"># é‡æ–°å½’ä¸€åŒ–</span></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a>        attention_weights <span class="op">=</span> attention_weights <span class="op">/</span> (attention_weights.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ä¸Šä¸‹æ–‡å‘é‡</span></span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> torch.bmm(</span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>            attention_weights.unsqueeze(<span class="dv">1</span>),</span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>            encoder_outputs</span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a>        ).squeeze(<span class="dv">1</span>)</span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> context, attention_weights, p</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a><span class="fu">### å¯¹æ¯”å®éªŒ</span></span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a><span class="co"># åˆ›å»ºæµ‹è¯•æ•°æ®</span></span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a>src_len <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a>enc_hidden <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a>dec_hidden <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb6-529"><a href="#cb6-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-530"><a href="#cb6-530" aria-hidden="true" tabindex="-1"></a>encoder_outputs <span class="op">=</span> torch.randn(batch_size, src_len, enc_hidden)</span>
<span id="cb6-531"><a href="#cb6-531" aria-hidden="true" tabindex="-1"></a>decoder_state <span class="op">=</span> torch.randn(batch_size, dec_hidden)</span>
<span id="cb6-532"><a href="#cb6-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-533"><a href="#cb6-533" aria-hidden="true" tabindex="-1"></a><span class="co"># æµ‹è¯•ä¸‰ç§ Luong Attention</span></span>
<span id="cb6-534"><a href="#cb6-534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> method <span class="kw">in</span> [<span class="st">'dot'</span>, <span class="st">'general'</span>, <span class="st">'concat'</span>]:</span>
<span id="cb6-535"><a href="#cb6-535" aria-hidden="true" tabindex="-1"></a>    attn <span class="op">=</span> LuongAttention(enc_hidden, dec_hidden, method<span class="op">=</span>method)</span>
<span id="cb6-536"><a href="#cb6-536" aria-hidden="true" tabindex="-1"></a>    context, weights <span class="op">=</span> attn(decoder_state, encoder_outputs)</span>
<span id="cb6-537"><a href="#cb6-537" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>method<span class="sc">:8s}</span><span class="ss">: context shape = </span><span class="sc">{</span>context<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, weights sum = </span><span class="sc">{</span>weights<span class="sc">.</span><span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-538"><a href="#cb6-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-539"><a href="#cb6-539" aria-hidden="true" tabindex="-1"></a><span class="co"># æµ‹è¯• Local Attention</span></span>
<span id="cb6-540"><a href="#cb6-540" aria-hidden="true" tabindex="-1"></a>local_attn <span class="op">=</span> LocalAttention(enc_hidden, dec_hidden, window_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb6-541"><a href="#cb6-541" aria-hidden="true" tabindex="-1"></a>context, weights, p <span class="op">=</span> local_attn(decoder_state, encoder_outputs)</span>
<span id="cb6-542"><a href="#cb6-542" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'local'</span><span class="sc">:8s}</span><span class="ss">: context shape = </span><span class="sc">{</span>context<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, predicted p = </span><span class="sc">{</span>p<span class="sc">.</span>tolist()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-543"><a href="#cb6-543" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-544"><a href="#cb6-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-545"><a href="#cb6-545" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-546"><a href="#cb6-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-547"><a href="#cb6-547" aria-hidden="true" tabindex="-1"></a><span class="fu">## æ·±å…¥ç†è§£</span></span>
<span id="cb6-548"><a href="#cb6-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-549"><a href="#cb6-549" aria-hidden="true" tabindex="-1"></a><span class="fu">### ä¸ºä»€ä¹ˆç‚¹ç§¯æ³¨æ„åŠ›èƒ½å·¥ä½œï¼Ÿâ€”â€”ç†è®ºè§†è§’</span></span>
<span id="cb6-550"><a href="#cb6-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-551"><a href="#cb6-551" aria-hidden="true" tabindex="-1"></a>ç‚¹ç§¯æ³¨æ„åŠ›çš„æœ‰æ•ˆæ€§å¯ä»¥ä»å¤šä¸ªè§’åº¦ç†è§£ã€‚</span>
<span id="cb6-552"><a href="#cb6-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-553"><a href="#cb6-553" aria-hidden="true" tabindex="-1"></a>**ä½™å¼¦ç›¸ä¼¼åº¦è§†è§’**ï¼šå½“å‘é‡è¢«å½’ä¸€åŒ–åï¼Œç‚¹ç§¯å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦ï¼š</span>
<span id="cb6-554"><a href="#cb6-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-555"><a href="#cb6-555" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-556"><a href="#cb6-556" aria-hidden="true" tabindex="-1"></a>\mathbf{s}^\top \mathbf{h} = <span class="sc">\|</span>\mathbf{s}<span class="sc">\|</span> <span class="sc">\|</span>\mathbf{h}<span class="sc">\|</span> \cos(\theta)</span>
<span id="cb6-557"><a href="#cb6-557" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-558"><a href="#cb6-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-559"><a href="#cb6-559" aria-hidden="true" tabindex="-1"></a>ä½™å¼¦ç›¸ä¼¼åº¦æ˜¯è¡¡é‡ä¸¤ä¸ªå‘é‡"æ–¹å‘ä¸€è‡´æ€§"çš„ç»å…¸æŒ‡æ ‡ã€‚ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šå­¦ä¹ è®©ç›¸å…³çš„çŠ¶æ€æŒ‡å‘ç›¸ä¼¼çš„æ–¹å‘ã€‚</span>
<span id="cb6-560"><a href="#cb6-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-561"><a href="#cb6-561" aria-hidden="true" tabindex="-1"></a>**æ ¸æ–¹æ³•è§†è§’**ï¼šç‚¹ç§¯å¯ä»¥çœ‹ä½œä¸€ä¸ªçº¿æ€§æ ¸ï¼ˆlinear kernelï¼‰ã€‚åœ¨æ ¸æ–¹æ³•çš„æ¡†æ¶ä¸‹ï¼Œæ³¨æ„åŠ›æƒé‡å®é™…ä¸Šæ˜¯åœ¨ä¸€ä¸ªç‰¹å¾ç©ºé—´ä¸­è®¡ç®—ç›¸ä¼¼åº¦ã€‚General Attentionå¼•å…¥çš„å¯å­¦ä¹ çŸ©é˜µ $\mathbf{W}_a$ ç›¸å½“äºå­¦ä¹ ä¸€ä¸ªMahalanobisè·ç¦»ã€‚</span>
<span id="cb6-562"><a href="#cb6-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-563"><a href="#cb6-563" aria-hidden="true" tabindex="-1"></a>**ä¿¡æ¯æ£€ç´¢è§†è§’**ï¼šç‚¹ç§¯æ³¨æ„åŠ›å¯ä»¥ç±»æ¯”ä¸ºå‘é‡ç©ºé—´æ¨¡å‹ä¸­çš„æŸ¥è¯¢-æ–‡æ¡£åŒ¹é…ã€‚è§£ç å™¨çŠ¶æ€æ˜¯"æŸ¥è¯¢"ï¼Œç¼–ç å™¨çŠ¶æ€æ˜¯"æ–‡æ¡£"ï¼Œç‚¹ç§¯è¡¡é‡æŸ¥è¯¢ä¸æ–‡æ¡£çš„ç›¸å…³æ€§ã€‚</span>
<span id="cb6-564"><a href="#cb6-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-565"><a href="#cb6-565" aria-hidden="true" tabindex="-1"></a><span class="fu">### ä¸ºä»€ä¹ˆéœ€è¦ç¼©æ”¾ï¼Ÿâ€”â€”Scaled Dot-Productçš„é¢„å…†</span></span>
<span id="cb6-566"><a href="#cb6-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-567"><a href="#cb6-567" aria-hidden="true" tabindex="-1"></a>Luongçš„è®ºæ–‡æ²¡æœ‰è®¨è®ºè¿™ä¸ªé—®é¢˜ï¼Œä½†åæ¥çš„Transformerè®ºæ–‡ï¼ˆVaswani et al., 2017ï¼‰æŒ‡å‡ºäº†ç‚¹ç§¯æ³¨æ„åŠ›çš„ä¸€ä¸ªæ½œåœ¨é—®é¢˜ï¼š</span>
<span id="cb6-568"><a href="#cb6-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-569"><a href="#cb6-569" aria-hidden="true" tabindex="-1"></a>å½“å‘é‡ç»´åº¦ $d$ å¾ˆå¤§æ—¶ï¼Œç‚¹ç§¯çš„æ–¹å·®ä¼šå¾ˆå¤§ã€‚å‡è®¾ $\mathbf{s}$ å’Œ $\mathbf{h}$ çš„æ¯ä¸ªåˆ†é‡éƒ½æ˜¯ç‹¬ç«‹çš„ã€å‡å€¼ä¸º0ã€æ–¹å·®ä¸º1çš„éšæœºå˜é‡ï¼Œé‚£ä¹ˆï¼š</span>
<span id="cb6-570"><a href="#cb6-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-571"><a href="#cb6-571" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-572"><a href="#cb6-572" aria-hidden="true" tabindex="-1"></a>\text{Var}(\mathbf{s}^\top \mathbf{h}) = d</span>
<span id="cb6-573"><a href="#cb6-573" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-574"><a href="#cb6-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-575"><a href="#cb6-575" aria-hidden="true" tabindex="-1"></a>å½“ $d = 512$ æ—¶ï¼Œç‚¹ç§¯çš„æ ‡å‡†å·®æ˜¯ $\sqrt{512} \approx 22.6$ã€‚è¿™æ„å‘³ç€ç‚¹ç§¯å¯èƒ½äº§ç”Ÿå¾ˆå¤§çš„æ­£å€¼æˆ–è´Ÿå€¼ï¼Œå¯¼è‡´softmaxè¾“å‡ºæ¥è¿‘one-hotåˆ†å¸ƒï¼Œæ¢¯åº¦å˜å¾—å¾ˆå°ã€‚</span>
<span id="cb6-576"><a href="#cb6-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-577"><a href="#cb6-577" aria-hidden="true" tabindex="-1"></a>è§£å†³æ–¹æ¡ˆæ˜¯**ç¼©æ”¾**ï¼š</span>
<span id="cb6-578"><a href="#cb6-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-579"><a href="#cb6-579" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-580"><a href="#cb6-580" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}, \mathbf{h}) = \frac{\mathbf{s}^\top \mathbf{h}}{\sqrt{d}}</span>
<span id="cb6-581"><a href="#cb6-581" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-582"><a href="#cb6-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-583"><a href="#cb6-583" aria-hidden="true" tabindex="-1"></a>è¿™å°±æ˜¯Transformerä¸­çš„**Scaled Dot-Product Attention**ã€‚Luongçš„è®ºæ–‡ä½¿ç”¨çš„ç»´åº¦è¾ƒå°ï¼ˆ500å·¦å³ï¼‰ï¼Œé—®é¢˜ä¸å¤ªæ˜æ˜¾ï¼›ä½†åœ¨Transformerçš„å¤§ç»´åº¦è®¾ç½®ä¸‹ï¼Œç¼©æ”¾å˜å¾—å¿…è¦ã€‚</span>
<span id="cb6-584"><a href="#cb6-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-585"><a href="#cb6-585" aria-hidden="true" tabindex="-1"></a><span class="fu">### æ–¹æ³•çš„è¾¹ç•Œæ¡ä»¶</span></span>
<span id="cb6-586"><a href="#cb6-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-587"><a href="#cb6-587" aria-hidden="true" tabindex="-1"></a>**Dot-Product Attentionçš„å±€é™**ï¼š</span>
<span id="cb6-588"><a href="#cb6-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-589"><a href="#cb6-589" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**ç»´åº¦å¿…é¡»åŒ¹é…**ï¼šè§£ç å™¨å’Œç¼–ç å™¨çš„éšè—ç»´åº¦å¿…é¡»ç›¸åŒï¼Œå¦åˆ™æ— æ³•è®¡ç®—ç‚¹ç§¯</span>
<span id="cb6-590"><a href="#cb6-590" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**è¡¨è¾¾èƒ½åŠ›æœ‰é™**ï¼šæ— æ³•å­¦ä¹ å¤æ‚çš„ç›¸å…³æ€§æ¨¡å¼ï¼Œåªèƒ½æ•æ‰"æ–¹å‘ç›¸ä¼¼"çš„å…³ç³»</span>
<span id="cb6-591"><a href="#cb6-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-592"><a href="#cb6-592" aria-hidden="true" tabindex="-1"></a>**Local Attentionçš„å±€é™**ï¼š</span>
<span id="cb6-593"><a href="#cb6-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-594"><a href="#cb6-594" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**éœ€è¦é¢„æµ‹å¯¹é½ä½ç½®**ï¼šå¦‚æœä½ç½®é¢„æµ‹é”™è¯¯ï¼Œä¼šé”™è¿‡é‡è¦ä¿¡æ¯</span>
<span id="cb6-595"><a href="#cb6-595" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**ä¸é€‚åˆéå•è°ƒå¯¹é½**ï¼šå¯¹äºè¯­åºå·®å¼‚å¤§çš„è¯­è¨€å¯¹ï¼Œå±€éƒ¨çª—å£å¯èƒ½è¦†ç›–ä¸åˆ°æ­£ç¡®ä½ç½®</span>
<span id="cb6-596"><a href="#cb6-596" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**çª—å£å¤§å°æ˜¯è¶…å‚æ•°**ï¼šé€‰æ‹©ä¸å½“ä¼šå½±å“æ€§èƒ½</span>
<span id="cb6-597"><a href="#cb6-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-598"><a href="#cb6-598" aria-hidden="true" tabindex="-1"></a>**General/Concatçš„å±€é™**ï¼š</span>
<span id="cb6-599"><a href="#cb6-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-600"><a href="#cb6-600" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**è®¡ç®—å¼€é”€**ï¼šé¢å¤–çš„çŸ©é˜µä¹˜æ³•å¢åŠ äº†è®¡ç®—é‡</span>
<span id="cb6-601"><a href="#cb6-601" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**è¿‡æ‹Ÿåˆé£é™©**ï¼šæ›´å¤šå‚æ•°å¯èƒ½å¯¼è‡´åœ¨å°æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆ</span>
<span id="cb6-602"><a href="#cb6-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-603"><a href="#cb6-603" aria-hidden="true" tabindex="-1"></a><span class="fu">### å¼€æ”¾ç ”ç©¶é—®é¢˜</span></span>
<span id="cb6-604"><a href="#cb6-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-605"><a href="#cb6-605" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**å¯¹é½å‡½æ•°çš„æœ€ä¼˜é€‰æ‹©**ï¼šåœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹åº”è¯¥é€‰æ‹©å“ªç§å¯¹é½å‡½æ•°ï¼Ÿæ˜¯å¦æœ‰ç†è®ºæŒ‡å¯¼ï¼Ÿ</span>
<span id="cb6-606"><a href="#cb6-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-607"><a href="#cb6-607" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**åŠ¨æ€çª—å£**ï¼šLocal Attentionä½¿ç”¨å›ºå®šçª—å£å¤§å°ï¼Œèƒ½å¦æ ¹æ®å†…å®¹åŠ¨æ€è°ƒæ•´ï¼Ÿ</span>
<span id="cb6-608"><a href="#cb6-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-609"><a href="#cb6-609" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**å¤šç²’åº¦æ³¨æ„åŠ›**ï¼šèƒ½å¦åŒæ—¶ä½¿ç”¨å…¨å±€å’Œå±€éƒ¨æ³¨æ„åŠ›ï¼Œåœ¨ä¸åŒç²’åº¦ä¸Šæ•è·ä¿¡æ¯ï¼Ÿ</span>
<span id="cb6-610"><a href="#cb6-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-611"><a href="#cb6-611" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-612"><a href="#cb6-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-613"><a href="#cb6-613" aria-hidden="true" tabindex="-1"></a><span class="fu">## å±€é™æ€§ä¸å±•æœ›</span></span>
<span id="cb6-614"><a href="#cb6-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-615"><a href="#cb6-615" aria-hidden="true" tabindex="-1"></a><span class="fu">### æœ¬ç« æ–¹æ³•çš„æ ¸å¿ƒå±€é™</span></span>
<span id="cb6-616"><a href="#cb6-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-617"><a href="#cb6-617" aria-hidden="true" tabindex="-1"></a>**1. æ³¨æ„åŠ›ä»ç„¶æ˜¯RNNçš„"é™„å±å“"**</span>
<span id="cb6-618"><a href="#cb6-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-619"><a href="#cb6-619" aria-hidden="true" tabindex="-1"></a>æ— è®ºæ˜¯Bahdanauè¿˜æ˜¯Luongçš„æ³¨æ„åŠ›ï¼Œéƒ½æ˜¯Seq2Seqæ¶æ„çš„å¢å¼ºç»„ä»¶ã€‚ç¼–ç å’Œè§£ç çš„æ ¸å¿ƒä»ç„¶ä¾èµ–RNNã€‚è¿™æ„å‘³ç€ï¼š</span>
<span id="cb6-620"><a href="#cb6-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-621"><a href="#cb6-621" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>é¡ºåºè®¡ç®—æ— æ³•é¿å…ï¼šRNNå¿…é¡»é€æ­¥å¤„ç†åºåˆ—</span>
<span id="cb6-622"><a href="#cb6-622" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>é•¿è·ç¦»ä¾èµ–ä»ç„¶å›°éš¾ï¼šè™½ç„¶Attentionæä¾›äº†æ·å¾„ï¼Œä½†RNNæœ¬èº«çš„é—®é¢˜æ²¡æœ‰è§£å†³</span>
<span id="cb6-623"><a href="#cb6-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-624"><a href="#cb6-624" aria-hidden="true" tabindex="-1"></a>**2. æ³¨æ„åŠ›åªåœ¨ç¼–ç å™¨-è§£ç å™¨ä¹‹é—´**</span>
<span id="cb6-625"><a href="#cb6-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-626"><a href="#cb6-626" aria-hidden="true" tabindex="-1"></a>å½“å‰çš„Attentionåªè®©è§£ç å™¨å…³æ³¨ç¼–ç å™¨ã€‚ä½†ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼š**ç¼–ç å™¨å†…éƒ¨çš„å„ä¸ªä½ç½®èƒ½å¦ç›¸äº’å…³æ³¨ï¼Ÿ** ä¸€ä¸ªè¯çš„ç†è§£å¯èƒ½ä¾èµ–äºåŒä¸€å¥è¯ä¸­çš„å…¶ä»–è¯ï¼Œè€Œå½“å‰çš„æ¶æ„æ²¡æœ‰æä¾›è¿™ç§æœºåˆ¶ã€‚</span>
<span id="cb6-627"><a href="#cb6-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-628"><a href="#cb6-628" aria-hidden="true" tabindex="-1"></a>**3. ä½ç½®ä¿¡æ¯æ˜¯éšå¼çš„**</span>
<span id="cb6-629"><a href="#cb6-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-630"><a href="#cb6-630" aria-hidden="true" tabindex="-1"></a>Attentionæœ¬èº«ä¸åŒ…å«ä½ç½®ä¿¡æ¯ã€‚ä½ç½®ä¿¡æ¯å®Œå…¨ä¾èµ–RNNçš„é¡ºåºå¤„ç†æ¥éšå¼ç¼–ç ã€‚å¦‚æœæŠ›å¼ƒRNNï¼Œä½ç½®ä¿¡æ¯å°†å®Œå…¨ä¸¢å¤±ã€‚</span>
<span id="cb6-631"><a href="#cb6-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-632"><a href="#cb6-632" aria-hidden="true" tabindex="-1"></a><span class="fu">### è¿™äº›å±€é™æŒ‡å‘ä»€ä¹ˆï¼Ÿ</span></span>
<span id="cb6-633"><a href="#cb6-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-634"><a href="#cb6-634" aria-hidden="true" tabindex="-1"></a>Luongçš„å·¥ä½œå®Œæˆäº†å¯¹Seq2Seq Attentionçš„ç³»ç»Ÿæ€§æ¢ç´¢ï¼Œç¡®ç«‹äº†ä¸€äº›æœ€ä½³å®è·µï¼ˆå¦‚ç‚¹ç§¯æ³¨æ„åŠ›çš„æ•ˆç‡ä¼˜åŠ¿ï¼‰ã€‚ä½†æ›´æ·±å±‚çš„é—®é¢˜æµ®ç°ï¼š</span>
<span id="cb6-635"><a href="#cb6-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-636"><a href="#cb6-636" aria-hidden="true" tabindex="-1"></a>**èƒ½å¦è®©Attentionç‹¬ç«‹äºRNNï¼Ÿ**</span>
<span id="cb6-637"><a href="#cb6-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-638"><a href="#cb6-638" aria-hidden="true" tabindex="-1"></a>å¦‚æœAttentionå¦‚æ­¤æœ‰æ•ˆï¼Œä¸ºä»€ä¹ˆè¿˜éœ€è¦RNNï¼Ÿèƒ½å¦è®¾è®¡ä¸€ä¸ªå®Œå…¨åŸºäºAttentionçš„æ¶æ„ï¼Ÿ</span>
<span id="cb6-639"><a href="#cb6-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-640"><a href="#cb6-640" aria-hidden="true" tabindex="-1"></a>**èƒ½å¦è®©åºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®ç›¸äº’å…³æ³¨ï¼Ÿ**</span>
<span id="cb6-641"><a href="#cb6-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-642"><a href="#cb6-642" aria-hidden="true" tabindex="-1"></a>å½“å‰çš„Attentionæ˜¯"è·¨åºåˆ—"çš„ï¼ˆè§£ç å™¨å…³æ³¨ç¼–ç å™¨ï¼‰ã€‚å¦‚æœè®©åŒä¸€åºåˆ—å†…çš„ä½ç½®ç›¸äº’å…³æ³¨â€”â€”è¿™å°±æ˜¯**Self-Attention**â€”â€”ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ</span>
<span id="cb6-643"><a href="#cb6-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-644"><a href="#cb6-644" aria-hidden="true" tabindex="-1"></a>è¿™äº›é—®é¢˜çš„ç­”æ¡ˆï¼Œå°†åœ¨æ¥ä¸‹æ¥çš„ä¸¤ç« æ­æ™“ï¼šç¬¬7ç« å°†ä»‹ç»Self-Attentionçš„è¯ç”Ÿï¼Œç¬¬8ç« å°†ä»‹ç»é©å‘½æ€§çš„Transformeræ¶æ„â€”â€”"Attention Is All You Need"ã€‚</span>
<span id="cb6-645"><a href="#cb6-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-646"><a href="#cb6-646" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; ä»åŠ æ€§åˆ°ä¹˜æ€§ï¼Œä»å…¨å±€åˆ°å±€éƒ¨ï¼ŒLuongçš„æ¢ç´¢ä¸ºAttentionæœºåˆ¶å»ºç«‹äº†ç†è®ºå’Œå®è·µçš„åŸºç¡€ã€‚ä½†çœŸæ­£çš„é©å‘½è¿˜åœ¨åé¢ï¼šå½“ç ”ç©¶è€…æ„è¯†åˆ°**æ³¨æ„åŠ›æœ¬èº«å°±å¯ä»¥æˆä¸ºæ¶æ„çš„æ ¸å¿ƒ**ï¼Œæ·±åº¦å­¦ä¹ çš„å†å²ç¿»å¼€äº†æ–°çš„ä¸€é¡µã€‚</span></span>
<span id="cb6-647"><a href="#cb6-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-648"><a href="#cb6-648" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-649"><a href="#cb6-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-650"><a href="#cb6-650" aria-hidden="true" tabindex="-1"></a><span class="fu">## æœ¬ç« å°ç»“</span></span>
<span id="cb6-651"><a href="#cb6-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-652"><a href="#cb6-652" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb6-653"><a href="#cb6-653" aria-hidden="true" tabindex="-1"></a><span class="fu">## æ ¸å¿ƒè¦ç‚¹</span></span>
<span id="cb6-654"><a href="#cb6-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-655"><a href="#cb6-655" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**é—®é¢˜**ï¼šBahdanauçš„åŠ æ€§æ³¨æ„åŠ›æœ‰æ•ˆä½†è®¡ç®—è¾ƒæ…¢ï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„è®¾è®¡ç©ºé—´è¿˜æœ‰å¾ˆå¤šæœªæ¢ç´¢çš„é€‰æ‹©</span>
<span id="cb6-656"><a href="#cb6-656" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**æ´å¯Ÿ**ï¼šç‚¹ç§¯æ³¨æ„åŠ›å¯ä»¥ç”¨ç®€å•çš„å‘é‡å†…ç§¯è®¡ç®—ç›¸å…³æ€§ï¼Œå¤§å¹…æé«˜è®¡ç®—æ•ˆç‡ï¼›å±€éƒ¨æ³¨æ„åŠ›å¯ä»¥å‡å°‘é•¿åºåˆ—çš„è®¡ç®—å¼€é”€</span>
<span id="cb6-657"><a href="#cb6-657" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**æ–¹æ³•**ï¼šLuongç³»ç»Ÿæ¯”è¾ƒäº†dot/general/concatä¸‰ç§å¯¹é½å‡½æ•°ï¼Œä»¥åŠglobal/localä¸¤ç§èŒƒå›´ç­–ç•¥</span>
<span id="cb6-658"><a href="#cb6-658" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**æ„ä¹‰**ï¼šç¡®ç«‹äº†ç‚¹ç§¯æ³¨æ„åŠ›çš„æ•ˆç‡ä¼˜åŠ¿ï¼Œä¸ºåæ¥Transformerçš„Scaled Dot-Product Attentionå¥ å®šåŸºç¡€</span>
<span id="cb6-659"><a href="#cb6-659" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-660"><a href="#cb6-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-661"><a href="#cb6-661" aria-hidden="true" tabindex="-1"></a><span class="fu">### å…³é”®å…¬å¼é€ŸæŸ¥</span></span>
<span id="cb6-662"><a href="#cb6-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-663"><a href="#cb6-663" aria-hidden="true" tabindex="-1"></a>**Dot-Product Attention**ï¼š</span>
<span id="cb6-664"><a href="#cb6-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-665"><a href="#cb6-665" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-666"><a href="#cb6-666" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{s}^\top \mathbf{h}</span>
<span id="cb6-667"><a href="#cb6-667" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-668"><a href="#cb6-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-669"><a href="#cb6-669" aria-hidden="true" tabindex="-1"></a>**General Attention**ï¼š</span>
<span id="cb6-670"><a href="#cb6-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-671"><a href="#cb6-671" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-672"><a href="#cb6-672" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{s}^\top \mathbf{W}_a \mathbf{h}</span>
<span id="cb6-673"><a href="#cb6-673" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-674"><a href="#cb6-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-675"><a href="#cb6-675" aria-hidden="true" tabindex="-1"></a>**Concat (Additive) Attention**ï¼š</span>
<span id="cb6-676"><a href="#cb6-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-677"><a href="#cb6-677" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-678"><a href="#cb6-678" aria-hidden="true" tabindex="-1"></a>\text{score}(\mathbf{s}, \mathbf{h}) = \mathbf{v}_a^\top \tanh(\mathbf{W}_a <span class="co">[</span><span class="ot">\mathbf{s}; \mathbf{h}</span><span class="co">]</span>)</span>
<span id="cb6-679"><a href="#cb6-679" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-680"><a href="#cb6-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-681"><a href="#cb6-681" aria-hidden="true" tabindex="-1"></a>**Local Attentionä½ç½®é¢„æµ‹**ï¼š</span>
<span id="cb6-682"><a href="#cb6-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-683"><a href="#cb6-683" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-684"><a href="#cb6-684" aria-hidden="true" tabindex="-1"></a>p_i = T_x \cdot \sigma(\mathbf{v}_p^\top \tanh(\mathbf{W}_p \mathbf{s}_i))</span>
<span id="cb6-685"><a href="#cb6-685" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-686"><a href="#cb6-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-687"><a href="#cb6-687" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-688"><a href="#cb6-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-689"><a href="#cb6-689" aria-hidden="true" tabindex="-1"></a><span class="fu">## æ€è€ƒé¢˜</span></span>
<span id="cb6-690"><a href="#cb6-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-691"><a href="#cb6-691" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**[æ¦‚å¿µç†è§£]** ç‚¹ç§¯æ³¨æ„åŠ›å’ŒåŠ æ€§æ³¨æ„åŠ›åœ¨è¡¨è¾¾èƒ½åŠ›ä¸Šæœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿè®¾è®¡ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œå±•ç¤ºåŠ æ€§æ³¨æ„åŠ›èƒ½å­¦ä¹ è€Œç‚¹ç§¯æ³¨æ„åŠ›æ— æ³•å­¦ä¹ çš„ç›¸å…³æ€§æ¨¡å¼ã€‚</span>
<span id="cb6-692"><a href="#cb6-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-693"><a href="#cb6-693" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**[æ•°å­¦æ¨å¯¼]** è¯æ˜ï¼šå½“ $\mathbf{W}_a$ æ˜¯å•ä½çŸ©é˜µæ—¶ï¼ŒGeneral Attentioné€€åŒ–ä¸ºDot-Product Attentionã€‚æ›´ä¸€èˆ¬åœ°ï¼Œå¦‚æœ $\mathbf{W}_a = \mathbf{U}\mathbf{V}^\top$ï¼ˆç§©-$r$åˆ†è§£ï¼‰ï¼Œè¿™å¯¹æ³¨æ„åŠ›æ¨¡å¼æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ</span>
<span id="cb6-694"><a href="#cb6-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-695"><a href="#cb6-695" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**[å·¥ç¨‹å®è·µ]** å®ç°ä¸€ä¸ªæ”¯æŒå¤šå¤´ï¼ˆmulti-headï¼‰çš„Luong Attentionã€‚æ¯ä¸ªå¤´ä½¿ç”¨ä¸åŒçš„ $\mathbf{W}_a$ï¼Œæœ€åæ‹¼æ¥æ‰€æœ‰å¤´çš„è¾“å‡ºã€‚å¯¹æ¯”å•å¤´å’Œå¤šå¤´åœ¨ç¿»è¯‘ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</span>
<span id="cb6-696"><a href="#cb6-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-697"><a href="#cb6-697" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**[æ‰¹åˆ¤æ€è€ƒ]** Local Attentionå‡è®¾å¯¹é½æ˜¯å¤§è‡´å•è°ƒçš„ï¼ˆæºå’Œç›®æ ‡çš„ä½ç½®å¯¹åº”ï¼‰ã€‚å¯¹äºå“ªäº›è¯­è¨€å¯¹æˆ–ä»»åŠ¡ï¼Œè¿™ä¸ªå‡è®¾ä¼šä¸¥é‡å¤±æ•ˆï¼Ÿèƒ½å¦è®¾è®¡ä¸€ç§"éå•è°ƒå±€éƒ¨æ³¨æ„åŠ›"ï¼Ÿ</span>
<span id="cb6-698"><a href="#cb6-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-699"><a href="#cb6-699" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**[å¼€æ”¾é—®é¢˜]** Hard Attentionè™½ç„¶è®­ç»ƒå›°éš¾ï¼Œä½†å®ƒæœ‰ä¸€ä¸ªä¼˜åŠ¿ï¼šç¨€ç–æ€§å¯ä»¥æé«˜å¯è§£é‡Šæ€§ã€‚æœ‰æ²¡æœ‰æ–¹æ³•æ—¢ä¿æŒSoft Attentionçš„å¯å¾®åˆ†æ€§ï¼Œåˆèƒ½è·å¾—æ¥è¿‘Hard Attentionçš„ç¨€ç–æ€§ï¼Ÿï¼ˆæç¤ºï¼šè€ƒè™‘ç¨€ç–softmaxã€Gumbel-softmaxï¼‰</span>
<span id="cb6-700"><a href="#cb6-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-701"><a href="#cb6-701" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-702"><a href="#cb6-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-703"><a href="#cb6-703" aria-hidden="true" tabindex="-1"></a><span class="fu">## å»¶ä¼¸é˜…è¯»</span></span>
<span id="cb6-704"><a href="#cb6-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-705"><a href="#cb6-705" aria-hidden="true" tabindex="-1"></a><span class="fu">### æ ¸å¿ƒè®ºæ–‡ï¼ˆå¿…è¯»ï¼‰</span></span>
<span id="cb6-706"><a href="#cb6-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-707"><a href="#cb6-707" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**[Luong et al., 2015] Effective Approaches to Attention-based Neural Machine Translation**</span>
<span id="cb6-708"><a href="#cb6-708" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>æœ¬ç« çš„æ ¸å¿ƒè®ºæ–‡ï¼Œç³»ç»Ÿæ¯”è¾ƒä¸åŒæ³¨æ„åŠ›å˜ä½“</span>
<span id="cb6-709"><a href="#cb6-709" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>é‡ç‚¹è¯»ï¼šSection 3ï¼ˆGlobal vs Localï¼‰ã€Section 4ï¼ˆå®éªŒå¯¹æ¯”ï¼‰</span>
<span id="cb6-710"><a href="#cb6-710" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>arXiv: <span class="co">[</span><span class="ot">1508.04025</span><span class="co">](https://arxiv.org/abs/1508.04025)</span></span>
<span id="cb6-711"><a href="#cb6-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-712"><a href="#cb6-712" aria-hidden="true" tabindex="-1"></a><span class="fu">### ç†è®ºåŸºç¡€</span></span>
<span id="cb6-713"><a href="#cb6-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-714"><a href="#cb6-714" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**[Bahdanau et al., 2015] Neural Machine Translation by Jointly Learning to Align and Translate**</span>
<span id="cb6-715"><a href="#cb6-715" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>ä¸Šä¸€ç« çš„æ ¸å¿ƒï¼ŒAttentionçš„å¼€å±±ä¹‹ä½œ</span>
<span id="cb6-716"><a href="#cb6-716" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>arXiv: <span class="co">[</span><span class="ot">1409.0473</span><span class="co">](https://arxiv.org/abs/1409.0473)</span></span>
<span id="cb6-717"><a href="#cb6-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-718"><a href="#cb6-718" aria-hidden="true" tabindex="-1"></a><span class="fu">### åç»­å‘å±•</span></span>
<span id="cb6-719"><a href="#cb6-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-720"><a href="#cb6-720" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**[Vaswani et al., 2017] Attention Is All You Need**</span>
<span id="cb6-721"><a href="#cb6-721" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>æå‡ºScaled Dot-Product Attentionå’ŒMulti-Head Attention</span>
<span id="cb6-722"><a href="#cb6-722" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>å®Œå…¨æŠ›å¼ƒRNNï¼Œåªç”¨Attentionæ„å»ºæ¨¡å‹</span>
<span id="cb6-723"><a href="#cb6-723" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>arXiv: <span class="co">[</span><span class="ot">1706.03762</span><span class="co">](https://arxiv.org/abs/1706.03762)</span></span>
<span id="cb6-724"><a href="#cb6-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-725"><a href="#cb6-725" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**[Xu et al., 2015] Show, Attend and Tell**</span>
<span id="cb6-726"><a href="#cb6-726" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Hard Attentionåœ¨å›¾åƒæè¿°ä¸­çš„åº”ç”¨</span>
<span id="cb6-727"><a href="#cb6-727" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>å¯¹æ¯”Softå’ŒHard Attentionçš„æ•ˆæœ</span>
<span id="cb6-728"><a href="#cb6-728" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>arXiv: <span class="co">[</span><span class="ot">1502.03044</span><span class="co">](https://arxiv.org/abs/1502.03044)</span></span>
<span id="cb6-729"><a href="#cb6-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-730"><a href="#cb6-730" aria-hidden="true" tabindex="-1"></a><span class="fu">### æŠ€æœ¯æŠ¥å‘Š</span></span>
<span id="cb6-731"><a href="#cb6-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-732"><a href="#cb6-732" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**[Britz et al., 2017] Massive Exploration of Neural Machine Translation Architectures**</span>
<span id="cb6-733"><a href="#cb6-733" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>å¤§è§„æ¨¡å¯¹æ¯”NMTçš„å„ç§è®¾è®¡é€‰æ‹©</span>
<span id="cb6-734"><a href="#cb6-734" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>åŒ…æ‹¬æ³¨æ„åŠ›å˜ä½“çš„å®è¯å¯¹æ¯”</span>
<span id="cb6-735"><a href="#cb6-735" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>arXiv: <span class="co">[</span><span class="ot">1703.03906</span><span class="co">](https://arxiv.org/abs/1703.03906)</span></span>
<span id="cb6-736"><a href="#cb6-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-737"><a href="#cb6-737" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-738"><a href="#cb6-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-739"><a href="#cb6-739" aria-hidden="true" tabindex="-1"></a><span class="fu">## å†å²æ³¨è„š</span></span>
<span id="cb6-740"><a href="#cb6-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-741"><a href="#cb6-741" aria-hidden="true" tabindex="-1"></a>Luongçš„è®ºæ–‡å‘è¡¨äº2015å¹´EMNLPï¼Œè·ç¦»Bahdanauçš„è®ºæ–‡ä»…ä¸€å¹´ã€‚åœ¨è¿™çŸ­çŸ­ä¸€å¹´é‡Œï¼ŒAttentionè¿…é€Ÿæˆä¸ºNMTçš„æ ‡å‡†é…ç½®ï¼Œå„ç§å˜ä½“å±‚å‡ºä¸ç©·ã€‚Luongçš„å·¥ä½œä¹‹æ‰€ä»¥é‡è¦ï¼Œä¸ä»…åœ¨äºæå‡ºäº†æ–°çš„å˜ä½“ï¼Œæ›´åœ¨äºå®ƒ**ç³»ç»Ÿæ€§åœ°æ¯”è¾ƒå’Œæ€»ç»“**äº†å½“æ—¶çš„å„ç§æ–¹æ³•ï¼Œä¸ºåæ¥è€…æä¾›äº†æ¸…æ™°çš„è®¾è®¡æŒ‡å—ã€‚</span>
<span id="cb6-742"><a href="#cb6-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-743"><a href="#cb6-743" aria-hidden="true" tabindex="-1"></a>æœ‰è¶£çš„æ˜¯ï¼ŒLuongè®ºæ–‡ä¸­æåˆ°çš„ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆDot-Productï¼‰å› ä¸ºè¿‡äºç®€å•è€Œæ²¡æœ‰å—åˆ°å¤ªå¤šå…³æ³¨ã€‚å½“æ—¶çš„ä¸»æµä»ç„¶æ˜¯å‚æ•°åŒ–çš„å¯¹é½å‡½æ•°ã€‚ä½†ä¸¤å¹´åï¼Œå½“Transformerè®ºæ–‡æå‡º"Scaled Dot-Product Attention"æ—¶ï¼Œç‚¹ç§¯æ³¨æ„åŠ›ç»ˆäºç™»ä¸Šäº†å†å²èˆå°çš„ä¸­å¤®â€”â€”å®ƒä¸ä»…ç®€å•é«˜æ•ˆï¼Œè€Œä¸”åœ¨å¤§è§„æ¨¡è®¾ç½®ä¸‹ä¸æ›´å¤æ‚çš„å¯¹é½å‡½æ•°è¡¨ç°ç›¸å½“ã€‚</span>
<span id="cb6-744"><a href="#cb6-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-745"><a href="#cb6-745" aria-hidden="true" tabindex="-1"></a>ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼ŒLuongçš„è®ºæ–‡æ˜¯Attentionå‘å±•å²ä¸Šçš„ä¸€ä¸ª"ä¸­åœºä¼‘æ¯"â€”â€”å®ƒæ€»ç»“äº†ç¬¬ä¸€é˜¶æ®µçš„æ¢ç´¢ï¼Œä¸ºç¬¬äºŒé˜¶æ®µï¼ˆSelf-Attentionå’ŒTransformerï¼‰çš„é©å‘½é“ºå¹³äº†é“è·¯ã€‚</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>