<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ying Zha">
<meta name="dcterms.date" content="2026-01-26">
<meta name="description" content="ELMo：第一个生成上下文相关词向量的预训练模型。通过深层双向LSTM语言模型，让同一个词在不同语境中拥有不同的向量表示，标志着从’词典式’到’阅读式’词向量的范式转变。">

<title>第11章：上下文词向量——ELMo – Tech Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-1b3db88def35042d172274863c1cdcf0.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-6ee47bd5d569ce80d002539aadcc850f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Force refresh if cache is stale -->

<script>

(function() {

  var SITE_VERSION = '2025-11-14-v2'; // Update this to force all users to refresh

  var stored = localStorage.getItem('site_version');

  if (stored !== SITE_VERSION) {

    localStorage.setItem('site_version', SITE_VERSION);

    if (stored !== null) {

      // Not first visit, force reload from server

      window.location.reload(true);

    }

  }

})();

</script>

<script>

// Default to dark scheme on first visit (no prior preference stored)

try {

  var key = 'quarto-color-scheme';

  if (window && window.localStorage && window.localStorage.getItem(key) === null) {

    window.localStorage.setItem(key, 'alternate');

  }

} catch (e) {

  // ignore storage errors (privacy mode, etc.)

}

</script>

<!-- Aggressive cache prevention for HTML pages -->

<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate, max-age=0">

<meta http-equiv="Pragma" content="no-cache">

<meta http-equiv="Expires" content="0">

<meta name="revisit-after" content="1 days">

<meta name="robots" content="noarchive">




  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tech Notes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../home.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts_en.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tags.html"> 
<span class="menu-text">Tags</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#从上一章说起" id="toc-从上一章说起" class="nav-link active" data-scroll-target="#从上一章说起"><span class="header-section-number">1</span> 从上一章说起</a></li>
  <li><a href="#问题的本质是什么" id="toc-问题的本质是什么" class="nav-link" data-scroll-target="#问题的本质是什么"><span class="header-section-number">2</span> 问题的本质是什么？</a>
  <ul class="collapse">
  <li><a href="#一词多义不是边缘案例而是语言的常态" id="toc-一词多义不是边缘案例而是语言的常态" class="nav-link" data-scroll-target="#一词多义不是边缘案例而是语言的常态"><span class="header-section-number">2.1</span> 一词多义：不是边缘案例，而是语言的常态</a></li>
  <li><a href="#之前的尝试为何不够" id="toc-之前的尝试为何不够" class="nav-link" data-scroll-target="#之前的尝试为何不够"><span class="header-section-number">2.2</span> 之前的尝试为何不够？</a></li>
  <li><a href="#我们需要什么样的解决方案" id="toc-我们需要什么样的解决方案" class="nav-link" data-scroll-target="#我们需要什么样的解决方案"><span class="header-section-number">2.3</span> 我们需要什么样的解决方案？</a></li>
  </ul></li>
  <li><a href="#核心思想与直觉" id="toc-核心思想与直觉" class="nav-link" data-scroll-target="#核心思想与直觉"><span class="header-section-number">3</span> 核心思想与直觉</a>
  <ul class="collapse">
  <li><a href="#关键洞察让语言模型替你读上下文" id="toc-关键洞察让语言模型替你读上下文" class="nav-link" data-scroll-target="#关键洞察让语言模型替你读上下文"><span class="header-section-number">3.1</span> 关键洞察：让语言模型替你”读”上下文</a></li>
  <li><a href="#elmo的三个核心设计决策" id="toc-elmo的三个核心设计决策" class="nav-link" data-scroll-target="#elmo的三个核心设计决策"><span class="header-section-number">3.2</span> ELMo的三个核心设计决策</a></li>
  <li><a href="#elmogptbert的架构对比" id="toc-elmogptbert的架构对比" class="nav-link" data-scroll-target="#elmogptbert的架构对比"><span class="header-section-number">3.3</span> ELMo、GPT、BERT的架构对比</a></li>
  </ul></li>
  <li><a href="#技术细节" id="toc-技术细节" class="nav-link" data-scroll-target="#技术细节"><span class="header-section-number">4</span> 技术细节</a>
  <ul class="collapse">
  <li><a href="#双向语言模型bilm" id="toc-双向语言模型bilm" class="nav-link" data-scroll-target="#双向语言模型bilm"><span class="header-section-number">4.1</span> 双向语言模型（biLM）</a></li>
  <li><a href="#elmo表示的构造" id="toc-elmo表示的构造" class="nav-link" data-scroll-target="#elmo表示的构造"><span class="header-section-number">4.2</span> ELMo表示的构造</a></li>
  <li><a href="#架构细节" id="toc-架构细节" class="nav-link" data-scroll-target="#架构细节"><span class="header-section-number">4.3</span> 架构细节</a></li>
  <li><a href="#elmo架构总览" id="toc-elmo架构总览" class="nav-link" data-scroll-target="#elmo架构总览"><span class="header-section-number">4.4</span> ELMo架构总览</a></li>
  <li><a href="#完整数值示例从输入到elmo表示" id="toc-完整数值示例从输入到elmo表示" class="nav-link" data-scroll-target="#完整数值示例从输入到elmo表示"><span class="header-section-number">4.5</span> 完整数值示例：从输入到ELMo表示</a></li>
  <li><a href="#下游任务的使用方式" id="toc-下游任务的使用方式" class="nav-link" data-scroll-target="#下游任务的使用方式"><span class="header-section-number">4.6</span> 下游任务的使用方式</a></li>
  <li><a href="#复杂度分析" id="toc-复杂度分析" class="nav-link" data-scroll-target="#复杂度分析"><span class="header-section-number">4.7</span> 复杂度分析</a></li>
  <li><a href="#与其他方法的对比" id="toc-与其他方法的对比" class="nav-link" data-scroll-target="#与其他方法的对比"><span class="header-section-number">4.8</span> 与其他方法的对比</a></li>
  </ul></li>
  <li><a href="#工程实践" id="toc-工程实践" class="nav-link" data-scroll-target="#工程实践"><span class="header-section-number">5</span> 工程实践</a>
  <ul class="collapse">
  <li><a href="#使用allennlp提取elmo表示" id="toc-使用allennlp提取elmo表示" class="nav-link" data-scroll-target="#使用allennlp提取elmo表示"><span class="header-section-number">5.1</span> 使用AllenNLP提取ELMo表示</a></li>
  <li><a href="#将elmo集成到已有模型" id="toc-将elmo集成到已有模型" class="nav-link" data-scroll-target="#将elmo集成到已有模型"><span class="header-section-number">5.2</span> 将ELMo集成到已有模型</a></li>
  <li><a href="#复现的关键细节" id="toc-复现的关键细节" class="nav-link" data-scroll-target="#复现的关键细节"><span class="header-section-number">5.3</span> 复现的关键细节</a></li>
  <li><a href="#实验结果" id="toc-实验结果" class="nav-link" data-scroll-target="#实验结果"><span class="header-section-number">5.4</span> 实验结果</a></li>
  </ul></li>
  <li><a href="#深入理解" id="toc-深入理解" class="nav-link" data-scroll-target="#深入理解"><span class="header-section-number">6</span> 深入理解</a>
  <ul class="collapse">
  <li><a href="#为什么有效层级信息分析" id="toc-为什么有效层级信息分析" class="nav-link" data-scroll-target="#为什么有效层级信息分析"><span class="header-section-number">6.1</span> 为什么有效？——层级信息分析</a></li>
  <li><a href="#为什么用所有层比只用顶层好" id="toc-为什么用所有层比只用顶层好" class="nav-link" data-scroll-target="#为什么用所有层比只用顶层好"><span class="header-section-number">6.2</span> 为什么用所有层比只用顶层好？</a></li>
  <li><a href="#与同期工作的比较taglm和cove" id="toc-与同期工作的比较taglm和cove" class="nav-link" data-scroll-target="#与同期工作的比较taglm和cove"><span class="header-section-number">6.3</span> 与同期工作的比较：TagLM和CoVe</a></li>
  <li><a href="#方法的边界条件" id="toc-方法的边界条件" class="nav-link" data-scroll-target="#方法的边界条件"><span class="header-section-number">6.4</span> 方法的边界条件</a></li>
  <li><a href="#开放研究问题2018年视角" id="toc-开放研究问题2018年视角" class="nav-link" data-scroll-target="#开放研究问题2018年视角"><span class="header-section-number">6.5</span> 开放研究问题（2018年视角）</a></li>
  </ul></li>
  <li><a href="#局限性与未解决的问题" id="toc-局限性与未解决的问题" class="nav-link" data-scroll-target="#局限性与未解决的问题"><span class="header-section-number">7</span> 局限性与未解决的问题</a>
  <ul class="collapse">
  <li><a href="#分离式双向的根本缺陷" id="toc-分离式双向的根本缺陷" class="nav-link" data-scroll-target="#分离式双向的根本缺陷"><span class="header-section-number">7.1</span> “分离式双向”的根本缺陷</a></li>
  <li><a href="#特征提取范式的局限" id="toc-特征提取范式的局限" class="nav-link" data-scroll-target="#特征提取范式的局限"><span class="header-section-number">7.2</span> 特征提取范式的局限</a></li>
  <li><a href="#lstm的可扩展性问题" id="toc-lstm的可扩展性问题" class="nav-link" data-scroll-target="#lstm的可扩展性问题"><span class="header-section-number">7.3</span> LSTM的可扩展性问题</a></li>
  <li><a href="#这些局限导向了什么" id="toc-这些局限导向了什么" class="nav-link" data-scroll-target="#这些局限导向了什么"><span class="header-section-number">7.4</span> 这些局限导向了什么？</a></li>
  </ul></li>
  <li><a href="#本章小结" id="toc-本章小结" class="nav-link" data-scroll-target="#本章小结"><span class="header-section-number">8</span> 本章小结</a>
  <ul class="collapse">
  <li><a href="#核心要点回顾" id="toc-核心要点回顾" class="nav-link" data-scroll-target="#核心要点回顾"><span class="header-section-number">8.1</span> 核心要点回顾</a></li>
  <li><a href="#关键公式速查" id="toc-关键公式速查" class="nav-link" data-scroll-target="#关键公式速查"><span class="header-section-number">8.2</span> 关键公式速查</a></li>
  <li><a href="#思考题" id="toc-思考题" class="nav-link" data-scroll-target="#思考题"><span class="header-section-number">8.3</span> 思考题</a></li>
  </ul></li>
  <li><a href="#延伸阅读" id="toc-延伸阅读" class="nav-link" data-scroll-target="#延伸阅读"><span class="header-section-number">9</span> 延伸阅读</a>
  <ul class="collapse">
  <li><a href="#核心论文必读" id="toc-核心论文必读" class="nav-link" data-scroll-target="#核心论文必读"><span class="header-section-number">9.1</span> 核心论文（必读）</a></li>
  <li><a href="#前驱工作" id="toc-前驱工作" class="nav-link" data-scroll-target="#前驱工作"><span class="header-section-number">9.2</span> 前驱工作</a></li>
  <li><a href="#后续发展" id="toc-后续发展" class="nav-link" data-scroll-target="#后续发展"><span class="header-section-number">9.3</span> 后续发展</a></li>
  <li><a href="#分析与探针研究" id="toc-分析与探针研究" class="nav-link" data-scroll-target="#分析与探针研究"><span class="header-section-number">9.4</span> 分析与探针研究</a></li>
  <li><a href="#综述与教程" id="toc-综述与教程" class="nav-link" data-scroll-target="#综述与教程"><span class="header-section-number">9.5</span> 综述与教程</a></li>
  <li><a href="#代码资源" id="toc-代码资源" class="nav-link" data-scroll-target="#代码资源"><span class="header-section-number">9.6</span> 代码资源</a></li>
  </ul></li>
  <li><a href="#历史注脚" id="toc-历史注脚" class="nav-link" data-scroll-target="#历史注脚"><span class="header-section-number">10</span> 历史注脚</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">第11章：上下文词向量——ELMo</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">从静态词典到动态阅读：让词的表示随语境而变</p>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">Pre-training</div>
    <div class="quarto-category">ELMo</div>
    <div class="quarto-category">Contextual Embeddings</div>
  </div>
  </div>

<div>
  <div class="description">
    ELMo：第一个生成上下文相关词向量的预训练模型。通过深层双向LSTM语言模型，让同一个词在不同语境中拥有不同的向量表示，标志着从’词典式’到’阅读式’词向量的范式转变。
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ying Zha </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 26, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><strong>核心问题</strong>：如何让词的向量表示随上下文而变化，使得同一个词在不同语境中拥有不同的表示？</p>
<p><strong>历史坐标</strong>：2018 | Peters et al.&nbsp;“Deep contextualized word representations” | 从静态词向量到上下文词向量的范式转变</p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>本章参考来源
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="论文" class="level3" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="论文"><span class="header-section-number">0.1</span> 论文</h3>
<ul>
<li><strong>Peters et al.&nbsp;(2018)</strong> “Deep contextualized word representations” (arXiv:1802.05365) — 参考了 Section 3（biLM架构、ELMo公式）、Section 5（层级分析）、Figure 1-2、Table 1-6</li>
<li><strong>Peters et al.&nbsp;(2017)</strong> “Semi-supervised sequence tagging with bidirectional language models” (TagLM) — 参考了与ELMo的对比</li>
<li><strong>McCann et al.&nbsp;(2017)</strong> “Learned in Translation: Contextualized Word Vectors” (CoVe) — 参考了设计路线对比</li>
</ul>
</section>
<section id="教材" class="level3" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="教材"><span class="header-section-number">0.2</span> 教材</h3>
<ul>
<li><strong>D2L</strong> Section 15.8 (BERT) — 参考了ELMo/GPT/BERT对比图 (<code>elmo-gpt-bert.svg</code>) 和教学组织方式</li>
<li><strong>SLP3</strong> Chapter 10 (Masked Language Models and Contextual Embeddings) — 参考了上下文词向量的动机铺设</li>
</ul>
</section>
<section id="课程" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="课程"><span class="header-section-number">0.3</span> 课程</h3>
<ul>
<li><strong>Stanford CS224N</strong> Lecture 14 (2020) “Contextual Word Representations” — 参考了”shallowly bidirectional”的讲解角度、TagLM→ELMo→ULMFiT→BERT的教学递进、feature-based vs fine-tuning对比框架</li>
<li><strong>Jay Alammar</strong> “The Illustrated BERT, ELMo, and co.” — 参考了ELMo架构可视化的设计思路</li>
</ul>
</section>
</div>
</div>
</div>
<hr>
<section id="从上一章说起" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="从上一章说起"><span class="header-section-number">1</span> 从上一章说起</h2>
<p>上一章我们追溯了预训练思想的起源。从Word2Vec的词向量预训练，到CV领域ImageNet的深层迁移启示，再到ULMFiT的完整预训练-微调框架，预训练范式在2017年底已经初具雏形。特别是ULMFiT证明了一个重要命题：NLP也可以像CV一样，通过”先在大数据上预训练、再在小数据上微调”的方式大幅提升性能。</p>
<p>然而，上一章结尾我们也揭示了当时预训练方法的三个根本局限。</p>
<p>第一个局限是<strong>静态词向量的一词多义问题</strong>。Word2Vec和GloVe为每个词分配一个固定的向量，无论它出现在什么上下文中。“I went to the <strong>bank</strong> to deposit money”中的bank和”I sat on the <strong>bank</strong> of the river”中的bank，共享同一个向量。这种”一词一向量”的设计无法捕获语言中普遍存在的多义现象。</p>
<p>第二个局限是<strong>浅层迁移的天花板</strong>。使用预训练词向量本质上只迁移了模型最底层（Embedding层）的知识，更高层次的句法结构、语义组合、篇章逻辑仍然需要从零学习。这就像给学生发了一本词典就让他参加阅读理解考试——认识词和理解文章之间还有巨大的鸿沟。</p>
<p>第三个局限是<strong>预训练目标与下游任务的脱节</strong>。Word2Vec学到的是”哪些词经常一起出现”，但这与下游任务（如”哪些词表达正面情感”）之间的关联是间接的、不完美的。</p>
<p>这三个局限指向了一个共同的方向：我们需要能够生成<strong>上下文相关的、深层的</strong>语言表示的预训练方法。</p>
<p>2018年初，Allen Institute for AI的Matthew Peters等人在论文”Deep contextualized word representations”中提出了ELMo（Embeddings from Language Models），给出了第一个令人信服的答案。</p>
<blockquote class="blockquote">
<p>💡 <strong>本章核心洞察</strong>：不要给每个词一个固定的向量，而是用一个在大规模文本上预训练的深层双向LSTM语言模型，根据上下文为每个词<strong>动态生成</strong>向量表示。更妙的是，不同层的LSTM捕获了不同层次的语言信息——低层偏句法、高层偏语义——让下游任务自动学习如何混合这些层次的信息。</p>
</blockquote>
<hr>
</section>
<section id="问题的本质是什么" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="问题的本质是什么"><span class="header-section-number">2</span> 问题的本质是什么？</h2>
<section id="一词多义不是边缘案例而是语言的常态" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="一词多义不是边缘案例而是语言的常态"><span class="header-section-number">2.1</span> 一词多义：不是边缘案例，而是语言的常态</h3>
<p>在正式介绍ELMo之前，让我们先深入理解”一词多义”问题的严重性——它不是一个可以忽略的边缘情况，而是自然语言的核心特征。</p>
<p>考虑英语中最常见的动词之一”run”。在不同语境中，它的含义截然不同：</p>
<ul>
<li>“I <strong>run</strong> every morning.”（跑步——身体运动）</li>
<li>“She <strong>runs</strong> a company.”（经营——管理行为）</li>
<li>“The program <strong>runs</strong> slowly.”（运行——计算机执行）</li>
<li>“His nose <strong>runs</strong> in winter.”（流——液体流动）</li>
<li>“The road <strong>runs</strong> along the coast.”（延伸——空间分布）</li>
</ul>
<p>这五个”run”的语义差异巨大，但在Word2Vec/GloVe中它们共享同一个300维向量。这个向量是所有含义的”平均”——它既不完美地代表”跑步”，也不完美地代表”经营”，而是一个模糊的折中。</p>
<p>这个问题有多普遍？根据WordNet的统计，英语中最常用的1000个词平均每个词有3.5个不同的义项。某些高频词的义项数量惊人：Merriam-Webster词典为”set”列出了超过430个义项，“run”超过370个。一词多义不是例外，而是规则。</p>
</section>
<section id="之前的尝试为何不够" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="之前的尝试为何不够"><span class="header-section-number">2.2</span> 之前的尝试为何不够？</h3>
<p>在ELMo之前，研究者已经意识到了这个问题，并尝试了一些解决方案。</p>
<p><strong>多义词向量（Multi-Sense Embeddings）</strong>。Reisinger &amp; Mooney (2010)和Huang et al.&nbsp;(2012)提出为每个词学习多个向量，每个向量对应一个义项。例如，“bank”有两个向量：一个对应”银行”，一个对应”河岸”。使用时通过聚类或注意力机制选择合适的向量。这个思路直觉上很合理，但实践中面临几个困难：义项数量需要预先指定、义项之间的边界往往模糊（“bank”在”central bank”和”blood bank”中的含义是同一个义项还是不同义项？）、而且无法处理从未见过的新用法。</p>
<p><strong>上下文嵌入的早期尝试</strong>。Melamud et al.&nbsp;(2016)提出了context2vec，用双向LSTM的隐状态来表示上下文，然后用上下文向量替代或增强词向量。这个方向是正确的，但模型规模和训练数据有限，效果未达到足够的影响力。</p>
<p>这些尝试的共同问题在于：它们仍然把”词义消歧”当作一个需要显式解决的任务。ELMo的突破在于——<strong>不需要显式地为每个词划分义项，只需要用一个足够强的语言模型去”阅读”上下文，词义的区分自然就隐含在模型的内部表示中</strong>。</p>
</section>
<section id="我们需要什么样的解决方案" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="我们需要什么样的解决方案"><span class="header-section-number">2.3</span> 我们需要什么样的解决方案？</h3>
<p>理想的上下文词向量应该满足几个条件。</p>
<p>第一，<strong>上下文敏感</strong>：同一个词在不同上下文中应该有不同的向量表示。“bank”在金融语境和地理语境中的向量应该明显不同。</p>
<p>第二，<strong>可从无标注数据学习</strong>：上下文词向量应该从大规模无标注文本中学习，而非依赖昂贵的人工义项标注。</p>
<p>第三，<strong>即插即用</strong>：上下文词向量应该能够轻松融入已有的NLP模型架构，作为”升级版”的词向量替换原来的静态词向量，而不需要彻底重新设计下游模型。</p>
<p>第四，<strong>多层次信息</strong>：不仅要捕获词义（语义），还应该捕获句法信息（词性、依存关系），因为不同的下游任务可能需要不同层次的语言信息。</p>
<p>ELMo的设计精确地满足了这四个条件。</p>
<hr>
</section>
</section>
<section id="核心思想与直觉" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="核心思想与直觉"><span class="header-section-number">3</span> 核心思想与直觉</h2>
<section id="关键洞察让语言模型替你读上下文" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="关键洞察让语言模型替你读上下文"><span class="header-section-number">3.1</span> 关键洞察：让语言模型替你”读”上下文</h3>
<p>ELMo的核心思想可以用一个直觉的类比来理解。</p>
<p>想象你在查一本传统词典。当你查找”bank”这个词时，词典会给你一个词条，列出它的所有含义。你需要自己根据上下文判断此处是哪个含义。静态词向量就是这种”词典模式”——给你一个固定的表示，让你自己去消歧。</p>
<p>现在想象一种”智能词典”：它不是给你”bank”的通用定义，而是在你标记出”bank”出现的那个句子后，词典会<strong>阅读整个句子</strong>，然后告诉你”在这个语境中，bank的含义最接近’金融机构’，这是它在当前语境下的精确语义向量”。这就是ELMo的工作方式。</p>
<p>而这个”智能词典”是怎么获得阅读理解能力的呢？答案是<strong>语言模型预训练</strong>。通过在数十亿词的文本上训练语言模型（预测下一个词和上一个词），ELMo的底层双向LSTM学会了丰富的语言知识。当它看到”I deposited money at the bank”时，前向LSTM从”I deposited money at the”这些左侧上下文中推断出bank很可能是金融机构；后向LSTM则从句末的信息提供了额外的确认。两个方向的LSTM隐状态拼接在一起，就构成了bank在这个特定语境中的上下文表示。</p>
</section>
<section id="elmo的三个核心设计决策" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="elmo的三个核心设计决策"><span class="header-section-number">3.2</span> ELMo的三个核心设计决策</h3>
<p>ELMo的设计包含三个关键决策，每一个都有深思熟虑的理由。</p>
<p><strong>决策一：用语言模型作为预训练任务</strong>。这个选择承继了上一章讨论的思想脉络——语言模型目标不需要任何标注数据，只需要原始文本。更重要的是，语言模型迫使模型理解语言的深层结构：要准确预测下一个词，模型必须理解语法（名词后面通常不会接另一个名词）、语义（“the capital of France is”后面应该是”Paris”）和常识推理（“after the rain, the streets were”后面可能是”wet”）。这比Word2Vec的共现预测要求更高层次的理解能力。</p>
<p><strong>决策二：用双向LSTM而非单向</strong>。语言理解需要同时利用左侧上下文和右侧上下文。“I went to the <strong>bank</strong>”中的bank可能是银行也可能是河岸，但如果你看到右侧是”to deposit money”，含义就明确了。单向语言模型只能看到一个方向的上下文，双向则可以综合两个方向的信息。</p>
<p><strong>决策三：暴露所有层的表示，而非只用最顶层</strong>。这是ELMo最独特的设计。传统做法是只使用模型最顶层的输出，但Peters等人发现，<strong>不同层捕获了不同类型的语言信息</strong>：底层偏向句法信息（词性、依存关系），顶层偏向语义信息（词义消歧、情感）。不同的下游任务可能需要不同层次的信息——词性标注可能更需要底层的句法信息，而情感分析可能更需要顶层的语义信息。ELMo让下游任务<strong>自动学习</strong>如何混合不同层的信息。</p>
</section>
<section id="elmogptbert的架构对比" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="elmogptbert的架构对比"><span class="header-section-number">3.3</span> ELMo、GPT、BERT的架构对比</h3>
<p>在正式进入技术细节之前，先从宏观视角看一下ELMo在预训练技术演进中的位置。下图展示了ELMo、GPT和BERT三种预训练方法的架构对比——它们分别代表了2018年出现的三条不同路线：</p>
<div id="fig-elmo-gpt-bert" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-elmo-gpt-bert-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-11/original/fig-elmo-gpt-bert-d2l.svg" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-elmo-gpt-bert-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: ELMo、GPT 和 BERT 三种预训练架构的对比。ELMo 使用双向 LSTM 并通过特征拼接迁移（左）；GPT 使用单向 Transformer Decoder 并通过微调迁移（中）；BERT 使用双向 Transformer Encoder 并通过微调迁移（右）。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Dive into Deep Learning, Figure 15.8.1. <a href="https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html">d2l.ai</a></em></p>
</div>
<p>从图中可以直观地看到ELMo的两个关键特征：它使用双向LSTM（而非Transformer），并且将预训练模型的输出作为”特征”拼接到下游模型中（而非像GPT/BERT那样直接微调整个模型）。这两个选择既是ELMo的特色，也是它后来被超越的原因——我们将在本章末尾的”局限性”一节详细讨论。</p>
<hr>
</section>
</section>
<section id="技术细节" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="技术细节"><span class="header-section-number">4</span> 技术细节</h2>
<section id="双向语言模型bilm" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="双向语言模型bilm"><span class="header-section-number">4.1</span> 双向语言模型（biLM）</h3>
<p>ELMo的基础是一个<strong>双向语言模型（bidirectional Language Model, biLM）</strong>。让我们从数学上精确定义它。</p>
<p>给定一个长度为<span class="math inline">\(N\)</span>的词序列<span class="math inline">\((t_1, t_2, \ldots, t_N)\)</span>，<strong>前向语言模型</strong>通过给定前缀来预测下一个词，建模序列的联合概率：</p>
<p><span class="math display">\[
p(t_1, t_2, \ldots, t_N) = \prod_{k=1}^{N} p(t_k \mid t_1, t_2, \ldots, t_{k-1})
\]</span></p>
<p>在ELMo中，前向语言模型用一个<span class="math inline">\(L\)</span>层的LSTM来实现。在位置<span class="math inline">\(k\)</span>，第<span class="math inline">\(j\)</span>层LSTM产生一个上下文相关的隐状态<span class="math inline">\(\overrightarrow{\mathbf{h}}_{k,j}\)</span>（<span class="math inline">\(j = 1, 2, \ldots, L\)</span>）。最顶层的隐状态<span class="math inline">\(\overrightarrow{\mathbf{h}}_{k,L}\)</span>通过一个softmax层来预测下一个词<span class="math inline">\(t_{k+1}\)</span>。</p>
<p>对称地，<strong>后向语言模型</strong>通过给定后缀来预测前一个词：</p>
<p><span class="math display">\[
p(t_1, t_2, \ldots, t_N) = \prod_{k=1}^{N} p(t_k \mid t_{k+1}, t_{k+2}, \ldots, t_N)
\]</span></p>
<p>后向语言模型同样用<span class="math inline">\(L\)</span>层LSTM实现，在位置<span class="math inline">\(k\)</span>产生隐状态<span class="math inline">\(\overleftarrow{\mathbf{h}}_{k,j}\)</span>。</p>
<p>biLM的训练目标是<strong>同时最大化前向和后向的对数似然</strong>：</p>
<p><span class="math display">\[
\sum_{k=1}^{N}\left(\log p(t_k \mid t_1, \ldots, t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) + \log p(t_k \mid t_{k+1}, \ldots, t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s)\right)
\]</span></p>
<p>这里有一个关键的细节：前向和后向LSTM的参数是<strong>独立的</strong>（<span class="math inline">\(\overrightarrow{\Theta}_{LSTM} \neq \overleftarrow{\Theta}_{LSTM}\)</span>），但它们<strong>共享</strong>词嵌入层<span class="math inline">\(\Theta_x\)</span>和softmax层<span class="math inline">\(\Theta_s\)</span>的参数。共享这两层的理由是：无论从哪个方向阅读，词本身的基础表示和输出词汇分布应该是一致的。而LSTM参数独立的理由是：从左到右阅读和从右到左阅读是两种不同的”阅读方式”，需要各自独立学习。</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Algorithm 1: biLM Pre-training（改编自 Peters et al., 2018）
</div>
</div>
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_biLM(corpus, vocab_size, L<span class="op">=</span><span class="dv">2</span>, d_lstm<span class="op">=</span><span class="dv">4096</span>, d_proj<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    双向语言模型预训练</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">    架构: Character CNN → L层 biLSTM (每层 d_lstm 维, 投影到 d_proj 维)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    训练数据: 1B Word Benchmark (~8亿词)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 初始化</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    char_cnn <span class="op">=</span> CharacterCNN(filters<span class="op">=</span>[<span class="fl">1..7</span>], output_dim<span class="op">=</span><span class="dv">512</span>)     <span class="co"># 字符级词嵌入</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    forward_lstm <span class="op">=</span> StackedLSTM(L, d_lstm, d_proj, residual<span class="op">=</span><span class="va">True</span>) <span class="co"># 前向 LSTM</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    backward_lstm <span class="op">=</span> StackedLSTM(L, d_lstm, d_proj, residual<span class="op">=</span><span class="va">True</span>) <span class="co"># 后向 LSTM (独立参数)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    softmax <span class="op">=</span> SharedSoftmax(d_proj, vocab_size)                  <span class="co"># 前后向共享</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> corpus:</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> batch  <span class="co"># (t_1, t_2, ..., t_N)</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: 字符级词嵌入 (前后向共享 Θ_x)</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> char_cnn(tokens)  <span class="co"># [N, 512]</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: 前向 LM — 用 (t_1,...,t_{k-1}) 预测 t_k</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        h_fwd <span class="op">=</span> forward_lstm(x)                <span class="co"># [N, L, d_proj]</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        loss_fwd <span class="op">=</span> cross_entropy(softmax(h_fwd[<span class="op">-</span><span class="dv">1</span>]), tokens[<span class="dv">1</span>:])</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 3: 后向 LM — 用 (t_{k+1},...,t_N) 预测 t_k</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>        h_bwd <span class="op">=</span> backward_lstm(reverse(x))      <span class="co"># [N, L, d_proj]</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>        loss_bwd <span class="op">=</span> cross_entropy(softmax(h_bwd[<span class="op">-</span><span class="dv">1</span>]), tokens[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 4: 联合优化</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fwd <span class="op">+</span> loss_bwd</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>改编自 Peters et al.&nbsp;(2018) “Deep contextualized word representations”, Section 3.1. <a href="https://arxiv.org/abs/1802.05365">arXiv:1802.05365</a></em></p>
</div>
</div>
</section>
<section id="elmo表示的构造" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="elmo表示的构造"><span class="header-section-number">4.2</span> ELMo表示的构造</h3>
<p>biLM训练完成后，对于每个词<span class="math inline">\(t_k\)</span>，我们可以从模型中提取<span class="math inline">\(2L + 1\)</span>个表示：</p>
<p><span class="math display">\[
R_k = \{\mathbf{x}_k^{LM},\; \overrightarrow{\mathbf{h}}_{k,j}^{LM},\; \overleftarrow{\mathbf{h}}_{k,j}^{LM} \mid j = 1, \ldots, L\}
\]</span></p>
<p>其中<span class="math inline">\(\mathbf{x}_k^{LM}\)</span>是第0层的词嵌入（上下文无关），<span class="math inline">\(\overrightarrow{\mathbf{h}}_{k,j}^{LM}\)</span>和<span class="math inline">\(\overleftarrow{\mathbf{h}}_{k,j}^{LM}\)</span>分别是第<span class="math inline">\(j\)</span>层前向和后向LSTM的隐状态。</p>
<p>为了简化符号，我们将每一层的前向和后向隐状态拼接为一个向量：</p>
<p><span class="math display">\[
\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j}^{LM};\; \overleftarrow{\mathbf{h}}_{k,j}^{LM}]
\]</span></p>
<p>对于第0层，<span class="math inline">\(\mathbf{h}_{k,0}^{LM} = \mathbf{x}_k^{LM}\)</span>（或者说词嵌入经过字符CNN后的输出，下文会详细讨论）。</p>
<p>这样，ELMo对词<span class="math inline">\(t_k\)</span>的表示定义为<strong>所有层表示的加权和</strong>：</p>
<p><span class="math display">\[
\text{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^{L} s_j^{task}\; \mathbf{h}_{k,j}^{LM}
\]</span></p>
<p>这个公式是ELMo的核心，值得仔细分解理解。</p>
<p><span class="math inline">\(s_j^{task}\)</span>是<strong>softmax归一化的层权重</strong>：<span class="math inline">\(s_j^{task} = \frac{\exp(w_j)}{\sum_{j'} \exp(w_{j'})}\)</span>，其中<span class="math inline">\(w_j\)</span>是可学习的标量参数。这些权重在下游任务的训练过程中学习，不同任务会学到不同的层权重——这正是ELMo”让下游任务自动选择所需信息层次”的机制。</p>
<p><span class="math inline">\(\gamma^{task}\)</span>是一个<strong>任务特定的缩放因子</strong>，也是可学习的。它的作用是调整ELMo表示的整体幅度，使其与下游模型的其他组件（如原始词向量、手工特征）在数值尺度上匹配。</p>
<p>你可能会问：为什么不直接学习<span class="math inline">\(L+1\)</span>个权重<span class="math inline">\(\alpha_j\)</span>（不经过softmax归一化），而要分成<span class="math inline">\(s_j\)</span>和<span class="math inline">\(\gamma\)</span>两部分？Peters等人发现，这种分离有助于稳定训练——softmax确保层权重加和为1，起到了正则化的作用，而<span class="math inline">\(\gamma\)</span>单独负责幅度调整。</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Algorithm 2: ELMo Representation Computation（改编自 Peters et al., 2018）
</div>
</div>
<div class="callout-body-container callout-body">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_elmo(tokens, pretrained_biLM, task_weights, task_gamma):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    从预训练 biLM 中提取 ELMo 表示</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">        tokens: 输入词序列 (t_1, ..., t_N)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">        pretrained_biLM: 已预训练的 biLM (参数冻结)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">        task_weights: 可学习的层权重 w_j (j=0,...,L), 下游任务训练时学习</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">        task_gamma: 可学习的缩放因子, 下游任务训练时学习</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">        elmo: [N, d] 的上下文词向量</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># biLM 参数冻结</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: 提取各层表示</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> pretrained_biLM.char_cnn(tokens)       <span class="co"># h_{k,0}: [N, 512]</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        h_fwd <span class="op">=</span> pretrained_biLM.forward_lstm(x)     <span class="co"># [N, L, d_proj]</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        h_bwd <span class="op">=</span> pretrained_biLM.backward_lstm(x)    <span class="co"># [N, L, d_proj]</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: 拼接前向和后向</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> []</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        h.append(x)                                 <span class="co"># 第0层: 上下文无关</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(L):</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            h.append(concat(h_fwd[:,j,:], h_bwd[:,j,:]))  <span class="co"># 第j层: [N, 2*d_proj]</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: 计算加权和 (此部分参数可学习)</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> softmax(task_weights)          <span class="co"># 归一化层权重, Σ s_j = 1</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    elmo <span class="op">=</span> task_gamma <span class="op">*</span> <span class="bu">sum</span>(s[j] <span class="op">*</span> h[j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(L<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> elmo  <span class="co"># [N, 1024] (2 * 512)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>改编自 Peters et al.&nbsp;(2018) “Deep contextualized word representations”, Section 3.2-3.3. <a href="https://arxiv.org/abs/1802.05365">arXiv:1802.05365</a></em></p>
</div>
</div>
</section>
<section id="架构细节" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="架构细节"><span class="header-section-number">4.3</span> 架构细节</h3>
<p>ELMo的biLM在具体实现上有几个重要的工程决策。</p>
<p><strong>字符级卷积（Character CNN）作为词嵌入</strong>。ELMo不使用传统的词级别lookup表，而是用字符级CNN来构建词表示。具体来说，每个词的字符序列经过一组不同宽度的卷积核（窗口大小1到7），然后经过max-pooling和两层highway network，得到一个512维的词表示。</p>
<p>这个设计的好处是显著的。首先，它天然地解决了<strong>OOV（Out-of-Vocabulary）问题</strong>——即使遇到从未见过的词，字符CNN也能根据字符模式生成合理的表示。“unhappiness”虽然可能不在词汇表中，但字符CNN可以从”un-“（否定前缀）、”happy”（核心语义）和”-ness”（名词后缀）中组合出合理的表示。其次，它自动捕获了<strong>形态学信息</strong>——同一词族的词（如run, runs, running, runner）会有相似的字符级表示。</p>
<p><strong>LSTM的规模与投影</strong>。ELMo使用<span class="math inline">\(L=2\)</span>层biLSTM，每层每个方向有4096个隐藏单元。这意味着每层的前向和后向拼接后有<span class="math inline">\(4096 \times 2 = 8192\)</span>维。为了减小计算和内存开销，每层的LSTM输出通过一个线性投影映射到512维，然后再输入到下一层。</p>
<p><strong>残差连接</strong>。第一层和第二层LSTM之间有残差连接，有助于梯度流动和训练稳定性。</p>
<p><strong>总参数量</strong>。整个biLM约有<strong>93.6M（约9360万）</strong>参数。与同期的模型相比，这个规模并不小（GPT-1有1.17亿参数，BERT-Base有1.1亿参数），但ELMo将所有参数都用在了LSTM上，而GPT和BERT则使用Transformer架构。</p>
</section>
<section id="elmo架构总览" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="elmo架构总览"><span class="header-section-number">4.4</span> ELMo架构总览</h3>
<p>在进入数值示例之前，让我们先从整体上理解ELMo的架构。下图展示了ELMo的完整信息流：从字符级输入到最终的上下文词向量。</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>📌 待绘制：ELMo架构图
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>内容描述</strong>：ELMo的完整架构示意图，展示从输入到输出的信息流。</p>
<p><strong>应包含的元素</strong>：</p>
<ol type="1">
<li><strong>输入层</strong>（底部）：字符序列 → Character CNN（7种卷积核 + max-pooling + highway network）→ 512维词嵌入 <span class="math inline">\(\mathbf{x}_k\)</span></li>
<li><strong>第1层 biLSTM</strong>：前向LSTM（4096维 → 投影至512维）和后向LSTM（4096维 → 投影至512维），拼接为1024维 <span class="math inline">\(\mathbf{h}_{k,1}\)</span></li>
<li><strong>残差连接</strong>：第1层到第2层之间</li>
<li><strong>第2层 biLSTM</strong>：结构同第1层，输出1024维 <span class="math inline">\(\mathbf{h}_{k,2}\)</span></li>
<li><strong>ELMo混合层</strong>（顶部）：<span class="math inline">\(s_0 \cdot \mathbf{h}_0 + s_1 \cdot \mathbf{h}_1 + s_2 \cdot \mathbf{h}_2\)</span>，乘以 <span class="math inline">\(\gamma\)</span></li>
<li><strong>标注关键维度</strong>：512, 4096, 512(投影), 1024(拼接)</li>
</ol>
<p><strong>视觉风格</strong>：纵向堆叠，左右对称（前向/后向），参考 Jay Alammar “The Illustrated BERT, ELMo” 的风格。</p>
<p><strong>建议工具</strong>：D2L/UDL风格的SVG，或使用TikZ/matplotlib生成。</p>
</div>
</div>
</section>
<section id="完整数值示例从输入到elmo表示" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="完整数值示例从输入到elmo表示"><span class="header-section-number">4.5</span> 完整数值示例：从输入到ELMo表示</h3>
<p>让我们通过一个简化的数值例子来完整理解ELMo的工作流程。为了可手算，我们将所有维度大幅缩小。</p>
<p><strong>设定</strong>：</p>
<ul>
<li>两个句子：“I deposited money at the <strong>bank</strong>” 和 “I fished along the river <strong>bank</strong>”</li>
<li>简化参数：词嵌入维度 <span class="math inline">\(d = 4\)</span>，LSTM隐藏维度 <span class="math inline">\(h = 3\)</span>，<span class="math inline">\(L = 2\)</span>层</li>
<li>目标：对比两个句子中”bank”的ELMo表示</li>
</ul>
<p><strong>Step 1: 词嵌入（第0层，上下文无关）</strong></p>
<p>假设字符CNN为”bank”生成的嵌入在两个句子中相同（因为词本身一样）：</p>
<p><span class="math display">\[
\mathbf{h}_{bank, 0}^{LM} = [0.5,\; -0.2,\; 0.8,\; 0.1]
\]</span></p>
<p>这是上下文无关的表示——两个句子中的bank在这一层完全一样。</p>
<p><strong>Step 2: 第1层biLSTM处理</strong></p>
<p>前向LSTM从左到右阅读句子。</p>
<p><em>句子1</em>：“I deposited money at the <strong>bank</strong>”</p>
<p>前向LSTM在读到bank时，隐状态已经编码了”I deposited money at the”的信息。“deposited”和”money”提供了强烈的金融语境信号：</p>
<p><span class="math display">\[
\overrightarrow{\mathbf{h}}_{bank, 1}^{(S1)} = [0.8,\; 0.3,\; -0.1] \quad \text{（编码了"deposited money"的金融信号）}
\]</span></p>
<p>后向LSTM在bank位置的隐状态编码了句尾信息（这个简化例子中句尾就是bank本身，信息有限）：</p>
<p><span class="math display">\[
\overleftarrow{\mathbf{h}}_{bank, 1}^{(S1)} = [0.2,\; 0.5,\; 0.1]
\]</span></p>
<p>拼接得到：</p>
<p><span class="math display">\[
\mathbf{h}_{bank, 1}^{(S1)} = [0.8,\; 0.3,\; -0.1,\; 0.2,\; 0.5,\; 0.1]
\]</span></p>
<p><em>句子2</em>：“I fished along the river <strong>bank</strong>”</p>
<p>前向LSTM编码了”I fished along the river”的信息。“fished”和”river”提供了自然/地理语境信号：</p>
<p><span class="math display">\[
\overrightarrow{\mathbf{h}}_{bank, 1}^{(S2)} = [-0.3,\; 0.7,\; 0.6] \quad \text{（编码了"fished, river"的自然信号）}
\]</span></p>
<p><span class="math display">\[
\overleftarrow{\mathbf{h}}_{bank, 1}^{(S2)} = [0.1,\; 0.4,\; 0.3]
\]</span></p>
<p>拼接得到：</p>
<p><span class="math display">\[
\mathbf{h}_{bank, 1}^{(S2)} = [-0.3,\; 0.7,\; 0.6,\; 0.1,\; 0.4,\; 0.3]
\]</span></p>
<p><strong>关键观察</strong>：虽然两个句子中的”bank”是同一个词，但第1层的表示已经不同了——因为LSTM编码了不同的上下文信息。</p>
<p><strong>Step 3: 第2层biLSTM处理</strong></p>
<p>第2层在第1层的基础上进一步抽象，捕获更高层次的语义信息。</p>
<p><em>句子1</em>：<span class="math inline">\(\mathbf{h}_{bank, 2}^{(S1)} = [0.9,\; 0.1,\; -0.5,\; 0.3,\; 0.6,\; -0.2]\)</span></p>
<p><em>句子2</em>：<span class="math inline">\(\mathbf{h}_{bank, 2}^{(S2)} = [-0.6,\; 0.8,\; 0.4,\; 0.0,\; 0.3,\; 0.7]\)</span></p>
<p>第2层的差异更加明显，因为更高层更能区分”金融bank”和”地理bank”的语义差异。</p>
<p><strong>Step 4: 构造ELMo表示</strong></p>
<p>假设我们在下游的<strong>情感分析任务</strong>上学到的层权重为：</p>
<p><span class="math display">\[
s_0 = 0.1, \quad s_1 = 0.3, \quad s_2 = 0.6
\]</span></p>
<p>（情感分析偏重语义，所以第2层权重最大。）</p>
<p>缩放因子 <span class="math inline">\(\gamma = 1.0\)</span>。</p>
<p><em>句子1中bank的ELMo表示</em>（简化为只取前4维展示）：</p>
<p><span class="math display">\[
\text{ELMo}_{bank}^{(S1)} = 1.0 \times (0.1 \times \mathbf{h}_0 + 0.3 \times \mathbf{h}_1^{(S1)} + 0.6 \times \mathbf{h}_2^{(S1)})
\]</span></p>
<p><em>句子2中bank的ELMo表示</em>：</p>
<p><span class="math display">\[
\text{ELMo}_{bank}^{(S2)} = 1.0 \times (0.1 \times \mathbf{h}_0 + 0.3 \times \mathbf{h}_1^{(S2)} + 0.6 \times \mathbf{h}_2^{(S2)})
\]</span></p>
<p>由于第1层和第2层的隐状态在两个句子中不同，最终的ELMo表示也不同。</p>
<p><strong>解读</strong>：同一个词”bank”在两个句子中获得了不同的ELMo向量。金融语境下的bank向量与”deposited”“money”等金融词更接近，地理语境下的bank向量则与”river”“fished”等自然词更接近。语言模型自动完成了词义消歧，无需任何显式的义项标注。</p>
<p>如果下游任务换成<strong>词性标注</strong>，学到的层权重可能变为 <span class="math inline">\(s_0 = 0.2, s_1 = 0.6, s_2 = 0.2\)</span>——因为词性标注更依赖句法信息（第1层），而非高层语义（第2层）。</p>
</section>
<section id="下游任务的使用方式" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="下游任务的使用方式"><span class="header-section-number">4.6</span> 下游任务的使用方式</h3>
<p>ELMo的使用方式非常简单——作为”特征增强”即插即用地加入已有模型。</p>
<p>给定一个已有的NLP模型（如BiLSTM-CRF用于NER，或Bi-Attention用于SQuAD），它原本的输入是静态词向量<span class="math inline">\(\mathbf{x}_k\)</span>。使用ELMo后，将输入替换为拼接：</p>
<p><span class="math display">\[
[\mathbf{x}_k;\; \text{ELMo}_k^{task}]
\]</span></p>
<p>也就是将原始的词向量和ELMo表示拼接在一起，作为模型的新输入。有时，也会在模型的中间层（如LSTM的输出层）再次加入ELMo表示。</p>
<p>训练时，biLM的参数<strong>冻结不变</strong>，只训练层权重<span class="math inline">\(s_j^{task}\)</span>、缩放因子<span class="math inline">\(\gamma^{task}\)</span>和下游模型的参数。这使得ELMo的使用非常高效——不需要对庞大的biLM进行反向传播。</p>
<p>Peters等人还发现，在ELMo表示上加一个适度的<strong>dropout</strong>可以起到正则化作用，防止下游模型过度依赖ELMo特征。</p>
</section>
<section id="复杂度分析" class="level3" data-number="4.7">
<h3 data-number="4.7" class="anchored" data-anchor-id="复杂度分析"><span class="header-section-number">4.7</span> 复杂度分析</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 54%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>维度</th>
<th>值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>模型参数</td>
<td>~93.6M（biLM预训练阶段）</td>
</tr>
<tr class="even">
<td>下游任务新增参数</td>
<td>仅 <span class="math inline">\(L + 2\)</span> 个标量（<span class="math inline">\(L+1\)</span>个层权重 <span class="math inline">\(+ 1\)</span>个缩放因子）</td>
</tr>
<tr class="odd">
<td>推理时间复杂度</td>
<td><span class="math inline">\(O(N \cdot d_{LSTM}^2 \cdot L)\)</span>，其中<span class="math inline">\(N\)</span>为序列长度</td>
</tr>
<tr class="even">
<td>推理空间复杂度</td>
<td><span class="math inline">\(O(N \cdot d_{LSTM} \cdot L)\)</span>，需要存储每层的隐状态</td>
</tr>
</tbody>
</table>
<p>ELMo在推理时需要对每个输入序列运行一次完整的biLSTM前向传播，这比简单的词向量查找要慢得多。但由于biLM参数冻结，不需要反向传播，所以在训练下游任务时的额外开销主要在前向计算上。</p>
</section>
<section id="与其他方法的对比" class="level3" data-number="4.8">
<h3 data-number="4.8" class="anchored" data-anchor-id="与其他方法的对比"><span class="header-section-number">4.8</span> 与其他方法的对比</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 30%">
<col style="width: 16%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>维度</th>
<th>静态词向量</th>
<th>ELMo</th>
<th>GPT (下一章)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>表示类型</td>
<td>上下文无关</td>
<td>上下文相关</td>
<td>上下文相关</td>
</tr>
<tr class="even">
<td>预训练架构</td>
<td>浅层网络</td>
<td>双向LSTM</td>
<td>单向Transformer</td>
</tr>
<tr class="odd">
<td>预训练任务</td>
<td>共现预测</td>
<td>双向语言建模</td>
<td>单向语言建模</td>
</tr>
<tr class="even">
<td>迁移方式</td>
<td>初始化Embedding</td>
<td>特征拼接（冻结）</td>
<td>整体微调</td>
</tr>
<tr class="odd">
<td>迁移深度</td>
<td>仅第0层</td>
<td>所有层（加权融合）</td>
<td>所有层</td>
</tr>
<tr class="even">
<td>下游任务适配</td>
<td>微调Embedding+训练上层</td>
<td>学习<span class="math inline">\(L+2\)</span>个标量+训练原模型</td>
<td>微调整个模型</td>
</tr>
<tr class="odd">
<td>多义词处理</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="工程实践" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="工程实践"><span class="header-section-number">5</span> 工程实践</h2>
<section id="使用allennlp提取elmo表示" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="使用allennlp提取elmo表示"><span class="header-section-number">5.1</span> 使用AllenNLP提取ELMo表示</h3>
<p>在ELMo发布后不久，Allen AI开源了ELMo的预训练模型和使用工具。以下是使用ELMo的标准工作流：</p>
<div id="7e58cc38" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 方式1：使用 AllenNLP 的 ELMo（原始实现）</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> allennlp.modules.elmo <span class="im">import</span> Elmo, batch_to_ids</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载预训练 ELMo 模型</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>options_file <span class="op">=</span> <span class="st">"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json"</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>weight_file <span class="op">=</span> <span class="st">"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5"</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># num_output_representations: 需要多少组不同的 ELMo 表示</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># （每组有独立的 s_j 和 gamma）</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>elmo <span class="op">=</span> Elmo(options_file, weight_file, num_output_representations<span class="op">=</span><span class="dv">1</span>, dropout<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 准备输入：将词转换为字符 ID</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"I"</span>, <span class="st">"deposited"</span>, <span class="st">"money"</span>, <span class="st">"at"</span>, <span class="st">"the"</span>, <span class="st">"bank"</span>],</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"I"</span>, <span class="st">"fished"</span>, <span class="st">"along"</span>, <span class="st">"the"</span>, <span class="st">"river"</span>, <span class="st">"bank"</span>]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>character_ids <span class="op">=</span> batch_to_ids(sentences)  <span class="co"># [batch=2, max_len=6, max_chars=50]</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 前向传播</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> elmo(character_ids)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># embeddings['elmo_representations']: list of [batch, seq_len, 1024]</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># embeddings['mask']: [batch, seq_len]</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>elmo_vectors <span class="op">=</span> embeddings[<span class="st">'elmo_representations'</span>][<span class="dv">0</span>]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># elmo_vectors.shape: [2, 6, 1024]</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 对比两个句子中 "bank"（位置5）的 ELMo 表示</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>bank_s1 <span class="op">=</span> elmo_vectors[<span class="dv">0</span>, <span class="dv">5</span>, :]  <span class="co"># 句子1中的 bank</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>bank_s2 <span class="op">=</span> elmo_vectors[<span class="dv">1</span>, <span class="dv">5</span>, :]  <span class="co"># 句子2中的 bank</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>similarity <span class="op">=</span> F.cosine_similarity(bank_s1.unsqueeze(<span class="dv">0</span>), bank_s2.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"两个 'bank' 的余弦相似度: </span><span class="sc">{</span>similarity<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 预期结果：约 0.6-0.7（明显低于 1.0，说明 ELMo 区分了两个含义）</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="将elmo集成到已有模型" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="将elmo集成到已有模型"><span class="header-section-number">5.2</span> 将ELMo集成到已有模型</h3>
<div id="f27b72f5" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> allennlp.modules.elmo <span class="im">import</span> Elmo, batch_to_ids</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ELMoSentimentClassifier(nn.Module):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""使用 ELMo 增强的情感分类器"""</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, glove_dim<span class="op">=</span><span class="dv">300</span>, elmo_dim<span class="op">=</span><span class="dv">1024</span>, hidden_dim<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                 num_classes<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ELMo 模块</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        options_file <span class="op">=</span> <span class="st">"..."</span>  <span class="co"># ELMo options JSON</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        weight_file <span class="op">=</span> <span class="st">"..."</span>  <span class="co"># ELMo weights HDF5</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.elmo <span class="op">=</span> Elmo(options_file, weight_file,</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>                         num_output_representations<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                         dropout<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>                         requires_grad<span class="op">=</span><span class="va">False</span>)  <span class="co"># 冻结 biLM 参数</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 输入维度 = GloVe + ELMo</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        input_dim <span class="op">=</span> glove_dim <span class="op">+</span> elmo_dim</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 下游分类模型</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_dim, hidden_dim, batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>                            bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(hidden_dim <span class="op">*</span> <span class="dv">2</span>, num_classes)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, glove_embeds, char_ids):</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co">        glove_embeds: [batch, seq_len, 300] 预训练 GloVe 向量</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co">        char_ids:     [batch, seq_len, max_chars] 字符 ID</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 获取 ELMo 表示</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        elmo_out <span class="op">=</span> <span class="va">self</span>.elmo(char_ids)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        elmo_embeds <span class="op">=</span> elmo_out[<span class="st">'elmo_representations'</span>][<span class="dv">0</span>]  <span class="co"># [batch, seq_len, 1024]</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 拼接 GloVe + ELMo</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([glove_embeds, elmo_embeds], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># combined: [batch, seq_len, 1324]</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 下游模型处理</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        lstm_out, (h_n, _) <span class="op">=</span> <span class="va">self</span>.lstm(combined)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        hidden <span class="op">=</span> torch.cat([h_n[<span class="dv">0</span>], h_n[<span class="dv">1</span>]], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(hidden)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练时，只有 lstm 和 classifier 的参数会被更新</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="co"># ELMo 内部的 biLM 参数冻结，但层权重 s_j 和 gamma 会学习</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="复现的关键细节" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="复现的关键细节"><span class="header-section-number">5.3</span> 复现的关键细节</h3>
<p>如果你要复现ELMo的原始实验或在自己的任务上使用ELMo，以下几个实现细节至关重要。</p>
<p><strong>字符级输入</strong>。ELMo的输入不是词ID，而是字符ID序列。每个词被表示为一个字符序列（最长50个字符），经过字符CNN后得到词表示。这意味着你的数据预处理管道需要保留原始字符形式，而不是只提供词级别的token。</p>
<p><strong>Dropout的位置</strong>。Peters等人推荐在ELMo表示上加dropout（通常0.5），而且是在拼接到下游模型之前加。这个dropout比直觉中的值要高，但在实践中确实能有效防止过拟合。</p>
<p><strong>层权重的初始化</strong>。层权重<span class="math inline">\(w_j\)</span>通常初始化为相等的值（即<span class="math inline">\(s_j = 1/(L+1)\)</span>），这意味着初始时所有层的贡献相等。训练过程中，权重会逐渐偏向对当前任务最有用的层。</p>
<p><strong>ELMo预训练数据</strong>。原始ELMo在1B Word Benchmark（约8亿词）上预训练。如果你需要在特定领域使用ELMo，Allen AI也提供了在不同数据上预训练的版本（如PubMed版本用于生物医学领域）。</p>
</section>
<section id="实验结果" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="实验结果"><span class="header-section-number">5.4</span> 实验结果</h3>
<p>Peters等人在6个NLP基准任务上评测了ELMo的效果：</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>任务</th>
<th>基线模型</th>
<th>+ELMo</th>
<th>绝对提升</th>
<th>相对错误减少</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SQuAD (F1)</td>
<td>81.1</td>
<td>85.8</td>
<td>+4.7</td>
<td>24.9%</td>
</tr>
<tr class="even">
<td>SNLI (Acc)</td>
<td>88.6</td>
<td>88.7</td>
<td>+0.1</td>
<td>~1%</td>
</tr>
<tr class="odd">
<td>SRL (F1)</td>
<td>81.4</td>
<td>84.6</td>
<td>+3.2</td>
<td>17.2%</td>
</tr>
<tr class="even">
<td>Coref (Avg F1)</td>
<td>67.2</td>
<td>70.4</td>
<td>+3.2</td>
<td>9.8%</td>
</tr>
<tr class="odd">
<td>NER (F1)</td>
<td>90.15</td>
<td>92.22</td>
<td>+2.1</td>
<td>21.1%</td>
</tr>
<tr class="even">
<td>SST-5 (Acc)</td>
<td>53.7</td>
<td>54.7</td>
<td>+1.0</td>
<td>2.2%</td>
</tr>
</tbody>
</table>
<p>值得注意的是，ELMo的提升在不同任务上差异很大。SQuAD（阅读理解）和NER获得了最大的提升，而SNLI和SST-5的提升较小。一个可能的解释是：阅读理解和NER更依赖于精细的上下文理解能力（需要根据上下文判断一个词的具体含义或实体类型），而SNLI和SST-5更依赖于全局的语义匹配。</p>
<p>另一个值得关注的维度是<strong>数据效率</strong>。Peters等人在论文中展示了ELMo在不同训练数据量下的效果对比（以SRL任务为例）：</p>
<div id="fig-sample-efficiency" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-sample-efficiency-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-11/original/fig1-sample-efficiency.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-sample-efficiency-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: ELMo的数据效率：在SRL任务上，使用ELMo（蓝色）只需要约1%的训练数据就能达到不使用ELMo的基线模型（橙色）用100%数据达到的性能。这意味着ELMo的预训练知识可以大幅减少对标注数据的依赖。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Peters et al.&nbsp;(2018), Figure 1. <a href="https://arxiv.org/abs/1802.05365">arXiv:1802.05365</a></em></p>
</div>
<p>这个结果有深远的意义：预训练模型不仅在全量数据下提升性能，更重要的是它在<strong>小数据场景</strong>下带来的增益更为显著。这与迁移学习的核心价值一致——利用在大数据上学到的通用知识，减少对特定任务标注数据的依赖。</p>
<hr>
</section>
</section>
<section id="深入理解" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="深入理解"><span class="header-section-number">6</span> 深入理解</h2>
<blockquote class="blockquote">
<p><strong>研究者必读</strong>：这一节探讨ELMo为什么有效、层级信息的分析、以及与同期工作的比较</p>
</blockquote>
<section id="为什么有效层级信息分析" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="为什么有效层级信息分析"><span class="header-section-number">6.1</span> 为什么有效？——层级信息分析</h3>
<p>ELMo最令人兴奋的发现之一是：<strong>biLM不同层捕获了质量不同的语言信息</strong>。Peters等人通过两个探针实验证实了这一点。</p>
<p><strong>实验一：词义消歧（Word Sense Disambiguation, WSD）</strong>。他们在一个标准的WSD数据集上测试了biLM不同层的表现。结果表明：第2层（顶层）在WSD任务上的表现最好，F1分数为67.2%，相比之下第1层只有63.7%。这说明高层更善于捕获语义信息——理解一个词在特定上下文中的精确含义。</p>
<p><strong>实验二：词性标注（Part-of-Speech Tagging）</strong>。有趣的是，在POS标注任务上，情况反了过来：第1层的表现（97.1%准确率）与第2层相当甚至略好。这说明低层更偏向捕获句法信息——词的语法类别主要取决于局部的语法结构，不需要深层的语义理解。</p>
<p>这个发现有一个深刻的启示：<strong>一个良好训练的语言模型自然地将语言信息按层级组织——低层编码句法、高层编码语义</strong>。这与CV中CNN的层级特征（低层边缘纹理、高层物体部件）形成了有趣的平行。</p>
<p>下游任务的层权重学习结果进一步验证了这个规律。Peters等人报告，在NER和SRL等序列标注任务上，学到的权重倾向于更均匀地分配到各层；而在需要更多语义理解的任务上，顶层获得了更大的权重。</p>
<p>下图展示了Peters等人在论文中报告的不同任务上学到的层权重分布：</p>
<div id="fig-layer-weights" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-layer-weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-11/original/fig2-layer-weights.png" class="img-fluid figure-img" style="width:75.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-layer-weights-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: 不同下游任务学到的ELMo层权重。每个任务对biLM各层的偏好不同：偏句法的任务（如POS标注）更依赖底层，偏语义的任务（如WSD）更依赖顶层。这直接验证了”低层编码句法、高层编码语义”的假设。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Peters et al.&nbsp;(2018), Figure 2. <a href="https://arxiv.org/abs/1802.05365">arXiv:1802.05365</a></em></p>
</div>
</section>
<section id="为什么用所有层比只用顶层好" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="为什么用所有层比只用顶层好"><span class="header-section-number">6.2</span> 为什么用所有层比只用顶层好？</h3>
<p>一个自然的问题是：既然顶层包含了最抽象的语义信息，为什么不只用顶层呢？</p>
<p>Peters等人的消融实验给出了明确的答案。在6个任务上，使用所有层的加权平均平均比只用最后一层好1.0-2.0个百分点。原因在于不同任务需要不同层次的语言信息。词性标注需要句法信息（低层），词义消歧需要语义信息（高层），而更复杂的任务如SRL和阅读理解则需要同时利用多个层次的信息。ELMo的层权重机制让模型自动找到每个任务的最优信息组合。</p>
<p>这个设计选择也解释了为什么ELMo在某些任务上的提升特别大：如果一个任务恰好需要biLM某个层已经很好地编码了的信息，ELMo就能提供巨大的增益。</p>
</section>
<section id="与同期工作的比较taglm和cove" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="与同期工作的比较taglm和cove"><span class="header-section-number">6.3</span> 与同期工作的比较：TagLM和CoVe</h3>
<p>ELMo并非凭空出现的。在它之前，有两个相关工作值得提及。</p>
<p><strong>TagLM（Peters et al., 2017）</strong>。有趣的是，ELMo的第一作者之前已经在2017年发表过一篇名为”Semi-supervised sequence tagging with bidirectional language models”的工作。TagLM也是用biLM的隐状态来增强序列标注模型，但只使用了<strong>最顶层</strong>的表示，没有层混合机制。ELMo的关键改进正是”暴露所有层 + 学习层权重”这个设计。</p>
<p><strong>CoVe（McCann et al., 2017）</strong>。“Learned in Translation: Contextualized Word Vectors”用一个在大规模翻译数据上训练的Encoder来生成上下文词向量。CoVe证明了上下文词向量的有效性，但它的预训练需要<strong>平行语料</strong>（标注数据），而非无标注文本。ELMo通过使用语言模型目标，完全消除了对标注数据的依赖。</p>
</section>
<section id="方法的边界条件" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="方法的边界条件"><span class="header-section-number">6.4</span> 方法的边界条件</h3>
<p><strong>假设一：双向信息的独立性</strong>。biLM将前向和后向LSTM作为两个独立的模型训练，仅在输入和输出层共享参数。这意味着前向LSTM在位置<span class="math inline">\(k\)</span>生成表示时只能利用左侧上下文<span class="math inline">\(t_1, \ldots, t_{k-1}\)</span>，后向LSTM只能利用右侧上下文<span class="math inline">\(t_{k+1}, \ldots, t_N\)</span>。两个方向的信息在ELMo公式中通过<strong>拼接</strong>来组合，但并没有在LSTM内部进行深度融合。这是ELMo”双向性”的一个根本限制——它是”分离式双向”而非”融合式双向”。</p>
<p><strong>假设二：语言模型是足够好的预训练目标</strong>。ELMo假设”预测下一个/前一个词”这个训练目标能够迫使模型学习深层的语言知识。虽然实验证明这个假设基本成立，但语言模型目标也有局限——它偏向于学习<strong>局部</strong>的语法和搭配模式，对于需要全局推理的知识（如数学逻辑、因果关系）的学习效率可能较低。</p>
<p><strong>失效条件</strong>。ELMo在以下场景表现不佳：当下游任务的领域与预训练数据差异太大时（如biLM在新闻文本上预训练，但应用于法律文本），上下文表示的质量会下降。当句子非常短（如只有2-3个词）时，上下文信息有限，ELMo退化为接近静态词向量。当面对高度创造性的语言使用（如诗歌中的反讽、双关语）时，语言模型的”常规化”理解可能无法捕获这些特殊用法。</p>
</section>
<section id="开放研究问题2018年视角" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="开放研究问题2018年视角"><span class="header-section-number">6.5</span> 开放研究问题（2018年视角）</h3>
<p>站在2018年初的时间节点——ELMo刚刚发表——几个关键的研究问题浮出水面。</p>
<p><strong>预训练架构的最优选择</strong>。ELMo使用LSTM，但Transformer已经在2017年证明了其优越性（第8章）。如果用Transformer替代LSTM来构建语言模型，效果会更好吗？这个问题在同年的GPT中得到了回答——答案是”是的”。</p>
<p><strong>特征提取 vs 微调</strong>。ELMo采用”冻结biLM + 提取特征”的范式，这虽然简单，但是否是最优的迁移方式？是否可以微调biLM的全部参数来获得更好的效果？这个问题在同年的GPT和2019年的BERT中得到了回答——微调通常优于特征提取。</p>
<p><strong>真正的双向融合</strong>。ELMo的”双向”是两个独立LSTM的拼接，前向和后向的信息没有在内部互相交流。能否设计出一种架构，让左右两个方向的信息在每一层都深度融合？这个问题在2019年的BERT中通过Masked Language Model得到了优雅的回答——通过遮蔽而非分方向来实现真正的双向注意力。</p>
<hr>
</section>
</section>
<section id="局限性与未解决的问题" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="局限性与未解决的问题"><span class="header-section-number">7</span> 局限性与未解决的问题</h2>
<section id="分离式双向的根本缺陷" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="分离式双向的根本缺陷"><span class="header-section-number">7.1</span> “分离式双向”的根本缺陷</h3>
<p>ELMo最根本的局限在于它的双向性是<strong>分离的（concatenated bidirectional）</strong>，而非<strong>融合的（jointly bidirectional）</strong>。</p>
<p>具体来说，前向LSTM在生成位置<span class="math inline">\(k\)</span>的表示时，只能看到<span class="math inline">\(t_1, \ldots, t_{k-1}\)</span>；后向LSTM只能看到<span class="math inline">\(t_{k+1}, \ldots, t_N\)</span>。两者的表示通过简单拼接组合：</p>
<p><span class="math display">\[
\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j};\; \overleftarrow{\mathbf{h}}_{k,j}]
\]</span></p>
<p>这种设计的问题在于，两个方向的信息从未在模型内部进行”深度对话”。考虑句子”The animal didn’t cross the street because <strong>it</strong> was too tired”。要理解”it”指代”animal”还是”street”，需要同时综合左侧信息（“The animal didn’t cross”）和右侧信息（“was too tired”）进行推理。在ELMo中，前向LSTM看到”The animal didn’t cross the street because”可能倾向于”it = street”（因为”street”距离更近），后向LSTM看到”was too tired”倾向于”it = animal”（因为街道不会累）。两者拼接后的信息确实包含了正确的线索，但这些线索是被动地堆叠在一起，没有经过交互式的推理。</p>
<p>为什么ELMo不能简单地将两个方向融合呢？原因在于语言模型的约束。如果一个模型在预测位置<span class="math inline">\(k\)</span>的词时同时能看到左右两侧的信息，那么它可以直接”偷看”答案——位置<span class="math inline">\(k\)</span>的词就在输入中。这会导致语言模型的训练目标变得毫无意义——模型不需要真正理解语言，只需要学会复制输入就能完美预测。这就是为什么前向和后向必须分开训练。</p>
<p>BERT后来用一个巧妙的方法解决了这个问题：<strong>遮蔽（Masking）</strong>。随机遮蔽输入中的部分词，然后让模型根据所有未遮蔽的上下文（包括左右两侧）来预测被遮蔽的词。这样模型无法”偷看”，但又能真正地利用双向信息——这正是第13章的主题。</p>
</section>
<section id="特征提取范式的局限" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="特征提取范式的局限"><span class="header-section-number">7.2</span> 特征提取范式的局限</h3>
<p>ELMo采用的是<strong>特征提取（feature extraction）</strong>范式：冻结预训练的biLM参数，只学习少量的层权重和缩放因子。这种方式有几个限制。</p>
<p>首先，<strong>预训练模型无法为目标任务做出任何调整</strong>。biLM在大规模通用文本上训练，其参数永远不会针对下游的情感分析或NER做任何适配。上一章讨论的ULMFiT已经证明了微调的巨大优势，但ELMo选择了更保守的特征提取路线。</p>
<p>其次，<strong>下游模型仍然需要从零设计和训练</strong>。使用ELMo时，你仍然需要为每个任务设计一个完整的模型架构（如BiLSTM-CRF用于NER，BiDAF用于QA），ELMo只是提供了更好的输入特征。这与GPT和BERT后来采用的”预训练一个模型 + 简单分类头”的极简方式形成了对比。</p>
</section>
<section id="lstm的可扩展性问题" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="lstm的可扩展性问题"><span class="header-section-number">7.3</span> LSTM的可扩展性问题</h3>
<p>ELMo使用LSTM作为backbone，而LSTM有一个固有的扩展性瓶颈：<strong>顺序计算</strong>。LSTM必须逐位置地处理序列——位置<span class="math inline">\(k\)</span>的隐状态依赖于位置<span class="math inline">\(k-1\)</span>的隐状态——这使得它无法在序列维度上并行化。当模型规模增大（更多层、更大隐藏维度）或序列变长时，训练速度会显著下降。</p>
<p>第8章我们已经看到，Transformer通过Self-Attention实现了完全并行的计算。同样是在2018年，GPT选择了Transformer Decoder作为预训练架构，获得了更好的可扩展性。ELMo的LSTM架构虽然在2018年已经足够强大，但在追求更大规模的”scaling law”趋势下，它注定会被Transformer取代。</p>
</section>
<section id="这些局限导向了什么" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="这些局限导向了什么"><span class="header-section-number">7.4</span> 这些局限导向了什么？</h3>
<p>ELMo的三个局限精确地预示了预训练技术接下来的演进方向。</p>
<p>分离式双向的缺陷催生了<strong>BERT的Masked Language Model</strong>——通过遮蔽来实现真正的双向融合（第13章）。</p>
<p>特征提取范式的局限推动了<strong>GPT的全模型微调路线</strong>——预训练整个模型，然后在下游任务上微调所有参数（第12章）。</p>
<p>LSTM的可扩展性问题则加速了<strong>Transformer成为预训练的标准骨架</strong>——GPT和BERT都选择了Transformer，这使得模型可以在更大的数据和更大的参数量下继续获益。</p>
<blockquote class="blockquote">
<p>下一章预告：第12章将介绍GPT——OpenAI用Transformer Decoder进行自回归预训练的开创性工作。GPT与ELMo的关键差异在于两个方面：用Transformer替代LSTM作为骨架架构，以及用全模型微调替代特征提取作为迁移方式。这两个选择将推动预训练范式进入一个新的阶段。</p>
</blockquote>
<hr>
</section>
</section>
<section id="本章小结" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="本章小结"><span class="header-section-number">8</span> 本章小结</h2>
<section id="核心要点回顾" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="核心要点回顾"><span class="header-section-number">8.1</span> 核心要点回顾</h3>
<p>这一章我们详细介绍了ELMo——第一个生成上下文相关词向量的预训练模型。</p>
<p>核心问题是静态词向量无法处理一词多义：同一个词在不同上下文中应该有不同的表示，但Word2Vec/GloVe为每个词只分配一个固定向量。核心洞察是用一个深层双向LSTM语言模型去”阅读”上下文，然后从模型的各层中提取上下文相关的词表示。</p>
<p>ELMo的技术方案包含三个核心要素：双向语言模型（biLM）提供了强大的上下文建模能力；暴露所有层的表示并通过可学习的权重混合，让不同的下游任务自动选择最适合的信息层次；字符级CNN作为输入层，天然地解决了OOV问题。</p>
<p>实验表明，ELMo在6个NLP任务上带来了显著的提升，尤其是在需要精细上下文理解的任务（如阅读理解和NER）上效果最为突出。更深层的发现是biLM的不同层编码了不同层次的语言信息：低层偏句法、高层偏语义。</p>
<p>然而，ELMo也有明确的局限：分离式双向（前向和后向LSTM独立运行）、特征提取范式（不微调预训练模型）、以及LSTM的可扩展性瓶颈。这些局限直接催生了后续的GPT和BERT。</p>
</section>
<section id="关键公式速查" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="关键公式速查"><span class="header-section-number">8.2</span> 关键公式速查</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>公式</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\sum_{k=1}^{N}(\log p_{fwd} + \log p_{bwd})\)</span></td>
<td>biLM的训练目标：最大化双向对数似然</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j};\; \overleftarrow{\mathbf{h}}_{k,j}]\)</span></td>
<td>第<span class="math inline">\(j\)</span>层的拼接表示</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\text{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^{L} s_j^{task}\; \mathbf{h}_{k,j}^{LM}\)</span></td>
<td>ELMo核心公式：所有层的加权和</td>
</tr>
<tr class="even">
<td><span class="math inline">\(s_j = \text{softmax}(w_j)\)</span></td>
<td>层权重的softmax归一化</td>
</tr>
</tbody>
</table>
</section>
<section id="思考题" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="思考题"><span class="header-section-number">8.3</span> 思考题</h3>
<ol type="1">
<li><p><strong>[概念理解]</strong> ELMo的”双向”和BERT的”双向”有何本质区别？为什么说ELMo是”分离式双向”而BERT是”融合式双向”？ELMo的设计为什么不能直接让前向和后向LSTM在内部交互？</p></li>
<li><p><strong>[数学推导]</strong> 假设ELMo使用<span class="math inline">\(L=2\)</span>层biLM，第0层维度为512，第1、2层每个方向4096维（拼接后8192维），但经过投影后降为1024维。(a) ELMo最终表示的维度是多少？(b) 下游任务需要学习多少个新参数（只算层权重和缩放因子）？(c) 如果biLM的总参数量为93.6M，计算ELMo新增参数占biLM参数的比例。</p></li>
<li><p><strong><a href="#工程实践">工程实践</a></strong> 在一个文本分类任务上，分别使用(a)GloVe词向量、(b)ELMo+GloVe拼接、(c)只用ELMo三种输入配置，对比模型性能。观察在不同数据量（100, 1000, 10000样本）下ELMo的优势如何变化。</p></li>
<li><p><strong>[研究思考]</strong> Peters等人发现biLM的低层偏句法、高层偏语义。如果biLM有10层而非2层，你预测中间层会编码什么样的信息？这种信息分层是语言模型训练目标的必然结果，还是LSTM架构的偶然产物？如果用Transformer替代LSTM，分层模式会不同吗？（提示：后来BERT的探针实验提供了部分答案。）</p></li>
<li><p><strong>[对比分析]</strong> ELMo（特征提取）和ULMFiT（微调）代表了预训练迁移的两条路线。从理论角度分析，在什么条件下特征提取更好？在什么条件下微调更好？（提示：考虑数据量、领域差异、计算资源等因素。）</p></li>
</ol>
<hr>
</section>
</section>
<section id="延伸阅读" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="延伸阅读"><span class="header-section-number">9</span> 延伸阅读</h2>
<section id="核心论文必读" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="核心论文必读"><span class="header-section-number">9.1</span> 核心论文（必读）</h3>
<p><strong>Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). “Deep contextualized word representations”</strong>。ELMo的原始论文。重点阅读：Section 3（biLM架构和ELMo公式）、Section 4（实验结果）、Section 5.1（层级信息分析）。可快速浏览：Section 2的相关工作部分。<a href="https://arxiv.org/abs/1802.05365">arXiv:1802.05365</a></p>
</section>
<section id="前驱工作" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="前驱工作"><span class="header-section-number">9.2</span> 前驱工作</h3>
<p><strong>Peters, M.E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). “Semi-supervised sequence tagging with bidirectional language models” (TagLM)</strong>。ELMo的前身工作，只用biLM顶层作为特征，没有层混合机制。对比TagLM和ELMo可以清晰地看到”暴露所有层”这个设计选择的价值。<a href="https://arxiv.org/abs/1705.00108">arXiv:1705.00108</a></p>
<p><strong>McCann, B., Bradbury, J., Xiong, C., &amp; Socher, R. (2017). “Learned in Translation: Contextualized Word Vectors” (CoVe)</strong>。用机器翻译编码器生成上下文词向量。与ELMo的关键区别：CoVe需要平行语料（标注数据），而ELMo只需要无标注文本。<a href="https://arxiv.org/abs/1708.00107">arXiv:1708.00107</a></p>
</section>
<section id="后续发展" class="level3" data-number="9.3">
<h3 data-number="9.3" class="anchored" data-anchor-id="后续发展"><span class="header-section-number">9.3</span> 后续发展</h3>
<p><strong>Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). “Improving Language Understanding by Generative Pre-Training” (GPT)</strong>。用Transformer Decoder + 全模型微调替代ELMo的LSTM + 特征提取——下一章的主题。</p>
<p><strong>Devlin, J., Chang, M.W., Lee, K., &amp; Toutanova, K. (2019). “BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding”</strong>。解决了ELMo的”分离式双向”问题，用Masked LM实现真正的双向融合——第13章的主题。<a href="https://arxiv.org/abs/1810.04805">arXiv:1810.04805</a></p>
</section>
<section id="分析与探针研究" class="level3" data-number="9.4">
<h3 data-number="9.4" class="anchored" data-anchor-id="分析与探针研究"><span class="header-section-number">9.4</span> 分析与探针研究</h3>
<p><strong>Peters, M.E., Neumann, M., Zettlemoyer, L., &amp; Yih, W.T. (2018). “Dissecting Contextual Word Embeddings: Architecture and Representation”</strong>。ELMo作者的后续工作，系统地分析了上下文词向量中不同层编码的信息类型。<a href="https://arxiv.org/abs/1808.08949">arXiv:1808.08949</a></p>
<p><strong>Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., &amp; Smith, N.A. (2019). “Linguistic Knowledge and Transferability of Contextual Representations”</strong>。对ELMo和GPT等上下文表示进行了16种探针任务的系统分析。<a href="https://arxiv.org/abs/1903.08855">arXiv:1903.08855</a></p>
</section>
<section id="综述与教程" class="level3" data-number="9.5">
<h3 data-number="9.5" class="anchored" data-anchor-id="综述与教程"><span class="header-section-number">9.5</span> 综述与教程</h3>
<p><strong>Rogers, A., Kovaleva, O., &amp; Rumshisky, A. (2020). “A Primer in BERTology: What We Know About How BERT Works”</strong>。虽然主要讨论BERT，但其分析框架也适用于ELMo，对理解”预训练模型内部到底学到了什么”很有帮助。</p>
</section>
<section id="代码资源" class="level3" data-number="9.6">
<h3 data-number="9.6" class="anchored" data-anchor-id="代码资源"><span class="header-section-number">9.6</span> 代码资源</h3>
<ul>
<li><strong>AllenNLP ELMo实现</strong>：<a href="https://github.com/allenai/allennlp">github.com/allenai/allennlp</a> — 官方实现，包含预训练模型下载</li>
<li><strong>TensorFlow Hub</strong>：<a href="https://tfhub.dev/google/elmo/3">tfhub.dev/google/elmo/3</a> — TensorFlow版本</li>
<li><strong>Hugging Face上的AllenNLP教程</strong>：提供ELMo的快速入门指南</li>
</ul>
<hr>
</section>
</section>
<section id="历史注脚" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="历史注脚"><span class="header-section-number">10</span> 历史注脚</h2>
<p>ELMo这个名字有一个有趣的来源。它是”Embeddings from Language Models”的缩写——一个巧妙而准确的命名。但许多人怀疑这个名字也是对《芝麻街》(Sesame Street)角色Elmo的致敬。后来的BERT（Bidirectional Encoder Representations from Transformers）似乎证实了这个猜测——Bert也是《芝麻街》的角色。再后来出现的ERNIE（Enhanced Representation through Knowledge Integration，百度版和清华版）和Big Bird（Transformers for Longer Sequences）把这个传统发扬光大。NLP社区用儿童教育节目的角色来命名划时代的AI模型，颇有一种”启蒙者”的浪漫。</p>
<p>时间线上的一个引人深思的巧合是：ELMo（2018年2月发表在arXiv）、GPT（2018年6月发布）和BERT（2018年10月发表在arXiv）全部出现在同一年。2018年被后来称为NLP的”ImageNet moment”——预训练范式在这一年彻底改变了NLP研究的面貌。三个团队几乎同时但独立地走向了同一个方向——上下文预训练，这说明预训练范式的到来不是偶然的个人天才，而是技术条件成熟后的必然趋势。</p>
<p>Peters等人在论文中低调地写道：“Extensive experiments show that ELMo representations work well in practice and improve the state of the art across six challenging NLP problems.” 这种克制的措辞很难让人预见到，仅仅几个月后，GPT和BERT就会将预训练从”有用的增强”推向”必不可少的基础设施”。ELMo是那个关键的第一步——它证明了深层预训练不仅在理论上合理，而且在实践中确实能带来显著的收益。但它选择的LSTM架构和特征提取范式，最终被Transformer和全模型微调所取代。技术的演进有时候就是这样：开拓者铺平了道路，但走得更远的往往是后来者。</p>


<!-- -->

</section>

</main> <!-- /main -->
﻿<script>

// Simple EN / 中文 language toggle for posts; robust via meta[quarto:offset]

(function() {

  const KEY = 'siteLang'; // 'en' | 'zh'

  const defaultLang = 'en';

  const POSTS_EN = 'posts_en.html';

  const POSTS_ZH = 'posts_zh.html';

  const TAGS = 'tags.html';



  function currentLang() { try { return localStorage.getItem(KEY) || defaultLang; } catch(e) { return defaultLang; } }

  function setLang(v) { try { localStorage.setItem(KEY, v); } catch(e) {} }

  function offset() {

    const meta = document.querySelector('meta[name="quarto:offset"]');

    const off = meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

    return off;

  }

  function targetFor(lang) { return lang === 'zh' ? POSTS_ZH : POSTS_EN; }

  function goToLang(lang) {

    const off = offset();

    const path = window.location.pathname;

    setLang(lang);

    if (path.endsWith('/' + TAGS) || path.endsWith(TAGS)) {

      window.location.href = off + TAGS;

    } else {

      window.location.href = off + targetFor(lang);

    }

  }

  function updateNavbarPostsLink() {

    const off = offset();

    const href = off + targetFor(currentLang());

    const links = document.querySelectorAll('header .navbar a.nav-link');

    links.forEach((a) => {

      const h = a.getAttribute('href') || '';

      if (h.endsWith(POSTS_EN) || h.endsWith(POSTS_ZH)) a.setAttribute('href', href);

    });

  }

  function mountToggle() {

    const tools = document.querySelector('.quarto-navbar-tools');

    if (!tools) return;

    const wrapper = document.createElement('div');

    wrapper.style.display = 'inline-flex';

    wrapper.style.alignItems = 'center';

    wrapper.style.gap = '0.35rem';

    wrapper.style.marginLeft = '0.35rem';



    const en = document.createElement('a');

    en.href = '';

    en.textContent = 'EN';

    en.className = 'quarto-navigation-tool px-1';

    en.onclick = function(){ goToLang('en'); return false; };



    const sep = document.createElement('span');

    sep.textContent = '|';

    sep.style.opacity = '0.6';



    const zh = document.createElement('a');

    zh.href = '';

    zh.textContent = '中文';

    zh.className = 'quarto-navigation-tool px-1';

    zh.onclick = function(){ goToLang('zh'); return false; };



    const lang = currentLang();

    (lang === 'en' ? en : zh).style.fontWeight = '700';



    wrapper.appendChild(en);

    wrapper.appendChild(sep);

    wrapper.appendChild(zh);

    tools.appendChild(wrapper);

    updateNavbarPostsLink();

  }

  document.addEventListener('DOMContentLoaded', mountToggle);

})();

</script>

<script>

(function(){

  function offset(){

    var meta = document.querySelector('meta[name="quarto:offset"]');

    return meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

  }

  document.addEventListener('DOMContentLoaded', function(){

    var brand = document.querySelector('header .navbar a.navbar-brand');

    if (brand) {

      brand.setAttribute('href', offset() + 'home.html');

    }

  });

})();

</script>



<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "第11章：上下文词向量——ELMo"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "从静态词典到动态阅读：让词的表示随语境而变"</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ying Zha"</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2026-01-26"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [NLP, Deep Learning, Pre-training, ELMo, Contextual Embeddings]</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="an">tags:</span><span class="co"> [ELMo, biLSTM, 上下文词向量, 预训练, 语言模型, 迁移学习]</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "ELMo：第一个生成上下文相关词向量的预训练模型。通过深层双向LSTM语言模型，让同一个词在不同语境中拥有不同的向量表示，标志着从'词典式'到'阅读式'词向量的范式转变。"</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "figures/chapter-11/elmo-banner.png"</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-cap-location: bottom</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **核心问题**：如何让词的向量表示随上下文而变化，使得同一个词在不同语境中拥有不同的表示？</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **历史坐标**：2018 </span><span class="pp">|</span><span class="at"> Peters et al. "Deep contextualized word representations" </span><span class="pp">|</span><span class="at"> 从静态词向量到上下文词向量的范式转变</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## 本章参考来源</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="fu">### 论文</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Peters et al. (2018)** "Deep contextualized word representations" (arXiv:1802.05365) — 参考了 Section 3（biLM架构、ELMo公式）、Section 5（层级分析）、Figure 1-2、Table 1-6</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Peters et al. (2017)** "Semi-supervised sequence tagging with bidirectional language models" (TagLM) — 参考了与ELMo的对比</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**McCann et al. (2017)** "Learned in Translation: Contextualized Word Vectors" (CoVe) — 参考了设计路线对比</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### 教材</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**D2L** Section 15.8 (BERT) — 参考了ELMo/GPT/BERT对比图 (<span class="in">`elmo-gpt-bert.svg`</span>) 和教学组织方式</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**SLP3** Chapter 10 (Masked Language Models and Contextual Embeddings) — 参考了上下文词向量的动机铺设</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="fu">### 课程</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Stanford CS224N** Lecture 14 (2020) "Contextual Word Representations" — 参考了"shallowly bidirectional"的讲解角度、TagLM→ELMo→ULMFiT→BERT的教学递进、feature-based vs fine-tuning对比框架</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Jay Alammar** "The Illustrated BERT, ELMo, and co." — 参考了ELMo架构可视化的设计思路</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## 从上一章说起</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>上一章我们追溯了预训练思想的起源。从Word2Vec的词向量预训练，到CV领域ImageNet的深层迁移启示，再到ULMFiT的完整预训练-微调框架，预训练范式在2017年底已经初具雏形。特别是ULMFiT证明了一个重要命题：NLP也可以像CV一样，通过"先在大数据上预训练、再在小数据上微调"的方式大幅提升性能。</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>然而，上一章结尾我们也揭示了当时预训练方法的三个根本局限。</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>第一个局限是**静态词向量的一词多义问题**。Word2Vec和GloVe为每个词分配一个固定的向量，无论它出现在什么上下文中。"I went to the **bank** to deposit money"中的bank和"I sat on the **bank** of the river"中的bank，共享同一个向量。这种"一词一向量"的设计无法捕获语言中普遍存在的多义现象。</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>第二个局限是**浅层迁移的天花板**。使用预训练词向量本质上只迁移了模型最底层（Embedding层）的知识，更高层次的句法结构、语义组合、篇章逻辑仍然需要从零学习。这就像给学生发了一本词典就让他参加阅读理解考试——认识词和理解文章之间还有巨大的鸿沟。</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>第三个局限是**预训练目标与下游任务的脱节**。Word2Vec学到的是"哪些词经常一起出现"，但这与下游任务（如"哪些词表达正面情感"）之间的关联是间接的、不完美的。</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>这三个局限指向了一个共同的方向：我们需要能够生成**上下文相关的、深层的**语言表示的预训练方法。</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>2018年初，Allen Institute for AI的Matthew Peters等人在论文"Deep contextualized word representations"中提出了ELMo（Embeddings from Language Models），给出了第一个令人信服的答案。</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 💡 **本章核心洞察**：不要给每个词一个固定的向量，而是用一个在大规模文本上预训练的深层双向LSTM语言模型，根据上下文为每个词**动态生成**向量表示。更妙的是，不同层的LSTM捕获了不同层次的语言信息——低层偏句法、高层偏语义——让下游任务自动学习如何混合这些层次的信息。</span></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## 问题的本质是什么？</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="fu">### 一词多义：不是边缘案例，而是语言的常态</span></span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>在正式介绍ELMo之前，让我们先深入理解"一词多义"问题的严重性——它不是一个可以忽略的边缘情况，而是自然语言的核心特征。</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>考虑英语中最常见的动词之一"run"。在不同语境中，它的含义截然不同：</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"I **run** every morning."（跑步——身体运动）</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"She **runs** a company."（经营——管理行为）</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"The program **runs** slowly."（运行——计算机执行）</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"His nose **runs** in winter."（流——液体流动）</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"The road **runs** along the coast."（延伸——空间分布）</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>这五个"run"的语义差异巨大，但在Word2Vec/GloVe中它们共享同一个300维向量。这个向量是所有含义的"平均"——它既不完美地代表"跑步"，也不完美地代表"经营"，而是一个模糊的折中。</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>这个问题有多普遍？根据WordNet的统计，英语中最常用的1000个词平均每个词有3.5个不同的义项。某些高频词的义项数量惊人：Merriam-Webster词典为"set"列出了超过430个义项，"run"超过370个。一词多义不是例外，而是规则。</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a><span class="fu">### 之前的尝试为何不够？</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>在ELMo之前，研究者已经意识到了这个问题，并尝试了一些解决方案。</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>**多义词向量（Multi-Sense Embeddings）**。Reisinger &amp; Mooney (2010)和Huang et al. (2012)提出为每个词学习多个向量，每个向量对应一个义项。例如，"bank"有两个向量：一个对应"银行"，一个对应"河岸"。使用时通过聚类或注意力机制选择合适的向量。这个思路直觉上很合理，但实践中面临几个困难：义项数量需要预先指定、义项之间的边界往往模糊（"bank"在"central bank"和"blood bank"中的含义是同一个义项还是不同义项？）、而且无法处理从未见过的新用法。</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>**上下文嵌入的早期尝试**。Melamud et al. (2016)提出了context2vec，用双向LSTM的隐状态来表示上下文，然后用上下文向量替代或增强词向量。这个方向是正确的，但模型规模和训练数据有限，效果未达到足够的影响力。</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>这些尝试的共同问题在于：它们仍然把"词义消歧"当作一个需要显式解决的任务。ELMo的突破在于——**不需要显式地为每个词划分义项，只需要用一个足够强的语言模型去"阅读"上下文，词义的区分自然就隐含在模型的内部表示中**。</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### 我们需要什么样的解决方案？</span></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>理想的上下文词向量应该满足几个条件。</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>第一，**上下文敏感**：同一个词在不同上下文中应该有不同的向量表示。"bank"在金融语境和地理语境中的向量应该明显不同。</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>第二，**可从无标注数据学习**：上下文词向量应该从大规模无标注文本中学习，而非依赖昂贵的人工义项标注。</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>第三，**即插即用**：上下文词向量应该能够轻松融入已有的NLP模型架构，作为"升级版"的词向量替换原来的静态词向量，而不需要彻底重新设计下游模型。</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>第四，**多层次信息**：不仅要捕获词义（语义），还应该捕获句法信息（词性、依存关系），因为不同的下游任务可能需要不同层次的语言信息。</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a>ELMo的设计精确地满足了这四个条件。</span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a><span class="fu">## 核心思想与直觉</span></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a><span class="fu">### 关键洞察：让语言模型替你"读"上下文</span></span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a>ELMo的核心思想可以用一个直觉的类比来理解。</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>想象你在查一本传统词典。当你查找"bank"这个词时，词典会给你一个词条，列出它的所有含义。你需要自己根据上下文判断此处是哪个含义。静态词向量就是这种"词典模式"——给你一个固定的表示，让你自己去消歧。</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>现在想象一种"智能词典"：它不是给你"bank"的通用定义，而是在你标记出"bank"出现的那个句子后，词典会**阅读整个句子**，然后告诉你"在这个语境中，bank的含义最接近'金融机构'，这是它在当前语境下的精确语义向量"。这就是ELMo的工作方式。</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>而这个"智能词典"是怎么获得阅读理解能力的呢？答案是**语言模型预训练**。通过在数十亿词的文本上训练语言模型（预测下一个词和上一个词），ELMo的底层双向LSTM学会了丰富的语言知识。当它看到"I deposited money at the bank"时，前向LSTM从"I deposited money at the"这些左侧上下文中推断出bank很可能是金融机构；后向LSTM则从句末的信息提供了额外的确认。两个方向的LSTM隐状态拼接在一起，就构成了bank在这个特定语境中的上下文表示。</span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELMo的三个核心设计决策</span></span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>ELMo的设计包含三个关键决策，每一个都有深思熟虑的理由。</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a>**决策一：用语言模型作为预训练任务**。这个选择承继了上一章讨论的思想脉络——语言模型目标不需要任何标注数据，只需要原始文本。更重要的是，语言模型迫使模型理解语言的深层结构：要准确预测下一个词，模型必须理解语法（名词后面通常不会接另一个名词）、语义（"the capital of France is"后面应该是"Paris"）和常识推理（"after the rain, the streets were"后面可能是"wet"）。这比Word2Vec的共现预测要求更高层次的理解能力。</span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a>**决策二：用双向LSTM而非单向**。语言理解需要同时利用左侧上下文和右侧上下文。"I went to the **bank**"中的bank可能是银行也可能是河岸，但如果你看到右侧是"to deposit money"，含义就明确了。单向语言模型只能看到一个方向的上下文，双向则可以综合两个方向的信息。</span>
<span id="cb5-127"><a href="#cb5-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-128"><a href="#cb5-128" aria-hidden="true" tabindex="-1"></a>**决策三：暴露所有层的表示，而非只用最顶层**。这是ELMo最独特的设计。传统做法是只使用模型最顶层的输出，但Peters等人发现，**不同层捕获了不同类型的语言信息**：底层偏向句法信息（词性、依存关系），顶层偏向语义信息（词义消歧、情感）。不同的下游任务可能需要不同层次的信息——词性标注可能更需要底层的句法信息，而情感分析可能更需要顶层的语义信息。ELMo让下游任务**自动学习**如何混合不同层的信息。</span>
<span id="cb5-129"><a href="#cb5-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-130"><a href="#cb5-130" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELMo、GPT、BERT的架构对比</span></span>
<span id="cb5-131"><a href="#cb5-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-132"><a href="#cb5-132" aria-hidden="true" tabindex="-1"></a>在正式进入技术细节之前，先从宏观视角看一下ELMo在预训练技术演进中的位置。下图展示了ELMo、GPT和BERT三种预训练方法的架构对比——它们分别代表了2018年出现的三条不同路线：</span>
<span id="cb5-133"><a href="#cb5-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-134"><a href="#cb5-134" aria-hidden="true" tabindex="-1"></a><span class="al">![ELMo、GPT 和 BERT 三种预训练架构的对比。ELMo 使用双向 LSTM 并通过特征拼接迁移（左）；GPT 使用单向 Transformer Decoder 并通过微调迁移（中）；BERT 使用双向 Transformer Encoder 并通过微调迁移（右）。](figures/chapter-11/original/fig-elmo-gpt-bert-d2l.svg)</span>{#fig-elmo-gpt-bert width=95%}</span>
<span id="cb5-135"><a href="#cb5-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-136"><a href="#cb5-136" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb5-137"><a href="#cb5-137" aria-hidden="true" tabindex="-1"></a>*Source: Dive into Deep Learning, Figure 15.8.1. [d2l.ai](https://d2l.ai/chapter_natural-language-processing-pretraining/bert.html)*</span>
<span id="cb5-138"><a href="#cb5-138" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-139"><a href="#cb5-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-140"><a href="#cb5-140" aria-hidden="true" tabindex="-1"></a>从图中可以直观地看到ELMo的两个关键特征：它使用双向LSTM（而非Transformer），并且将预训练模型的输出作为"特征"拼接到下游模型中（而非像GPT/BERT那样直接微调整个模型）。这两个选择既是ELMo的特色，也是它后来被超越的原因——我们将在本章末尾的"局限性"一节详细讨论。</span>
<span id="cb5-141"><a href="#cb5-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-142"><a href="#cb5-142" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-143"><a href="#cb5-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-144"><a href="#cb5-144" aria-hidden="true" tabindex="-1"></a><span class="fu">## 技术细节</span></span>
<span id="cb5-145"><a href="#cb5-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-146"><a href="#cb5-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### 双向语言模型（biLM）</span></span>
<span id="cb5-147"><a href="#cb5-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-148"><a href="#cb5-148" aria-hidden="true" tabindex="-1"></a>ELMo的基础是一个**双向语言模型（bidirectional Language Model, biLM）**。让我们从数学上精确定义它。</span>
<span id="cb5-149"><a href="#cb5-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-150"><a href="#cb5-150" aria-hidden="true" tabindex="-1"></a>给定一个长度为$N$的词序列$(t_1, t_2, \ldots, t_N)$，**前向语言模型**通过给定前缀来预测下一个词，建模序列的联合概率：</span>
<span id="cb5-151"><a href="#cb5-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-152"><a href="#cb5-152" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-153"><a href="#cb5-153" aria-hidden="true" tabindex="-1"></a>p(t_1, t_2, \ldots, t_N) = \prod_{k=1}^{N} p(t_k \mid t_1, t_2, \ldots, t_{k-1})</span>
<span id="cb5-154"><a href="#cb5-154" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-155"><a href="#cb5-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-156"><a href="#cb5-156" aria-hidden="true" tabindex="-1"></a>在ELMo中，前向语言模型用一个$L$层的LSTM来实现。在位置$k$，第$j$层LSTM产生一个上下文相关的隐状态$\overrightarrow{\mathbf{h}}_{k,j}$（$j = 1, 2, \ldots, L$）。最顶层的隐状态$\overrightarrow{\mathbf{h}}_{k,L}$通过一个softmax层来预测下一个词$t_{k+1}$。</span>
<span id="cb5-157"><a href="#cb5-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-158"><a href="#cb5-158" aria-hidden="true" tabindex="-1"></a>对称地，**后向语言模型**通过给定后缀来预测前一个词：</span>
<span id="cb5-159"><a href="#cb5-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-160"><a href="#cb5-160" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-161"><a href="#cb5-161" aria-hidden="true" tabindex="-1"></a>p(t_1, t_2, \ldots, t_N) = \prod_{k=1}^{N} p(t_k \mid t_{k+1}, t_{k+2}, \ldots, t_N)</span>
<span id="cb5-162"><a href="#cb5-162" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-163"><a href="#cb5-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-164"><a href="#cb5-164" aria-hidden="true" tabindex="-1"></a>后向语言模型同样用$L$层LSTM实现，在位置$k$产生隐状态$\overleftarrow{\mathbf{h}}_{k,j}$。</span>
<span id="cb5-165"><a href="#cb5-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-166"><a href="#cb5-166" aria-hidden="true" tabindex="-1"></a>biLM的训练目标是**同时最大化前向和后向的对数似然**：</span>
<span id="cb5-167"><a href="#cb5-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-168"><a href="#cb5-168" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-169"><a href="#cb5-169" aria-hidden="true" tabindex="-1"></a>\sum_{k=1}^{N}\left(\log p(t_k \mid t_1, \ldots, t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) + \log p(t_k \mid t_{k+1}, \ldots, t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s)\right)</span>
<span id="cb5-170"><a href="#cb5-170" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-171"><a href="#cb5-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-172"><a href="#cb5-172" aria-hidden="true" tabindex="-1"></a>这里有一个关键的细节：前向和后向LSTM的参数是**独立的**（$\overrightarrow{\Theta}_{LSTM} \neq \overleftarrow{\Theta}_{LSTM}$），但它们**共享**词嵌入层$\Theta_x$和softmax层$\Theta_s$的参数。共享这两层的理由是：无论从哪个方向阅读，词本身的基础表示和输出词汇分布应该是一致的。而LSTM参数独立的理由是：从左到右阅读和从右到左阅读是两种不同的"阅读方式"，需要各自独立学习。</span>
<span id="cb5-173"><a href="#cb5-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-174"><a href="#cb5-174" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb5-175"><a href="#cb5-175" aria-hidden="true" tabindex="-1"></a><span class="fu">## Algorithm 1: biLM Pre-training（改编自 Peters et al., 2018）</span></span>
<span id="cb5-176"><a href="#cb5-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-177"><a href="#cb5-177" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb5-178"><a href="#cb5-178" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_biLM(corpus, vocab_size, L<span class="op">=</span><span class="dv">2</span>, d_lstm<span class="op">=</span><span class="dv">4096</span>, d_proj<span class="op">=</span><span class="dv">512</span>):</span>
<span id="cb5-179"><a href="#cb5-179" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-180"><a href="#cb5-180" aria-hidden="true" tabindex="-1"></a><span class="co">    双向语言模型预训练</span></span>
<span id="cb5-181"><a href="#cb5-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-182"><a href="#cb5-182" aria-hidden="true" tabindex="-1"></a><span class="co">    架构: Character CNN → L层 biLSTM (每层 d_lstm 维, 投影到 d_proj 维)</span></span>
<span id="cb5-183"><a href="#cb5-183" aria-hidden="true" tabindex="-1"></a><span class="co">    训练数据: 1B Word Benchmark (~8亿词)</span></span>
<span id="cb5-184"><a href="#cb5-184" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-185"><a href="#cb5-185" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 初始化</span></span>
<span id="cb5-186"><a href="#cb5-186" aria-hidden="true" tabindex="-1"></a>    char_cnn <span class="op">=</span> CharacterCNN(filters<span class="op">=</span>[<span class="fl">1..7</span>], output_dim<span class="op">=</span><span class="dv">512</span>)     <span class="co"># 字符级词嵌入</span></span>
<span id="cb5-187"><a href="#cb5-187" aria-hidden="true" tabindex="-1"></a>    forward_lstm <span class="op">=</span> StackedLSTM(L, d_lstm, d_proj, residual<span class="op">=</span><span class="va">True</span>) <span class="co"># 前向 LSTM</span></span>
<span id="cb5-188"><a href="#cb5-188" aria-hidden="true" tabindex="-1"></a>    backward_lstm <span class="op">=</span> StackedLSTM(L, d_lstm, d_proj, residual<span class="op">=</span><span class="va">True</span>) <span class="co"># 后向 LSTM (独立参数)</span></span>
<span id="cb5-189"><a href="#cb5-189" aria-hidden="true" tabindex="-1"></a>    softmax <span class="op">=</span> SharedSoftmax(d_proj, vocab_size)                  <span class="co"># 前后向共享</span></span>
<span id="cb5-190"><a href="#cb5-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-191"><a href="#cb5-191" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> corpus:</span>
<span id="cb5-192"><a href="#cb5-192" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> batch  <span class="co"># (t_1, t_2, ..., t_N)</span></span>
<span id="cb5-193"><a href="#cb5-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-194"><a href="#cb5-194" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: 字符级词嵌入 (前后向共享 Θ_x)</span></span>
<span id="cb5-195"><a href="#cb5-195" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> char_cnn(tokens)  <span class="co"># [N, 512]</span></span>
<span id="cb5-196"><a href="#cb5-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-197"><a href="#cb5-197" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: 前向 LM — 用 (t_1,...,t_{k-1}) 预测 t_k</span></span>
<span id="cb5-198"><a href="#cb5-198" aria-hidden="true" tabindex="-1"></a>        h_fwd <span class="op">=</span> forward_lstm(x)                <span class="co"># [N, L, d_proj]</span></span>
<span id="cb5-199"><a href="#cb5-199" aria-hidden="true" tabindex="-1"></a>        loss_fwd <span class="op">=</span> cross_entropy(softmax(h_fwd[<span class="op">-</span><span class="dv">1</span>]), tokens[<span class="dv">1</span>:])</span>
<span id="cb5-200"><a href="#cb5-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-201"><a href="#cb5-201" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 3: 后向 LM — 用 (t_{k+1},...,t_N) 预测 t_k</span></span>
<span id="cb5-202"><a href="#cb5-202" aria-hidden="true" tabindex="-1"></a>        h_bwd <span class="op">=</span> backward_lstm(reverse(x))      <span class="co"># [N, L, d_proj]</span></span>
<span id="cb5-203"><a href="#cb5-203" aria-hidden="true" tabindex="-1"></a>        loss_bwd <span class="op">=</span> cross_entropy(softmax(h_bwd[<span class="op">-</span><span class="dv">1</span>]), tokens[:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb5-204"><a href="#cb5-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-205"><a href="#cb5-205" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 4: 联合优化</span></span>
<span id="cb5-206"><a href="#cb5-206" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fwd <span class="op">+</span> loss_bwd</span>
<span id="cb5-207"><a href="#cb5-207" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb5-208"><a href="#cb5-208" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb5-209"><a href="#cb5-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-210"><a href="#cb5-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-211"><a href="#cb5-211" aria-hidden="true" tabindex="-1"></a>*改编自 Peters et al. (2018) "Deep contextualized word representations", Section 3.1. [arXiv:1802.05365](https://arxiv.org/abs/1802.05365)*</span>
<span id="cb5-212"><a href="#cb5-212" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-213"><a href="#cb5-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-214"><a href="#cb5-214" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELMo表示的构造</span></span>
<span id="cb5-215"><a href="#cb5-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-216"><a href="#cb5-216" aria-hidden="true" tabindex="-1"></a>biLM训练完成后，对于每个词$t_k$，我们可以从模型中提取$2L + 1$个表示：</span>
<span id="cb5-217"><a href="#cb5-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-218"><a href="#cb5-218" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-219"><a href="#cb5-219" aria-hidden="true" tabindex="-1"></a>R_k = <span class="sc">\{</span>\mathbf{x}_k^{LM},\; \overrightarrow{\mathbf{h}}_{k,j}^{LM},\; \overleftarrow{\mathbf{h}}_{k,j}^{LM} \mid j = 1, \ldots, L<span class="sc">\}</span></span>
<span id="cb5-220"><a href="#cb5-220" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-221"><a href="#cb5-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-222"><a href="#cb5-222" aria-hidden="true" tabindex="-1"></a>其中$\mathbf{x}_k^{LM}$是第0层的词嵌入（上下文无关），$\overrightarrow{\mathbf{h}}_{k,j}^{LM}$和$\overleftarrow{\mathbf{h}}_{k,j}^{LM}$分别是第$j$层前向和后向LSTM的隐状态。</span>
<span id="cb5-223"><a href="#cb5-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-224"><a href="#cb5-224" aria-hidden="true" tabindex="-1"></a>为了简化符号，我们将每一层的前向和后向隐状态拼接为一个向量：</span>
<span id="cb5-225"><a href="#cb5-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-226"><a href="#cb5-226" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-227"><a href="#cb5-227" aria-hidden="true" tabindex="-1"></a>\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j}^{LM};\; \overleftarrow{\mathbf{h}}_{k,j}^{LM}]</span>
<span id="cb5-228"><a href="#cb5-228" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-229"><a href="#cb5-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-230"><a href="#cb5-230" aria-hidden="true" tabindex="-1"></a>对于第0层，$\mathbf{h}_{k,0}^{LM} = \mathbf{x}_k^{LM}$（或者说词嵌入经过字符CNN后的输出，下文会详细讨论）。</span>
<span id="cb5-231"><a href="#cb5-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-232"><a href="#cb5-232" aria-hidden="true" tabindex="-1"></a>这样，ELMo对词$t_k$的表示定义为**所有层表示的加权和**：</span>
<span id="cb5-233"><a href="#cb5-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-234"><a href="#cb5-234" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-235"><a href="#cb5-235" aria-hidden="true" tabindex="-1"></a>\text{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^{L} s_j^{task}\; \mathbf{h}_{k,j}^{LM}</span>
<span id="cb5-236"><a href="#cb5-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-237"><a href="#cb5-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-238"><a href="#cb5-238" aria-hidden="true" tabindex="-1"></a>这个公式是ELMo的核心，值得仔细分解理解。</span>
<span id="cb5-239"><a href="#cb5-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-240"><a href="#cb5-240" aria-hidden="true" tabindex="-1"></a>$s_j^{task}$是**softmax归一化的层权重**：$s_j^{task} = \frac{\exp(w_j)}{\sum_{j'} \exp(w_{j'})}$，其中$w_j$是可学习的标量参数。这些权重在下游任务的训练过程中学习，不同任务会学到不同的层权重——这正是ELMo"让下游任务自动选择所需信息层次"的机制。</span>
<span id="cb5-241"><a href="#cb5-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-242"><a href="#cb5-242" aria-hidden="true" tabindex="-1"></a>$\gamma^{task}$是一个**任务特定的缩放因子**，也是可学习的。它的作用是调整ELMo表示的整体幅度，使其与下游模型的其他组件（如原始词向量、手工特征）在数值尺度上匹配。</span>
<span id="cb5-243"><a href="#cb5-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-244"><a href="#cb5-244" aria-hidden="true" tabindex="-1"></a>你可能会问：为什么不直接学习$L+1$个权重$\alpha_j$（不经过softmax归一化），而要分成$s_j$和$\gamma$两部分？Peters等人发现，这种分离有助于稳定训练——softmax确保层权重加和为1，起到了正则化的作用，而$\gamma$单独负责幅度调整。</span>
<span id="cb5-245"><a href="#cb5-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-246"><a href="#cb5-246" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb5-247"><a href="#cb5-247" aria-hidden="true" tabindex="-1"></a><span class="fu">## Algorithm 2: ELMo Representation Computation（改编自 Peters et al., 2018）</span></span>
<span id="cb5-248"><a href="#cb5-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-249"><a href="#cb5-249" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb5-250"><a href="#cb5-250" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_elmo(tokens, pretrained_biLM, task_weights, task_gamma):</span>
<span id="cb5-251"><a href="#cb5-251" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-252"><a href="#cb5-252" aria-hidden="true" tabindex="-1"></a><span class="co">    从预训练 biLM 中提取 ELMo 表示</span></span>
<span id="cb5-253"><a href="#cb5-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-254"><a href="#cb5-254" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-255"><a href="#cb5-255" aria-hidden="true" tabindex="-1"></a><span class="co">        tokens: 输入词序列 (t_1, ..., t_N)</span></span>
<span id="cb5-256"><a href="#cb5-256" aria-hidden="true" tabindex="-1"></a><span class="co">        pretrained_biLM: 已预训练的 biLM (参数冻结)</span></span>
<span id="cb5-257"><a href="#cb5-257" aria-hidden="true" tabindex="-1"></a><span class="co">        task_weights: 可学习的层权重 w_j (j=0,...,L), 下游任务训练时学习</span></span>
<span id="cb5-258"><a href="#cb5-258" aria-hidden="true" tabindex="-1"></a><span class="co">        task_gamma: 可学习的缩放因子, 下游任务训练时学习</span></span>
<span id="cb5-259"><a href="#cb5-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-260"><a href="#cb5-260" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb5-261"><a href="#cb5-261" aria-hidden="true" tabindex="-1"></a><span class="co">        elmo: [N, d] 的上下文词向量</span></span>
<span id="cb5-262"><a href="#cb5-262" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-263"><a href="#cb5-263" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># biLM 参数冻结</span></span>
<span id="cb5-264"><a href="#cb5-264" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 1: 提取各层表示</span></span>
<span id="cb5-265"><a href="#cb5-265" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> pretrained_biLM.char_cnn(tokens)       <span class="co"># h_{k,0}: [N, 512]</span></span>
<span id="cb5-266"><a href="#cb5-266" aria-hidden="true" tabindex="-1"></a>        h_fwd <span class="op">=</span> pretrained_biLM.forward_lstm(x)     <span class="co"># [N, L, d_proj]</span></span>
<span id="cb5-267"><a href="#cb5-267" aria-hidden="true" tabindex="-1"></a>        h_bwd <span class="op">=</span> pretrained_biLM.backward_lstm(x)    <span class="co"># [N, L, d_proj]</span></span>
<span id="cb5-268"><a href="#cb5-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-269"><a href="#cb5-269" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 2: 拼接前向和后向</span></span>
<span id="cb5-270"><a href="#cb5-270" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> []</span>
<span id="cb5-271"><a href="#cb5-271" aria-hidden="true" tabindex="-1"></a>        h.append(x)                                 <span class="co"># 第0层: 上下文无关</span></span>
<span id="cb5-272"><a href="#cb5-272" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(L):</span>
<span id="cb5-273"><a href="#cb5-273" aria-hidden="true" tabindex="-1"></a>            h.append(concat(h_fwd[:,j,:], h_bwd[:,j,:]))  <span class="co"># 第j层: [N, 2*d_proj]</span></span>
<span id="cb5-274"><a href="#cb5-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-275"><a href="#cb5-275" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: 计算加权和 (此部分参数可学习)</span></span>
<span id="cb5-276"><a href="#cb5-276" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> softmax(task_weights)          <span class="co"># 归一化层权重, Σ s_j = 1</span></span>
<span id="cb5-277"><a href="#cb5-277" aria-hidden="true" tabindex="-1"></a>    elmo <span class="op">=</span> task_gamma <span class="op">*</span> <span class="bu">sum</span>(s[j] <span class="op">*</span> h[j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(L<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb5-278"><a href="#cb5-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-279"><a href="#cb5-279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> elmo  <span class="co"># [N, 1024] (2 * 512)</span></span>
<span id="cb5-280"><a href="#cb5-280" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-281"><a href="#cb5-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-282"><a href="#cb5-282" aria-hidden="true" tabindex="-1"></a>*改编自 Peters et al. (2018) "Deep contextualized word representations", Section 3.2-3.3. [arXiv:1802.05365](https://arxiv.org/abs/1802.05365)*</span>
<span id="cb5-283"><a href="#cb5-283" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-284"><a href="#cb5-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-285"><a href="#cb5-285" aria-hidden="true" tabindex="-1"></a><span class="fu">### 架构细节</span></span>
<span id="cb5-286"><a href="#cb5-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-287"><a href="#cb5-287" aria-hidden="true" tabindex="-1"></a>ELMo的biLM在具体实现上有几个重要的工程决策。</span>
<span id="cb5-288"><a href="#cb5-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-289"><a href="#cb5-289" aria-hidden="true" tabindex="-1"></a>**字符级卷积（Character CNN）作为词嵌入**。ELMo不使用传统的词级别lookup表，而是用字符级CNN来构建词表示。具体来说，每个词的字符序列经过一组不同宽度的卷积核（窗口大小1到7），然后经过max-pooling和两层highway network，得到一个512维的词表示。</span>
<span id="cb5-290"><a href="#cb5-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-291"><a href="#cb5-291" aria-hidden="true" tabindex="-1"></a>这个设计的好处是显著的。首先，它天然地解决了**OOV（Out-of-Vocabulary）问题**——即使遇到从未见过的词，字符CNN也能根据字符模式生成合理的表示。"unhappiness"虽然可能不在词汇表中，但字符CNN可以从"un-"（否定前缀）、"happy"（核心语义）和"-ness"（名词后缀）中组合出合理的表示。其次，它自动捕获了**形态学信息**——同一词族的词（如run, runs, running, runner）会有相似的字符级表示。</span>
<span id="cb5-292"><a href="#cb5-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-293"><a href="#cb5-293" aria-hidden="true" tabindex="-1"></a>**LSTM的规模与投影**。ELMo使用$L=2$层biLSTM，每层每个方向有4096个隐藏单元。这意味着每层的前向和后向拼接后有$4096 \times 2 = 8192$维。为了减小计算和内存开销，每层的LSTM输出通过一个线性投影映射到512维，然后再输入到下一层。</span>
<span id="cb5-294"><a href="#cb5-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-295"><a href="#cb5-295" aria-hidden="true" tabindex="-1"></a>**残差连接**。第一层和第二层LSTM之间有残差连接，有助于梯度流动和训练稳定性。</span>
<span id="cb5-296"><a href="#cb5-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-297"><a href="#cb5-297" aria-hidden="true" tabindex="-1"></a>**总参数量**。整个biLM约有**93.6M（约9360万）**参数。与同期的模型相比，这个规模并不小（GPT-1有1.17亿参数，BERT-Base有1.1亿参数），但ELMo将所有参数都用在了LSTM上，而GPT和BERT则使用Transformer架构。</span>
<span id="cb5-298"><a href="#cb5-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-299"><a href="#cb5-299" aria-hidden="true" tabindex="-1"></a><span class="fu">### ELMo架构总览</span></span>
<span id="cb5-300"><a href="#cb5-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-301"><a href="#cb5-301" aria-hidden="true" tabindex="-1"></a>在进入数值示例之前，让我们先从整体上理解ELMo的架构。下图展示了ELMo的完整信息流：从字符级输入到最终的上下文词向量。</span>
<span id="cb5-302"><a href="#cb5-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-303"><a href="#cb5-303" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb5-304"><a href="#cb5-304" aria-hidden="true" tabindex="-1"></a><span class="fu">## 📌 待绘制：ELMo架构图</span></span>
<span id="cb5-305"><a href="#cb5-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-306"><a href="#cb5-306" aria-hidden="true" tabindex="-1"></a>**内容描述**：ELMo的完整架构示意图，展示从输入到输出的信息流。</span>
<span id="cb5-307"><a href="#cb5-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-308"><a href="#cb5-308" aria-hidden="true" tabindex="-1"></a>**应包含的元素**：</span>
<span id="cb5-309"><a href="#cb5-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-310"><a href="#cb5-310" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**输入层**（底部）：字符序列 → Character CNN（7种卷积核 + max-pooling + highway network）→ 512维词嵌入 $\mathbf{x}_k$</span>
<span id="cb5-311"><a href="#cb5-311" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**第1层 biLSTM**：前向LSTM（4096维 → 投影至512维）和后向LSTM（4096维 → 投影至512维），拼接为1024维 $\mathbf{h}_{k,1}$</span>
<span id="cb5-312"><a href="#cb5-312" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**残差连接**：第1层到第2层之间</span>
<span id="cb5-313"><a href="#cb5-313" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**第2层 biLSTM**：结构同第1层，输出1024维 $\mathbf{h}_{k,2}$</span>
<span id="cb5-314"><a href="#cb5-314" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**ELMo混合层**（顶部）：$s_0 \cdot \mathbf{h}_0 + s_1 \cdot \mathbf{h}_1 + s_2 \cdot \mathbf{h}_2$，乘以 $\gamma$</span>
<span id="cb5-315"><a href="#cb5-315" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**标注关键维度**：512, 4096, 512(投影), 1024(拼接)</span>
<span id="cb5-316"><a href="#cb5-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-317"><a href="#cb5-317" aria-hidden="true" tabindex="-1"></a>**视觉风格**：纵向堆叠，左右对称（前向/后向），参考 Jay Alammar "The Illustrated BERT, ELMo" 的风格。</span>
<span id="cb5-318"><a href="#cb5-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-319"><a href="#cb5-319" aria-hidden="true" tabindex="-1"></a>**建议工具**：D2L/UDL风格的SVG，或使用TikZ/matplotlib生成。</span>
<span id="cb5-320"><a href="#cb5-320" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-321"><a href="#cb5-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-322"><a href="#cb5-322" aria-hidden="true" tabindex="-1"></a><span class="fu">### 完整数值示例：从输入到ELMo表示</span></span>
<span id="cb5-323"><a href="#cb5-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-324"><a href="#cb5-324" aria-hidden="true" tabindex="-1"></a>让我们通过一个简化的数值例子来完整理解ELMo的工作流程。为了可手算，我们将所有维度大幅缩小。</span>
<span id="cb5-325"><a href="#cb5-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-326"><a href="#cb5-326" aria-hidden="true" tabindex="-1"></a>**设定**：</span>
<span id="cb5-327"><a href="#cb5-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-328"><a href="#cb5-328" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>两个句子："I deposited money at the **bank**" 和 "I fished along the river **bank**"</span>
<span id="cb5-329"><a href="#cb5-329" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>简化参数：词嵌入维度 $d = 4$，LSTM隐藏维度 $h = 3$，$L = 2$层</span>
<span id="cb5-330"><a href="#cb5-330" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>目标：对比两个句子中"bank"的ELMo表示</span>
<span id="cb5-331"><a href="#cb5-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-332"><a href="#cb5-332" aria-hidden="true" tabindex="-1"></a>**Step 1: 词嵌入（第0层，上下文无关）**</span>
<span id="cb5-333"><a href="#cb5-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-334"><a href="#cb5-334" aria-hidden="true" tabindex="-1"></a>假设字符CNN为"bank"生成的嵌入在两个句子中相同（因为词本身一样）：</span>
<span id="cb5-335"><a href="#cb5-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-336"><a href="#cb5-336" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-337"><a href="#cb5-337" aria-hidden="true" tabindex="-1"></a>\mathbf{h}_{bank, 0}^{LM} = <span class="co">[</span><span class="ot">0.5,\; -0.2,\; 0.8,\; 0.1</span><span class="co">]</span></span>
<span id="cb5-338"><a href="#cb5-338" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-339"><a href="#cb5-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-340"><a href="#cb5-340" aria-hidden="true" tabindex="-1"></a>这是上下文无关的表示——两个句子中的bank在这一层完全一样。</span>
<span id="cb5-341"><a href="#cb5-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-342"><a href="#cb5-342" aria-hidden="true" tabindex="-1"></a>**Step 2: 第1层biLSTM处理**</span>
<span id="cb5-343"><a href="#cb5-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-344"><a href="#cb5-344" aria-hidden="true" tabindex="-1"></a>前向LSTM从左到右阅读句子。</span>
<span id="cb5-345"><a href="#cb5-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-346"><a href="#cb5-346" aria-hidden="true" tabindex="-1"></a>*句子1*："I deposited money at the **bank**"</span>
<span id="cb5-347"><a href="#cb5-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-348"><a href="#cb5-348" aria-hidden="true" tabindex="-1"></a>前向LSTM在读到bank时，隐状态已经编码了"I deposited money at the"的信息。"deposited"和"money"提供了强烈的金融语境信号：</span>
<span id="cb5-349"><a href="#cb5-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-350"><a href="#cb5-350" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-351"><a href="#cb5-351" aria-hidden="true" tabindex="-1"></a>\overrightarrow{\mathbf{h}}_{bank, 1}^{(S1)} = <span class="co">[</span><span class="ot">0.8,\; 0.3,\; -0.1</span><span class="co">]</span> \quad \text{（编码了"deposited money"的金融信号）}</span>
<span id="cb5-352"><a href="#cb5-352" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-353"><a href="#cb5-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-354"><a href="#cb5-354" aria-hidden="true" tabindex="-1"></a>后向LSTM在bank位置的隐状态编码了句尾信息（这个简化例子中句尾就是bank本身，信息有限）：</span>
<span id="cb5-355"><a href="#cb5-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-356"><a href="#cb5-356" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-357"><a href="#cb5-357" aria-hidden="true" tabindex="-1"></a>\overleftarrow{\mathbf{h}}_{bank, 1}^{(S1)} = <span class="co">[</span><span class="ot">0.2,\; 0.5,\; 0.1</span><span class="co">]</span></span>
<span id="cb5-358"><a href="#cb5-358" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-359"><a href="#cb5-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-360"><a href="#cb5-360" aria-hidden="true" tabindex="-1"></a>拼接得到：</span>
<span id="cb5-361"><a href="#cb5-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-362"><a href="#cb5-362" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-363"><a href="#cb5-363" aria-hidden="true" tabindex="-1"></a>\mathbf{h}_{bank, 1}^{(S1)} = <span class="co">[</span><span class="ot">0.8,\; 0.3,\; -0.1,\; 0.2,\; 0.5,\; 0.1</span><span class="co">]</span></span>
<span id="cb5-364"><a href="#cb5-364" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-365"><a href="#cb5-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-366"><a href="#cb5-366" aria-hidden="true" tabindex="-1"></a>*句子2*："I fished along the river **bank**"</span>
<span id="cb5-367"><a href="#cb5-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-368"><a href="#cb5-368" aria-hidden="true" tabindex="-1"></a>前向LSTM编码了"I fished along the river"的信息。"fished"和"river"提供了自然/地理语境信号：</span>
<span id="cb5-369"><a href="#cb5-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-370"><a href="#cb5-370" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-371"><a href="#cb5-371" aria-hidden="true" tabindex="-1"></a>\overrightarrow{\mathbf{h}}_{bank, 1}^{(S2)} = <span class="co">[</span><span class="ot">-0.3,\; 0.7,\; 0.6</span><span class="co">]</span> \quad \text{（编码了"fished, river"的自然信号）}</span>
<span id="cb5-372"><a href="#cb5-372" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-373"><a href="#cb5-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-374"><a href="#cb5-374" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-375"><a href="#cb5-375" aria-hidden="true" tabindex="-1"></a>\overleftarrow{\mathbf{h}}_{bank, 1}^{(S2)} = <span class="co">[</span><span class="ot">0.1,\; 0.4,\; 0.3</span><span class="co">]</span></span>
<span id="cb5-376"><a href="#cb5-376" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-377"><a href="#cb5-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-378"><a href="#cb5-378" aria-hidden="true" tabindex="-1"></a>拼接得到：</span>
<span id="cb5-379"><a href="#cb5-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-380"><a href="#cb5-380" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-381"><a href="#cb5-381" aria-hidden="true" tabindex="-1"></a>\mathbf{h}_{bank, 1}^{(S2)} = <span class="co">[</span><span class="ot">-0.3,\; 0.7,\; 0.6,\; 0.1,\; 0.4,\; 0.3</span><span class="co">]</span></span>
<span id="cb5-382"><a href="#cb5-382" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-383"><a href="#cb5-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-384"><a href="#cb5-384" aria-hidden="true" tabindex="-1"></a>**关键观察**：虽然两个句子中的"bank"是同一个词，但第1层的表示已经不同了——因为LSTM编码了不同的上下文信息。</span>
<span id="cb5-385"><a href="#cb5-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-386"><a href="#cb5-386" aria-hidden="true" tabindex="-1"></a>**Step 3: 第2层biLSTM处理**</span>
<span id="cb5-387"><a href="#cb5-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-388"><a href="#cb5-388" aria-hidden="true" tabindex="-1"></a>第2层在第1层的基础上进一步抽象，捕获更高层次的语义信息。</span>
<span id="cb5-389"><a href="#cb5-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-390"><a href="#cb5-390" aria-hidden="true" tabindex="-1"></a>*句子1*：$\mathbf{h}_{bank, 2}^{(S1)} = <span class="co">[</span><span class="ot">0.9,\; 0.1,\; -0.5,\; 0.3,\; 0.6,\; -0.2</span><span class="co">]</span>$</span>
<span id="cb5-391"><a href="#cb5-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-392"><a href="#cb5-392" aria-hidden="true" tabindex="-1"></a>*句子2*：$\mathbf{h}_{bank, 2}^{(S2)} = <span class="co">[</span><span class="ot">-0.6,\; 0.8,\; 0.4,\; 0.0,\; 0.3,\; 0.7</span><span class="co">]</span>$</span>
<span id="cb5-393"><a href="#cb5-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-394"><a href="#cb5-394" aria-hidden="true" tabindex="-1"></a>第2层的差异更加明显，因为更高层更能区分"金融bank"和"地理bank"的语义差异。</span>
<span id="cb5-395"><a href="#cb5-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-396"><a href="#cb5-396" aria-hidden="true" tabindex="-1"></a>**Step 4: 构造ELMo表示**</span>
<span id="cb5-397"><a href="#cb5-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-398"><a href="#cb5-398" aria-hidden="true" tabindex="-1"></a>假设我们在下游的**情感分析任务**上学到的层权重为：</span>
<span id="cb5-399"><a href="#cb5-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-400"><a href="#cb5-400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-401"><a href="#cb5-401" aria-hidden="true" tabindex="-1"></a>s_0 = 0.1, \quad s_1 = 0.3, \quad s_2 = 0.6</span>
<span id="cb5-402"><a href="#cb5-402" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-403"><a href="#cb5-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-404"><a href="#cb5-404" aria-hidden="true" tabindex="-1"></a>（情感分析偏重语义，所以第2层权重最大。）</span>
<span id="cb5-405"><a href="#cb5-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-406"><a href="#cb5-406" aria-hidden="true" tabindex="-1"></a>缩放因子 $\gamma = 1.0$。</span>
<span id="cb5-407"><a href="#cb5-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-408"><a href="#cb5-408" aria-hidden="true" tabindex="-1"></a>*句子1中bank的ELMo表示*（简化为只取前4维展示）：</span>
<span id="cb5-409"><a href="#cb5-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-410"><a href="#cb5-410" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-411"><a href="#cb5-411" aria-hidden="true" tabindex="-1"></a>\text{ELMo}_{bank}^{(S1)} = 1.0 \times (0.1 \times \mathbf{h}_0 + 0.3 \times \mathbf{h}_1^{(S1)} + 0.6 \times \mathbf{h}_2^{(S1)})</span>
<span id="cb5-412"><a href="#cb5-412" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-413"><a href="#cb5-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-414"><a href="#cb5-414" aria-hidden="true" tabindex="-1"></a>*句子2中bank的ELMo表示*：</span>
<span id="cb5-415"><a href="#cb5-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-416"><a href="#cb5-416" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-417"><a href="#cb5-417" aria-hidden="true" tabindex="-1"></a>\text{ELMo}_{bank}^{(S2)} = 1.0 \times (0.1 \times \mathbf{h}_0 + 0.3 \times \mathbf{h}_1^{(S2)} + 0.6 \times \mathbf{h}_2^{(S2)})</span>
<span id="cb5-418"><a href="#cb5-418" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-419"><a href="#cb5-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-420"><a href="#cb5-420" aria-hidden="true" tabindex="-1"></a>由于第1层和第2层的隐状态在两个句子中不同，最终的ELMo表示也不同。</span>
<span id="cb5-421"><a href="#cb5-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-422"><a href="#cb5-422" aria-hidden="true" tabindex="-1"></a>**解读**：同一个词"bank"在两个句子中获得了不同的ELMo向量。金融语境下的bank向量与"deposited""money"等金融词更接近，地理语境下的bank向量则与"river""fished"等自然词更接近。语言模型自动完成了词义消歧，无需任何显式的义项标注。</span>
<span id="cb5-423"><a href="#cb5-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-424"><a href="#cb5-424" aria-hidden="true" tabindex="-1"></a>如果下游任务换成**词性标注**，学到的层权重可能变为 $s_0 = 0.2, s_1 = 0.6, s_2 = 0.2$——因为词性标注更依赖句法信息（第1层），而非高层语义（第2层）。</span>
<span id="cb5-425"><a href="#cb5-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-426"><a href="#cb5-426" aria-hidden="true" tabindex="-1"></a><span class="fu">### 下游任务的使用方式</span></span>
<span id="cb5-427"><a href="#cb5-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-428"><a href="#cb5-428" aria-hidden="true" tabindex="-1"></a>ELMo的使用方式非常简单——作为"特征增强"即插即用地加入已有模型。</span>
<span id="cb5-429"><a href="#cb5-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-430"><a href="#cb5-430" aria-hidden="true" tabindex="-1"></a>给定一个已有的NLP模型（如BiLSTM-CRF用于NER，或Bi-Attention用于SQuAD），它原本的输入是静态词向量$\mathbf{x}_k$。使用ELMo后，将输入替换为拼接：</span>
<span id="cb5-431"><a href="#cb5-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-432"><a href="#cb5-432" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-433"><a href="#cb5-433" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">\mathbf{x}_k;\; \text{ELMo}_k^{task}</span><span class="co">]</span></span>
<span id="cb5-434"><a href="#cb5-434" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-435"><a href="#cb5-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-436"><a href="#cb5-436" aria-hidden="true" tabindex="-1"></a>也就是将原始的词向量和ELMo表示拼接在一起，作为模型的新输入。有时，也会在模型的中间层（如LSTM的输出层）再次加入ELMo表示。</span>
<span id="cb5-437"><a href="#cb5-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-438"><a href="#cb5-438" aria-hidden="true" tabindex="-1"></a>训练时，biLM的参数**冻结不变**，只训练层权重$s_j^{task}$、缩放因子$\gamma^{task}$和下游模型的参数。这使得ELMo的使用非常高效——不需要对庞大的biLM进行反向传播。</span>
<span id="cb5-439"><a href="#cb5-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-440"><a href="#cb5-440" aria-hidden="true" tabindex="-1"></a>Peters等人还发现，在ELMo表示上加一个适度的**dropout**可以起到正则化作用，防止下游模型过度依赖ELMo特征。</span>
<span id="cb5-441"><a href="#cb5-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-442"><a href="#cb5-442" aria-hidden="true" tabindex="-1"></a><span class="fu">### 复杂度分析</span></span>
<span id="cb5-443"><a href="#cb5-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-444"><a href="#cb5-444" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 维度 <span class="pp">|</span> 值 <span class="pp">|</span></span>
<span id="cb5-445"><a href="#cb5-445" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|-----|</span></span>
<span id="cb5-446"><a href="#cb5-446" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 模型参数 <span class="pp">|</span> ~93.6M（biLM预训练阶段） <span class="pp">|</span></span>
<span id="cb5-447"><a href="#cb5-447" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 下游任务新增参数 <span class="pp">|</span> 仅 $L + 2$ 个标量（$L+1$个层权重 $+ 1$个缩放因子） <span class="pp">|</span></span>
<span id="cb5-448"><a href="#cb5-448" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 推理时间复杂度 <span class="pp">|</span> $O(N \cdot d_{LSTM}^2 \cdot L)$，其中$N$为序列长度 <span class="pp">|</span></span>
<span id="cb5-449"><a href="#cb5-449" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 推理空间复杂度 <span class="pp">|</span> $O(N \cdot d_{LSTM} \cdot L)$，需要存储每层的隐状态 <span class="pp">|</span></span>
<span id="cb5-450"><a href="#cb5-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-451"><a href="#cb5-451" aria-hidden="true" tabindex="-1"></a>ELMo在推理时需要对每个输入序列运行一次完整的biLSTM前向传播，这比简单的词向量查找要慢得多。但由于biLM参数冻结，不需要反向传播，所以在训练下游任务时的额外开销主要在前向计算上。</span>
<span id="cb5-452"><a href="#cb5-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-453"><a href="#cb5-453" aria-hidden="true" tabindex="-1"></a><span class="fu">### 与其他方法的对比</span></span>
<span id="cb5-454"><a href="#cb5-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-455"><a href="#cb5-455" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 维度 <span class="pp">|</span> 静态词向量 <span class="pp">|</span> ELMo <span class="pp">|</span> GPT (下一章) <span class="pp">|</span></span>
<span id="cb5-456"><a href="#cb5-456" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|-----------|------|-------------|</span></span>
<span id="cb5-457"><a href="#cb5-457" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 表示类型 <span class="pp">|</span> 上下文无关 <span class="pp">|</span> 上下文相关 <span class="pp">|</span> 上下文相关 <span class="pp">|</span></span>
<span id="cb5-458"><a href="#cb5-458" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 预训练架构 <span class="pp">|</span> 浅层网络 <span class="pp">|</span> 双向LSTM <span class="pp">|</span> 单向Transformer <span class="pp">|</span></span>
<span id="cb5-459"><a href="#cb5-459" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 预训练任务 <span class="pp">|</span> 共现预测 <span class="pp">|</span> 双向语言建模 <span class="pp">|</span> 单向语言建模 <span class="pp">|</span></span>
<span id="cb5-460"><a href="#cb5-460" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 迁移方式 <span class="pp">|</span> 初始化Embedding <span class="pp">|</span> 特征拼接（冻结） <span class="pp">|</span> 整体微调 <span class="pp">|</span></span>
<span id="cb5-461"><a href="#cb5-461" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 迁移深度 <span class="pp">|</span> 仅第0层 <span class="pp">|</span> 所有层（加权融合） <span class="pp">|</span> 所有层 <span class="pp">|</span></span>
<span id="cb5-462"><a href="#cb5-462" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 下游任务适配 <span class="pp">|</span> 微调Embedding+训练上层 <span class="pp">|</span> 学习$L+2$个标量+训练原模型 <span class="pp">|</span> 微调整个模型 <span class="pp">|</span></span>
<span id="cb5-463"><a href="#cb5-463" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 多义词处理 <span class="pp">|</span> ❌ <span class="pp">|</span> ✅ <span class="pp">|</span> ✅ <span class="pp">|</span></span>
<span id="cb5-464"><a href="#cb5-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-465"><a href="#cb5-465" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-466"><a href="#cb5-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-467"><a href="#cb5-467" aria-hidden="true" tabindex="-1"></a><span class="fu">## 工程实践</span></span>
<span id="cb5-468"><a href="#cb5-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-469"><a href="#cb5-469" aria-hidden="true" tabindex="-1"></a><span class="fu">### 使用AllenNLP提取ELMo表示</span></span>
<span id="cb5-470"><a href="#cb5-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-471"><a href="#cb5-471" aria-hidden="true" tabindex="-1"></a>在ELMo发布后不久，Allen AI开源了ELMo的预训练模型和使用工具。以下是使用ELMo的标准工作流：</span>
<span id="cb5-472"><a href="#cb5-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-475"><a href="#cb5-475" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb5-476"><a href="#cb5-476" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb5-477"><a href="#cb5-477" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb5-478"><a href="#cb5-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-479"><a href="#cb5-479" aria-hidden="true" tabindex="-1"></a><span class="co"># 方式1：使用 AllenNLP 的 ELMo（原始实现）</span></span>
<span id="cb5-480"><a href="#cb5-480" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> allennlp.modules.elmo <span class="im">import</span> Elmo, batch_to_ids</span>
<span id="cb5-481"><a href="#cb5-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-482"><a href="#cb5-482" aria-hidden="true" tabindex="-1"></a><span class="co"># 加载预训练 ELMo 模型</span></span>
<span id="cb5-483"><a href="#cb5-483" aria-hidden="true" tabindex="-1"></a>options_file <span class="op">=</span> <span class="st">"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json"</span></span>
<span id="cb5-484"><a href="#cb5-484" aria-hidden="true" tabindex="-1"></a>weight_file <span class="op">=</span> <span class="st">"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5"</span></span>
<span id="cb5-485"><a href="#cb5-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-486"><a href="#cb5-486" aria-hidden="true" tabindex="-1"></a><span class="co"># num_output_representations: 需要多少组不同的 ELMo 表示</span></span>
<span id="cb5-487"><a href="#cb5-487" aria-hidden="true" tabindex="-1"></a><span class="co"># （每组有独立的 s_j 和 gamma）</span></span>
<span id="cb5-488"><a href="#cb5-488" aria-hidden="true" tabindex="-1"></a>elmo <span class="op">=</span> Elmo(options_file, weight_file, num_output_representations<span class="op">=</span><span class="dv">1</span>, dropout<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb5-489"><a href="#cb5-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-490"><a href="#cb5-490" aria-hidden="true" tabindex="-1"></a><span class="co"># 准备输入：将词转换为字符 ID</span></span>
<span id="cb5-491"><a href="#cb5-491" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [</span>
<span id="cb5-492"><a href="#cb5-492" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"I"</span>, <span class="st">"deposited"</span>, <span class="st">"money"</span>, <span class="st">"at"</span>, <span class="st">"the"</span>, <span class="st">"bank"</span>],</span>
<span id="cb5-493"><a href="#cb5-493" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"I"</span>, <span class="st">"fished"</span>, <span class="st">"along"</span>, <span class="st">"the"</span>, <span class="st">"river"</span>, <span class="st">"bank"</span>]</span>
<span id="cb5-494"><a href="#cb5-494" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb5-495"><a href="#cb5-495" aria-hidden="true" tabindex="-1"></a>character_ids <span class="op">=</span> batch_to_ids(sentences)  <span class="co"># [batch=2, max_len=6, max_chars=50]</span></span>
<span id="cb5-496"><a href="#cb5-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-497"><a href="#cb5-497" aria-hidden="true" tabindex="-1"></a><span class="co"># 前向传播</span></span>
<span id="cb5-498"><a href="#cb5-498" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> elmo(character_ids)</span>
<span id="cb5-499"><a href="#cb5-499" aria-hidden="true" tabindex="-1"></a><span class="co"># embeddings['elmo_representations']: list of [batch, seq_len, 1024]</span></span>
<span id="cb5-500"><a href="#cb5-500" aria-hidden="true" tabindex="-1"></a><span class="co"># embeddings['mask']: [batch, seq_len]</span></span>
<span id="cb5-501"><a href="#cb5-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-502"><a href="#cb5-502" aria-hidden="true" tabindex="-1"></a>elmo_vectors <span class="op">=</span> embeddings[<span class="st">'elmo_representations'</span>][<span class="dv">0</span>]</span>
<span id="cb5-503"><a href="#cb5-503" aria-hidden="true" tabindex="-1"></a><span class="co"># elmo_vectors.shape: [2, 6, 1024]</span></span>
<span id="cb5-504"><a href="#cb5-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-505"><a href="#cb5-505" aria-hidden="true" tabindex="-1"></a><span class="co"># 对比两个句子中 "bank"（位置5）的 ELMo 表示</span></span>
<span id="cb5-506"><a href="#cb5-506" aria-hidden="true" tabindex="-1"></a>bank_s1 <span class="op">=</span> elmo_vectors[<span class="dv">0</span>, <span class="dv">5</span>, :]  <span class="co"># 句子1中的 bank</span></span>
<span id="cb5-507"><a href="#cb5-507" aria-hidden="true" tabindex="-1"></a>bank_s2 <span class="op">=</span> elmo_vectors[<span class="dv">1</span>, <span class="dv">5</span>, :]  <span class="co"># 句子2中的 bank</span></span>
<span id="cb5-508"><a href="#cb5-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-509"><a href="#cb5-509" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-510"><a href="#cb5-510" aria-hidden="true" tabindex="-1"></a>similarity <span class="op">=</span> F.cosine_similarity(bank_s1.unsqueeze(<span class="dv">0</span>), bank_s2.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb5-511"><a href="#cb5-511" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"两个 'bank' 的余弦相似度: </span><span class="sc">{</span>similarity<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-512"><a href="#cb5-512" aria-hidden="true" tabindex="-1"></a><span class="co"># 预期结果：约 0.6-0.7（明显低于 1.0，说明 ELMo 区分了两个含义）</span></span>
<span id="cb5-513"><a href="#cb5-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-514"><a href="#cb5-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-515"><a href="#cb5-515" aria-hidden="true" tabindex="-1"></a><span class="fu">### 将ELMo集成到已有模型</span></span>
<span id="cb5-516"><a href="#cb5-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-519"><a href="#cb5-519" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb5-520"><a href="#cb5-520" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb5-521"><a href="#cb5-521" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb5-522"><a href="#cb5-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-523"><a href="#cb5-523" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-524"><a href="#cb5-524" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-525"><a href="#cb5-525" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> allennlp.modules.elmo <span class="im">import</span> Elmo, batch_to_ids</span>
<span id="cb5-526"><a href="#cb5-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-527"><a href="#cb5-527" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ELMoSentimentClassifier(nn.Module):</span>
<span id="cb5-528"><a href="#cb5-528" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""使用 ELMo 增强的情感分类器"""</span></span>
<span id="cb5-529"><a href="#cb5-529" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, glove_dim<span class="op">=</span><span class="dv">300</span>, elmo_dim<span class="op">=</span><span class="dv">1024</span>, hidden_dim<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb5-530"><a href="#cb5-530" aria-hidden="true" tabindex="-1"></a>                 num_classes<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb5-531"><a href="#cb5-531" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-532"><a href="#cb5-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-533"><a href="#cb5-533" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ELMo 模块</span></span>
<span id="cb5-534"><a href="#cb5-534" aria-hidden="true" tabindex="-1"></a>        options_file <span class="op">=</span> <span class="st">"..."</span>  <span class="co"># ELMo options JSON</span></span>
<span id="cb5-535"><a href="#cb5-535" aria-hidden="true" tabindex="-1"></a>        weight_file <span class="op">=</span> <span class="st">"..."</span>  <span class="co"># ELMo weights HDF5</span></span>
<span id="cb5-536"><a href="#cb5-536" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.elmo <span class="op">=</span> Elmo(options_file, weight_file,</span>
<span id="cb5-537"><a href="#cb5-537" aria-hidden="true" tabindex="-1"></a>                         num_output_representations<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-538"><a href="#cb5-538" aria-hidden="true" tabindex="-1"></a>                         dropout<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb5-539"><a href="#cb5-539" aria-hidden="true" tabindex="-1"></a>                         requires_grad<span class="op">=</span><span class="va">False</span>)  <span class="co"># 冻结 biLM 参数</span></span>
<span id="cb5-540"><a href="#cb5-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-541"><a href="#cb5-541" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 输入维度 = GloVe + ELMo</span></span>
<span id="cb5-542"><a href="#cb5-542" aria-hidden="true" tabindex="-1"></a>        input_dim <span class="op">=</span> glove_dim <span class="op">+</span> elmo_dim</span>
<span id="cb5-543"><a href="#cb5-543" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-544"><a href="#cb5-544" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 下游分类模型</span></span>
<span id="cb5-545"><a href="#cb5-545" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> nn.LSTM(input_dim, hidden_dim, batch_first<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-546"><a href="#cb5-546" aria-hidden="true" tabindex="-1"></a>                            bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-547"><a href="#cb5-547" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Linear(hidden_dim <span class="op">*</span> <span class="dv">2</span>, num_classes)</span>
<span id="cb5-548"><a href="#cb5-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-549"><a href="#cb5-549" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, glove_embeds, char_ids):</span>
<span id="cb5-550"><a href="#cb5-550" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb5-551"><a href="#cb5-551" aria-hidden="true" tabindex="-1"></a><span class="co">        glove_embeds: [batch, seq_len, 300] 预训练 GloVe 向量</span></span>
<span id="cb5-552"><a href="#cb5-552" aria-hidden="true" tabindex="-1"></a><span class="co">        char_ids:     [batch, seq_len, max_chars] 字符 ID</span></span>
<span id="cb5-553"><a href="#cb5-553" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb5-554"><a href="#cb5-554" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 获取 ELMo 表示</span></span>
<span id="cb5-555"><a href="#cb5-555" aria-hidden="true" tabindex="-1"></a>        elmo_out <span class="op">=</span> <span class="va">self</span>.elmo(char_ids)</span>
<span id="cb5-556"><a href="#cb5-556" aria-hidden="true" tabindex="-1"></a>        elmo_embeds <span class="op">=</span> elmo_out[<span class="st">'elmo_representations'</span>][<span class="dv">0</span>]  <span class="co"># [batch, seq_len, 1024]</span></span>
<span id="cb5-557"><a href="#cb5-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-558"><a href="#cb5-558" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 拼接 GloVe + ELMo</span></span>
<span id="cb5-559"><a href="#cb5-559" aria-hidden="true" tabindex="-1"></a>        combined <span class="op">=</span> torch.cat([glove_embeds, elmo_embeds], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-560"><a href="#cb5-560" aria-hidden="true" tabindex="-1"></a>        <span class="co"># combined: [batch, seq_len, 1324]</span></span>
<span id="cb5-561"><a href="#cb5-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-562"><a href="#cb5-562" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 下游模型处理</span></span>
<span id="cb5-563"><a href="#cb5-563" aria-hidden="true" tabindex="-1"></a>        lstm_out, (h_n, _) <span class="op">=</span> <span class="va">self</span>.lstm(combined)</span>
<span id="cb5-564"><a href="#cb5-564" aria-hidden="true" tabindex="-1"></a>        hidden <span class="op">=</span> torch.cat([h_n[<span class="dv">0</span>], h_n[<span class="dv">1</span>]], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-565"><a href="#cb5-565" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(hidden)</span>
<span id="cb5-566"><a href="#cb5-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-567"><a href="#cb5-567" aria-hidden="true" tabindex="-1"></a><span class="co"># 训练时，只有 lstm 和 classifier 的参数会被更新</span></span>
<span id="cb5-568"><a href="#cb5-568" aria-hidden="true" tabindex="-1"></a><span class="co"># ELMo 内部的 biLM 参数冻结，但层权重 s_j 和 gamma 会学习</span></span>
<span id="cb5-569"><a href="#cb5-569" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb5-570"><a href="#cb5-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-571"><a href="#cb5-571" aria-hidden="true" tabindex="-1"></a><span class="fu">### 复现的关键细节</span></span>
<span id="cb5-572"><a href="#cb5-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-573"><a href="#cb5-573" aria-hidden="true" tabindex="-1"></a>如果你要复现ELMo的原始实验或在自己的任务上使用ELMo，以下几个实现细节至关重要。</span>
<span id="cb5-574"><a href="#cb5-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-575"><a href="#cb5-575" aria-hidden="true" tabindex="-1"></a>**字符级输入**。ELMo的输入不是词ID，而是字符ID序列。每个词被表示为一个字符序列（最长50个字符），经过字符CNN后得到词表示。这意味着你的数据预处理管道需要保留原始字符形式，而不是只提供词级别的token。</span>
<span id="cb5-576"><a href="#cb5-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-577"><a href="#cb5-577" aria-hidden="true" tabindex="-1"></a>**Dropout的位置**。Peters等人推荐在ELMo表示上加dropout（通常0.5），而且是在拼接到下游模型之前加。这个dropout比直觉中的值要高，但在实践中确实能有效防止过拟合。</span>
<span id="cb5-578"><a href="#cb5-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-579"><a href="#cb5-579" aria-hidden="true" tabindex="-1"></a>**层权重的初始化**。层权重$w_j$通常初始化为相等的值（即$s_j = 1/(L+1)$），这意味着初始时所有层的贡献相等。训练过程中，权重会逐渐偏向对当前任务最有用的层。</span>
<span id="cb5-580"><a href="#cb5-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-581"><a href="#cb5-581" aria-hidden="true" tabindex="-1"></a>**ELMo预训练数据**。原始ELMo在1B Word Benchmark（约8亿词）上预训练。如果你需要在特定领域使用ELMo，Allen AI也提供了在不同数据上预训练的版本（如PubMed版本用于生物医学领域）。</span>
<span id="cb5-582"><a href="#cb5-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-583"><a href="#cb5-583" aria-hidden="true" tabindex="-1"></a><span class="fu">### 实验结果</span></span>
<span id="cb5-584"><a href="#cb5-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-585"><a href="#cb5-585" aria-hidden="true" tabindex="-1"></a>Peters等人在6个NLP基准任务上评测了ELMo的效果：</span>
<span id="cb5-586"><a href="#cb5-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-587"><a href="#cb5-587" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 任务 <span class="pp">|</span> 基线模型 <span class="pp">|</span> +ELMo <span class="pp">|</span> 绝对提升 <span class="pp">|</span> 相对错误减少 <span class="pp">|</span></span>
<span id="cb5-588"><a href="#cb5-588" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|---------|-------|---------|-------------|</span></span>
<span id="cb5-589"><a href="#cb5-589" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SQuAD (F1) <span class="pp">|</span> 81.1 <span class="pp">|</span> 85.8 <span class="pp">|</span> +4.7 <span class="pp">|</span> 24.9% <span class="pp">|</span></span>
<span id="cb5-590"><a href="#cb5-590" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SNLI (Acc) <span class="pp">|</span> 88.6 <span class="pp">|</span> 88.7 <span class="pp">|</span> +0.1 <span class="pp">|</span> ~1% <span class="pp">|</span></span>
<span id="cb5-591"><a href="#cb5-591" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SRL (F1) <span class="pp">|</span> 81.4 <span class="pp">|</span> 84.6 <span class="pp">|</span> +3.2 <span class="pp">|</span> 17.2% <span class="pp">|</span></span>
<span id="cb5-592"><a href="#cb5-592" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Coref (Avg F1) <span class="pp">|</span> 67.2 <span class="pp">|</span> 70.4 <span class="pp">|</span> +3.2 <span class="pp">|</span> 9.8% <span class="pp">|</span></span>
<span id="cb5-593"><a href="#cb5-593" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> NER (F1) <span class="pp">|</span> 90.15 <span class="pp">|</span> 92.22 <span class="pp">|</span> +2.1 <span class="pp">|</span> 21.1% <span class="pp">|</span></span>
<span id="cb5-594"><a href="#cb5-594" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> SST-5 (Acc) <span class="pp">|</span> 53.7 <span class="pp">|</span> 54.7 <span class="pp">|</span> +1.0 <span class="pp">|</span> 2.2% <span class="pp">|</span></span>
<span id="cb5-595"><a href="#cb5-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-596"><a href="#cb5-596" aria-hidden="true" tabindex="-1"></a>值得注意的是，ELMo的提升在不同任务上差异很大。SQuAD（阅读理解）和NER获得了最大的提升，而SNLI和SST-5的提升较小。一个可能的解释是：阅读理解和NER更依赖于精细的上下文理解能力（需要根据上下文判断一个词的具体含义或实体类型），而SNLI和SST-5更依赖于全局的语义匹配。</span>
<span id="cb5-597"><a href="#cb5-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-598"><a href="#cb5-598" aria-hidden="true" tabindex="-1"></a>另一个值得关注的维度是**数据效率**。Peters等人在论文中展示了ELMo在不同训练数据量下的效果对比（以SRL任务为例）：</span>
<span id="cb5-599"><a href="#cb5-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-600"><a href="#cb5-600" aria-hidden="true" tabindex="-1"></a><span class="al">![ELMo的数据效率：在SRL任务上，使用ELMo（蓝色）只需要约1%的训练数据就能达到不使用ELMo的基线模型（橙色）用100%数据达到的性能。这意味着ELMo的预训练知识可以大幅减少对标注数据的依赖。](figures/chapter-11/original/fig1-sample-efficiency.png)</span>{#fig-sample-efficiency width=75%}</span>
<span id="cb5-601"><a href="#cb5-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-602"><a href="#cb5-602" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb5-603"><a href="#cb5-603" aria-hidden="true" tabindex="-1"></a>*Source: Peters et al. (2018), Figure 1. [arXiv:1802.05365](https://arxiv.org/abs/1802.05365)*</span>
<span id="cb5-604"><a href="#cb5-604" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-605"><a href="#cb5-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-606"><a href="#cb5-606" aria-hidden="true" tabindex="-1"></a>这个结果有深远的意义：预训练模型不仅在全量数据下提升性能，更重要的是它在**小数据场景**下带来的增益更为显著。这与迁移学习的核心价值一致——利用在大数据上学到的通用知识，减少对特定任务标注数据的依赖。</span>
<span id="cb5-607"><a href="#cb5-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-608"><a href="#cb5-608" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-609"><a href="#cb5-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-610"><a href="#cb5-610" aria-hidden="true" tabindex="-1"></a><span class="fu">## 深入理解</span></span>
<span id="cb5-611"><a href="#cb5-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-612"><a href="#cb5-612" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **研究者必读**：这一节探讨ELMo为什么有效、层级信息的分析、以及与同期工作的比较</span></span>
<span id="cb5-613"><a href="#cb5-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-614"><a href="#cb5-614" aria-hidden="true" tabindex="-1"></a><span class="fu">### 为什么有效？——层级信息分析</span></span>
<span id="cb5-615"><a href="#cb5-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-616"><a href="#cb5-616" aria-hidden="true" tabindex="-1"></a>ELMo最令人兴奋的发现之一是：**biLM不同层捕获了质量不同的语言信息**。Peters等人通过两个探针实验证实了这一点。</span>
<span id="cb5-617"><a href="#cb5-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-618"><a href="#cb5-618" aria-hidden="true" tabindex="-1"></a>**实验一：词义消歧（Word Sense Disambiguation, WSD）**。他们在一个标准的WSD数据集上测试了biLM不同层的表现。结果表明：第2层（顶层）在WSD任务上的表现最好，F1分数为67.2%，相比之下第1层只有63.7%。这说明高层更善于捕获语义信息——理解一个词在特定上下文中的精确含义。</span>
<span id="cb5-619"><a href="#cb5-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-620"><a href="#cb5-620" aria-hidden="true" tabindex="-1"></a>**实验二：词性标注（Part-of-Speech Tagging）**。有趣的是，在POS标注任务上，情况反了过来：第1层的表现（97.1%准确率）与第2层相当甚至略好。这说明低层更偏向捕获句法信息——词的语法类别主要取决于局部的语法结构，不需要深层的语义理解。</span>
<span id="cb5-621"><a href="#cb5-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-622"><a href="#cb5-622" aria-hidden="true" tabindex="-1"></a>这个发现有一个深刻的启示：**一个良好训练的语言模型自然地将语言信息按层级组织——低层编码句法、高层编码语义**。这与CV中CNN的层级特征（低层边缘纹理、高层物体部件）形成了有趣的平行。</span>
<span id="cb5-623"><a href="#cb5-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-624"><a href="#cb5-624" aria-hidden="true" tabindex="-1"></a>下游任务的层权重学习结果进一步验证了这个规律。Peters等人报告，在NER和SRL等序列标注任务上，学到的权重倾向于更均匀地分配到各层；而在需要更多语义理解的任务上，顶层获得了更大的权重。</span>
<span id="cb5-625"><a href="#cb5-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-626"><a href="#cb5-626" aria-hidden="true" tabindex="-1"></a>下图展示了Peters等人在论文中报告的不同任务上学到的层权重分布：</span>
<span id="cb5-627"><a href="#cb5-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-628"><a href="#cb5-628" aria-hidden="true" tabindex="-1"></a><span class="al">![不同下游任务学到的ELMo层权重。每个任务对biLM各层的偏好不同：偏句法的任务（如POS标注）更依赖底层，偏语义的任务（如WSD）更依赖顶层。这直接验证了"低层编码句法、高层编码语义"的假设。](figures/chapter-11/original/fig2-layer-weights.png)</span>{#fig-layer-weights width=75%}</span>
<span id="cb5-629"><a href="#cb5-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-630"><a href="#cb5-630" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb5-631"><a href="#cb5-631" aria-hidden="true" tabindex="-1"></a>*Source: Peters et al. (2018), Figure 2. [arXiv:1802.05365](https://arxiv.org/abs/1802.05365)*</span>
<span id="cb5-632"><a href="#cb5-632" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb5-633"><a href="#cb5-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-634"><a href="#cb5-634" aria-hidden="true" tabindex="-1"></a><span class="fu">### 为什么用所有层比只用顶层好？</span></span>
<span id="cb5-635"><a href="#cb5-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-636"><a href="#cb5-636" aria-hidden="true" tabindex="-1"></a>一个自然的问题是：既然顶层包含了最抽象的语义信息，为什么不只用顶层呢？</span>
<span id="cb5-637"><a href="#cb5-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-638"><a href="#cb5-638" aria-hidden="true" tabindex="-1"></a>Peters等人的消融实验给出了明确的答案。在6个任务上，使用所有层的加权平均平均比只用最后一层好1.0-2.0个百分点。原因在于不同任务需要不同层次的语言信息。词性标注需要句法信息（低层），词义消歧需要语义信息（高层），而更复杂的任务如SRL和阅读理解则需要同时利用多个层次的信息。ELMo的层权重机制让模型自动找到每个任务的最优信息组合。</span>
<span id="cb5-639"><a href="#cb5-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-640"><a href="#cb5-640" aria-hidden="true" tabindex="-1"></a>这个设计选择也解释了为什么ELMo在某些任务上的提升特别大：如果一个任务恰好需要biLM某个层已经很好地编码了的信息，ELMo就能提供巨大的增益。</span>
<span id="cb5-641"><a href="#cb5-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-642"><a href="#cb5-642" aria-hidden="true" tabindex="-1"></a><span class="fu">### 与同期工作的比较：TagLM和CoVe</span></span>
<span id="cb5-643"><a href="#cb5-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-644"><a href="#cb5-644" aria-hidden="true" tabindex="-1"></a>ELMo并非凭空出现的。在它之前，有两个相关工作值得提及。</span>
<span id="cb5-645"><a href="#cb5-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-646"><a href="#cb5-646" aria-hidden="true" tabindex="-1"></a>**TagLM（Peters et al., 2017）**。有趣的是，ELMo的第一作者之前已经在2017年发表过一篇名为"Semi-supervised sequence tagging with bidirectional language models"的工作。TagLM也是用biLM的隐状态来增强序列标注模型，但只使用了**最顶层**的表示，没有层混合机制。ELMo的关键改进正是"暴露所有层 + 学习层权重"这个设计。</span>
<span id="cb5-647"><a href="#cb5-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-648"><a href="#cb5-648" aria-hidden="true" tabindex="-1"></a>**CoVe（McCann et al., 2017）**。"Learned in Translation: Contextualized Word Vectors"用一个在大规模翻译数据上训练的Encoder来生成上下文词向量。CoVe证明了上下文词向量的有效性，但它的预训练需要**平行语料**（标注数据），而非无标注文本。ELMo通过使用语言模型目标，完全消除了对标注数据的依赖。</span>
<span id="cb5-649"><a href="#cb5-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-650"><a href="#cb5-650" aria-hidden="true" tabindex="-1"></a><span class="fu">### 方法的边界条件</span></span>
<span id="cb5-651"><a href="#cb5-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-652"><a href="#cb5-652" aria-hidden="true" tabindex="-1"></a>**假设一：双向信息的独立性**。biLM将前向和后向LSTM作为两个独立的模型训练，仅在输入和输出层共享参数。这意味着前向LSTM在位置$k$生成表示时只能利用左侧上下文$t_1, \ldots, t_{k-1}$，后向LSTM只能利用右侧上下文$t_{k+1}, \ldots, t_N$。两个方向的信息在ELMo公式中通过**拼接**来组合，但并没有在LSTM内部进行深度融合。这是ELMo"双向性"的一个根本限制——它是"分离式双向"而非"融合式双向"。</span>
<span id="cb5-653"><a href="#cb5-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-654"><a href="#cb5-654" aria-hidden="true" tabindex="-1"></a>**假设二：语言模型是足够好的预训练目标**。ELMo假设"预测下一个/前一个词"这个训练目标能够迫使模型学习深层的语言知识。虽然实验证明这个假设基本成立，但语言模型目标也有局限——它偏向于学习**局部**的语法和搭配模式，对于需要全局推理的知识（如数学逻辑、因果关系）的学习效率可能较低。</span>
<span id="cb5-655"><a href="#cb5-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-656"><a href="#cb5-656" aria-hidden="true" tabindex="-1"></a>**失效条件**。ELMo在以下场景表现不佳：当下游任务的领域与预训练数据差异太大时（如biLM在新闻文本上预训练，但应用于法律文本），上下文表示的质量会下降。当句子非常短（如只有2-3个词）时，上下文信息有限，ELMo退化为接近静态词向量。当面对高度创造性的语言使用（如诗歌中的反讽、双关语）时，语言模型的"常规化"理解可能无法捕获这些特殊用法。</span>
<span id="cb5-657"><a href="#cb5-657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-658"><a href="#cb5-658" aria-hidden="true" tabindex="-1"></a><span class="fu">### 开放研究问题（2018年视角）</span></span>
<span id="cb5-659"><a href="#cb5-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-660"><a href="#cb5-660" aria-hidden="true" tabindex="-1"></a>站在2018年初的时间节点——ELMo刚刚发表——几个关键的研究问题浮出水面。</span>
<span id="cb5-661"><a href="#cb5-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-662"><a href="#cb5-662" aria-hidden="true" tabindex="-1"></a>**预训练架构的最优选择**。ELMo使用LSTM，但Transformer已经在2017年证明了其优越性（第8章）。如果用Transformer替代LSTM来构建语言模型，效果会更好吗？这个问题在同年的GPT中得到了回答——答案是"是的"。</span>
<span id="cb5-663"><a href="#cb5-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-664"><a href="#cb5-664" aria-hidden="true" tabindex="-1"></a>**特征提取 vs 微调**。ELMo采用"冻结biLM + 提取特征"的范式，这虽然简单，但是否是最优的迁移方式？是否可以微调biLM的全部参数来获得更好的效果？这个问题在同年的GPT和2019年的BERT中得到了回答——微调通常优于特征提取。</span>
<span id="cb5-665"><a href="#cb5-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-666"><a href="#cb5-666" aria-hidden="true" tabindex="-1"></a>**真正的双向融合**。ELMo的"双向"是两个独立LSTM的拼接，前向和后向的信息没有在内部互相交流。能否设计出一种架构，让左右两个方向的信息在每一层都深度融合？这个问题在2019年的BERT中通过Masked Language Model得到了优雅的回答——通过遮蔽而非分方向来实现真正的双向注意力。</span>
<span id="cb5-667"><a href="#cb5-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-668"><a href="#cb5-668" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-669"><a href="#cb5-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-670"><a href="#cb5-670" aria-hidden="true" tabindex="-1"></a><span class="fu">## 局限性与未解决的问题</span></span>
<span id="cb5-671"><a href="#cb5-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-672"><a href="#cb5-672" aria-hidden="true" tabindex="-1"></a><span class="fu">### "分离式双向"的根本缺陷</span></span>
<span id="cb5-673"><a href="#cb5-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-674"><a href="#cb5-674" aria-hidden="true" tabindex="-1"></a>ELMo最根本的局限在于它的双向性是**分离的（concatenated bidirectional）**，而非**融合的（jointly bidirectional）**。</span>
<span id="cb5-675"><a href="#cb5-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-676"><a href="#cb5-676" aria-hidden="true" tabindex="-1"></a>具体来说，前向LSTM在生成位置$k$的表示时，只能看到$t_1, \ldots, t_{k-1}$；后向LSTM只能看到$t_{k+1}, \ldots, t_N$。两者的表示通过简单拼接组合：</span>
<span id="cb5-677"><a href="#cb5-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-678"><a href="#cb5-678" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-679"><a href="#cb5-679" aria-hidden="true" tabindex="-1"></a>\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j};\; \overleftarrow{\mathbf{h}}_{k,j}]</span>
<span id="cb5-680"><a href="#cb5-680" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb5-681"><a href="#cb5-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-682"><a href="#cb5-682" aria-hidden="true" tabindex="-1"></a>这种设计的问题在于，两个方向的信息从未在模型内部进行"深度对话"。考虑句子"The animal didn't cross the street because **it** was too tired"。要理解"it"指代"animal"还是"street"，需要同时综合左侧信息（"The animal didn't cross"）和右侧信息（"was too tired"）进行推理。在ELMo中，前向LSTM看到"The animal didn't cross the street because"可能倾向于"it = street"（因为"street"距离更近），后向LSTM看到"was too tired"倾向于"it = animal"（因为街道不会累）。两者拼接后的信息确实包含了正确的线索，但这些线索是被动地堆叠在一起，没有经过交互式的推理。</span>
<span id="cb5-683"><a href="#cb5-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-684"><a href="#cb5-684" aria-hidden="true" tabindex="-1"></a>为什么ELMo不能简单地将两个方向融合呢？原因在于语言模型的约束。如果一个模型在预测位置$k$的词时同时能看到左右两侧的信息，那么它可以直接"偷看"答案——位置$k$的词就在输入中。这会导致语言模型的训练目标变得毫无意义——模型不需要真正理解语言，只需要学会复制输入就能完美预测。这就是为什么前向和后向必须分开训练。</span>
<span id="cb5-685"><a href="#cb5-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-686"><a href="#cb5-686" aria-hidden="true" tabindex="-1"></a>BERT后来用一个巧妙的方法解决了这个问题：**遮蔽（Masking）**。随机遮蔽输入中的部分词，然后让模型根据所有未遮蔽的上下文（包括左右两侧）来预测被遮蔽的词。这样模型无法"偷看"，但又能真正地利用双向信息——这正是第13章的主题。</span>
<span id="cb5-687"><a href="#cb5-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-688"><a href="#cb5-688" aria-hidden="true" tabindex="-1"></a><span class="fu">### 特征提取范式的局限</span></span>
<span id="cb5-689"><a href="#cb5-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-690"><a href="#cb5-690" aria-hidden="true" tabindex="-1"></a>ELMo采用的是**特征提取（feature extraction）**范式：冻结预训练的biLM参数，只学习少量的层权重和缩放因子。这种方式有几个限制。</span>
<span id="cb5-691"><a href="#cb5-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-692"><a href="#cb5-692" aria-hidden="true" tabindex="-1"></a>首先，**预训练模型无法为目标任务做出任何调整**。biLM在大规模通用文本上训练，其参数永远不会针对下游的情感分析或NER做任何适配。上一章讨论的ULMFiT已经证明了微调的巨大优势，但ELMo选择了更保守的特征提取路线。</span>
<span id="cb5-693"><a href="#cb5-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-694"><a href="#cb5-694" aria-hidden="true" tabindex="-1"></a>其次，**下游模型仍然需要从零设计和训练**。使用ELMo时，你仍然需要为每个任务设计一个完整的模型架构（如BiLSTM-CRF用于NER，BiDAF用于QA），ELMo只是提供了更好的输入特征。这与GPT和BERT后来采用的"预训练一个模型 + 简单分类头"的极简方式形成了对比。</span>
<span id="cb5-695"><a href="#cb5-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-696"><a href="#cb5-696" aria-hidden="true" tabindex="-1"></a><span class="fu">### LSTM的可扩展性问题</span></span>
<span id="cb5-697"><a href="#cb5-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-698"><a href="#cb5-698" aria-hidden="true" tabindex="-1"></a>ELMo使用LSTM作为backbone，而LSTM有一个固有的扩展性瓶颈：**顺序计算**。LSTM必须逐位置地处理序列——位置$k$的隐状态依赖于位置$k-1$的隐状态——这使得它无法在序列维度上并行化。当模型规模增大（更多层、更大隐藏维度）或序列变长时，训练速度会显著下降。</span>
<span id="cb5-699"><a href="#cb5-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-700"><a href="#cb5-700" aria-hidden="true" tabindex="-1"></a>第8章我们已经看到，Transformer通过Self-Attention实现了完全并行的计算。同样是在2018年，GPT选择了Transformer Decoder作为预训练架构，获得了更好的可扩展性。ELMo的LSTM架构虽然在2018年已经足够强大，但在追求更大规模的"scaling law"趋势下，它注定会被Transformer取代。</span>
<span id="cb5-701"><a href="#cb5-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-702"><a href="#cb5-702" aria-hidden="true" tabindex="-1"></a><span class="fu">### 这些局限导向了什么？</span></span>
<span id="cb5-703"><a href="#cb5-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-704"><a href="#cb5-704" aria-hidden="true" tabindex="-1"></a>ELMo的三个局限精确地预示了预训练技术接下来的演进方向。</span>
<span id="cb5-705"><a href="#cb5-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-706"><a href="#cb5-706" aria-hidden="true" tabindex="-1"></a>分离式双向的缺陷催生了**BERT的Masked Language Model**——通过遮蔽来实现真正的双向融合（第13章）。</span>
<span id="cb5-707"><a href="#cb5-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-708"><a href="#cb5-708" aria-hidden="true" tabindex="-1"></a>特征提取范式的局限推动了**GPT的全模型微调路线**——预训练整个模型，然后在下游任务上微调所有参数（第12章）。</span>
<span id="cb5-709"><a href="#cb5-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-710"><a href="#cb5-710" aria-hidden="true" tabindex="-1"></a>LSTM的可扩展性问题则加速了**Transformer成为预训练的标准骨架**——GPT和BERT都选择了Transformer，这使得模型可以在更大的数据和更大的参数量下继续获益。</span>
<span id="cb5-711"><a href="#cb5-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-712"><a href="#cb5-712" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 下一章预告：第12章将介绍GPT——OpenAI用Transformer Decoder进行自回归预训练的开创性工作。GPT与ELMo的关键差异在于两个方面：用Transformer替代LSTM作为骨架架构，以及用全模型微调替代特征提取作为迁移方式。这两个选择将推动预训练范式进入一个新的阶段。</span></span>
<span id="cb5-713"><a href="#cb5-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-714"><a href="#cb5-714" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-715"><a href="#cb5-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-716"><a href="#cb5-716" aria-hidden="true" tabindex="-1"></a><span class="fu">## 本章小结</span></span>
<span id="cb5-717"><a href="#cb5-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-718"><a href="#cb5-718" aria-hidden="true" tabindex="-1"></a><span class="fu">### 核心要点回顾</span></span>
<span id="cb5-719"><a href="#cb5-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-720"><a href="#cb5-720" aria-hidden="true" tabindex="-1"></a>这一章我们详细介绍了ELMo——第一个生成上下文相关词向量的预训练模型。</span>
<span id="cb5-721"><a href="#cb5-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-722"><a href="#cb5-722" aria-hidden="true" tabindex="-1"></a>核心问题是静态词向量无法处理一词多义：同一个词在不同上下文中应该有不同的表示，但Word2Vec/GloVe为每个词只分配一个固定向量。核心洞察是用一个深层双向LSTM语言模型去"阅读"上下文，然后从模型的各层中提取上下文相关的词表示。</span>
<span id="cb5-723"><a href="#cb5-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-724"><a href="#cb5-724" aria-hidden="true" tabindex="-1"></a>ELMo的技术方案包含三个核心要素：双向语言模型（biLM）提供了强大的上下文建模能力；暴露所有层的表示并通过可学习的权重混合，让不同的下游任务自动选择最适合的信息层次；字符级CNN作为输入层，天然地解决了OOV问题。</span>
<span id="cb5-725"><a href="#cb5-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-726"><a href="#cb5-726" aria-hidden="true" tabindex="-1"></a>实验表明，ELMo在6个NLP任务上带来了显著的提升，尤其是在需要精细上下文理解的任务（如阅读理解和NER）上效果最为突出。更深层的发现是biLM的不同层编码了不同层次的语言信息：低层偏句法、高层偏语义。</span>
<span id="cb5-727"><a href="#cb5-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-728"><a href="#cb5-728" aria-hidden="true" tabindex="-1"></a>然而，ELMo也有明确的局限：分离式双向（前向和后向LSTM独立运行）、特征提取范式（不微调预训练模型）、以及LSTM的可扩展性瓶颈。这些局限直接催生了后续的GPT和BERT。</span>
<span id="cb5-729"><a href="#cb5-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-730"><a href="#cb5-730" aria-hidden="true" tabindex="-1"></a><span class="fu">### 关键公式速查</span></span>
<span id="cb5-731"><a href="#cb5-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-732"><a href="#cb5-732" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 公式 <span class="pp">|</span> 含义 <span class="pp">|</span></span>
<span id="cb5-733"><a href="#cb5-733" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|------|</span></span>
<span id="cb5-734"><a href="#cb5-734" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\sum_{k=1}^{N}(\log p_{fwd} + \log p_{bwd})$ <span class="pp">|</span> biLM的训练目标：最大化双向对数似然 <span class="pp">|</span></span>
<span id="cb5-735"><a href="#cb5-735" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\mathbf{h}_{k,j}^{LM} = [\overrightarrow{\mathbf{h}}_{k,j};\; \overleftarrow{\mathbf{h}}_{k,j}]$ <span class="pp">|</span> 第$j$层的拼接表示 <span class="pp">|</span></span>
<span id="cb5-736"><a href="#cb5-736" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $\text{ELMo}_k^{task} = \gamma^{task} \sum_{j=0}^{L} s_j^{task}\; \mathbf{h}_{k,j}^{LM}$ <span class="pp">|</span> ELMo核心公式：所有层的加权和 <span class="pp">|</span></span>
<span id="cb5-737"><a href="#cb5-737" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> $s_j = \text{softmax}(w_j)$ <span class="pp">|</span> 层权重的softmax归一化 <span class="pp">|</span></span>
<span id="cb5-738"><a href="#cb5-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-739"><a href="#cb5-739" aria-hidden="true" tabindex="-1"></a><span class="fu">### 思考题</span></span>
<span id="cb5-740"><a href="#cb5-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-741"><a href="#cb5-741" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**[概念理解]** ELMo的"双向"和BERT的"双向"有何本质区别？为什么说ELMo是"分离式双向"而BERT是"融合式双向"？ELMo的设计为什么不能直接让前向和后向LSTM在内部交互？</span>
<span id="cb5-742"><a href="#cb5-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-743"><a href="#cb5-743" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**[数学推导]** 假设ELMo使用$L=2$层biLM，第0层维度为512，第1、2层每个方向4096维（拼接后8192维），但经过投影后降为1024维。(a) ELMo最终表示的维度是多少？(b) 下游任务需要学习多少个新参数（只算层权重和缩放因子）？(c) 如果biLM的总参数量为93.6M，计算ELMo新增参数占biLM参数的比例。</span>
<span id="cb5-744"><a href="#cb5-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-745"><a href="#cb5-745" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**[工程实践]** 在一个文本分类任务上，分别使用(a)GloVe词向量、(b)ELMo+GloVe拼接、(c)只用ELMo三种输入配置，对比模型性能。观察在不同数据量（100, 1000, 10000样本）下ELMo的优势如何变化。</span>
<span id="cb5-746"><a href="#cb5-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-747"><a href="#cb5-747" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**[研究思考]** Peters等人发现biLM的低层偏句法、高层偏语义。如果biLM有10层而非2层，你预测中间层会编码什么样的信息？这种信息分层是语言模型训练目标的必然结果，还是LSTM架构的偶然产物？如果用Transformer替代LSTM，分层模式会不同吗？（提示：后来BERT的探针实验提供了部分答案。）</span>
<span id="cb5-748"><a href="#cb5-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-749"><a href="#cb5-749" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**[对比分析]** ELMo（特征提取）和ULMFiT（微调）代表了预训练迁移的两条路线。从理论角度分析，在什么条件下特征提取更好？在什么条件下微调更好？（提示：考虑数据量、领域差异、计算资源等因素。）</span>
<span id="cb5-750"><a href="#cb5-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-751"><a href="#cb5-751" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-752"><a href="#cb5-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-753"><a href="#cb5-753" aria-hidden="true" tabindex="-1"></a><span class="fu">## 延伸阅读</span></span>
<span id="cb5-754"><a href="#cb5-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-755"><a href="#cb5-755" aria-hidden="true" tabindex="-1"></a><span class="fu">### 核心论文（必读）</span></span>
<span id="cb5-756"><a href="#cb5-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-757"><a href="#cb5-757" aria-hidden="true" tabindex="-1"></a>**Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). "Deep contextualized word representations"**。ELMo的原始论文。重点阅读：Section 3（biLM架构和ELMo公式）、Section 4（实验结果）、Section 5.1（层级信息分析）。可快速浏览：Section 2的相关工作部分。<span class="co">[</span><span class="ot">arXiv:1802.05365</span><span class="co">](https://arxiv.org/abs/1802.05365)</span></span>
<span id="cb5-758"><a href="#cb5-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-759"><a href="#cb5-759" aria-hidden="true" tabindex="-1"></a><span class="fu">### 前驱工作</span></span>
<span id="cb5-760"><a href="#cb5-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-761"><a href="#cb5-761" aria-hidden="true" tabindex="-1"></a>**Peters, M.E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). "Semi-supervised sequence tagging with bidirectional language models" (TagLM)**。ELMo的前身工作，只用biLM顶层作为特征，没有层混合机制。对比TagLM和ELMo可以清晰地看到"暴露所有层"这个设计选择的价值。<span class="co">[</span><span class="ot">arXiv:1705.00108</span><span class="co">](https://arxiv.org/abs/1705.00108)</span></span>
<span id="cb5-762"><a href="#cb5-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-763"><a href="#cb5-763" aria-hidden="true" tabindex="-1"></a>**McCann, B., Bradbury, J., Xiong, C., &amp; Socher, R. (2017). "Learned in Translation: Contextualized Word Vectors" (CoVe)**。用机器翻译编码器生成上下文词向量。与ELMo的关键区别：CoVe需要平行语料（标注数据），而ELMo只需要无标注文本。<span class="co">[</span><span class="ot">arXiv:1708.00107</span><span class="co">](https://arxiv.org/abs/1708.00107)</span></span>
<span id="cb5-764"><a href="#cb5-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-765"><a href="#cb5-765" aria-hidden="true" tabindex="-1"></a><span class="fu">### 后续发展</span></span>
<span id="cb5-766"><a href="#cb5-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-767"><a href="#cb5-767" aria-hidden="true" tabindex="-1"></a>**Radford, A., Narasimhan, K., Salimans, T., &amp; Sutskever, I. (2018). "Improving Language Understanding by Generative Pre-Training" (GPT)**。用Transformer Decoder + 全模型微调替代ELMo的LSTM + 特征提取——下一章的主题。</span>
<span id="cb5-768"><a href="#cb5-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-769"><a href="#cb5-769" aria-hidden="true" tabindex="-1"></a>**Devlin, J., Chang, M.W., Lee, K., &amp; Toutanova, K. (2019). "BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding"**。解决了ELMo的"分离式双向"问题，用Masked LM实现真正的双向融合——第13章的主题。<span class="co">[</span><span class="ot">arXiv:1810.04805</span><span class="co">](https://arxiv.org/abs/1810.04805)</span></span>
<span id="cb5-770"><a href="#cb5-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-771"><a href="#cb5-771" aria-hidden="true" tabindex="-1"></a><span class="fu">### 分析与探针研究</span></span>
<span id="cb5-772"><a href="#cb5-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-773"><a href="#cb5-773" aria-hidden="true" tabindex="-1"></a>**Peters, M.E., Neumann, M., Zettlemoyer, L., &amp; Yih, W.T. (2018). "Dissecting Contextual Word Embeddings: Architecture and Representation"**。ELMo作者的后续工作，系统地分析了上下文词向量中不同层编码的信息类型。<span class="co">[</span><span class="ot">arXiv:1808.08949</span><span class="co">](https://arxiv.org/abs/1808.08949)</span></span>
<span id="cb5-774"><a href="#cb5-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-775"><a href="#cb5-775" aria-hidden="true" tabindex="-1"></a>**Liu, N.F., Gardner, M., Belinkov, Y., Peters, M.E., &amp; Smith, N.A. (2019). "Linguistic Knowledge and Transferability of Contextual Representations"**。对ELMo和GPT等上下文表示进行了16种探针任务的系统分析。<span class="co">[</span><span class="ot">arXiv:1903.08855</span><span class="co">](https://arxiv.org/abs/1903.08855)</span></span>
<span id="cb5-776"><a href="#cb5-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-777"><a href="#cb5-777" aria-hidden="true" tabindex="-1"></a><span class="fu">### 综述与教程</span></span>
<span id="cb5-778"><a href="#cb5-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-779"><a href="#cb5-779" aria-hidden="true" tabindex="-1"></a>**Rogers, A., Kovaleva, O., &amp; Rumshisky, A. (2020). "A Primer in BERTology: What We Know About How BERT Works"**。虽然主要讨论BERT，但其分析框架也适用于ELMo，对理解"预训练模型内部到底学到了什么"很有帮助。</span>
<span id="cb5-780"><a href="#cb5-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-781"><a href="#cb5-781" aria-hidden="true" tabindex="-1"></a><span class="fu">### 代码资源</span></span>
<span id="cb5-782"><a href="#cb5-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-783"><a href="#cb5-783" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**AllenNLP ELMo实现**：<span class="co">[</span><span class="ot">github.com/allenai/allennlp</span><span class="co">](https://github.com/allenai/allennlp)</span> — 官方实现，包含预训练模型下载</span>
<span id="cb5-784"><a href="#cb5-784" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**TensorFlow Hub**：<span class="co">[</span><span class="ot">tfhub.dev/google/elmo/3</span><span class="co">](https://tfhub.dev/google/elmo/3)</span> — TensorFlow版本</span>
<span id="cb5-785"><a href="#cb5-785" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hugging Face上的AllenNLP教程**：提供ELMo的快速入门指南</span>
<span id="cb5-786"><a href="#cb5-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-787"><a href="#cb5-787" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb5-788"><a href="#cb5-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-789"><a href="#cb5-789" aria-hidden="true" tabindex="-1"></a><span class="fu">## 历史注脚</span></span>
<span id="cb5-790"><a href="#cb5-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-791"><a href="#cb5-791" aria-hidden="true" tabindex="-1"></a>ELMo这个名字有一个有趣的来源。它是"Embeddings from Language Models"的缩写——一个巧妙而准确的命名。但许多人怀疑这个名字也是对《芝麻街》(Sesame Street)角色Elmo的致敬。后来的BERT（Bidirectional Encoder Representations from Transformers）似乎证实了这个猜测——Bert也是《芝麻街》的角色。再后来出现的ERNIE（Enhanced Representation through Knowledge Integration，百度版和清华版）和Big Bird（Transformers for Longer Sequences）把这个传统发扬光大。NLP社区用儿童教育节目的角色来命名划时代的AI模型，颇有一种"启蒙者"的浪漫。</span>
<span id="cb5-792"><a href="#cb5-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-793"><a href="#cb5-793" aria-hidden="true" tabindex="-1"></a>时间线上的一个引人深思的巧合是：ELMo（2018年2月发表在arXiv）、GPT（2018年6月发布）和BERT（2018年10月发表在arXiv）全部出现在同一年。2018年被后来称为NLP的"ImageNet moment"——预训练范式在这一年彻底改变了NLP研究的面貌。三个团队几乎同时但独立地走向了同一个方向——上下文预训练，这说明预训练范式的到来不是偶然的个人天才，而是技术条件成熟后的必然趋势。</span>
<span id="cb5-794"><a href="#cb5-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-795"><a href="#cb5-795" aria-hidden="true" tabindex="-1"></a>Peters等人在论文中低调地写道："Extensive experiments show that ELMo representations work well in practice and improve the state of the art across six challenging NLP problems." 这种克制的措辞很难让人预见到，仅仅几个月后，GPT和BERT就会将预训练从"有用的增强"推向"必不可少的基础设施"。ELMo是那个关键的第一步——它证明了深层预训练不仅在理论上合理，而且在实践中确实能带来显著的收益。但它选择的LSTM架构和特征提取范式，最终被Transformer和全模型微调所取代。技术的演进有时候就是这样：开拓者铺平了道路，但走得更远的往往是后来者。</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>