<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ying Zha">
<meta name="dcterms.date" content="2026-01-28">
<meta name="description" content="上一章的评测方法论揭示了一个深刻的困境：我们连’什么是好的模型输出’都还没有共识，就已经在训练越来越大的模型了。GPT-3拥有1750亿参数和惊人的few-shot能力，但它本质上只是一个’补全机器’——你必须精心设计prompt才能让它做正确的事。本章讲述指令微调（Instruction Tuning）如何将语言模型从被动的文本补全器变为主动的任务执行者：从FLAN的多任务指令微调，到Self-Instruct的自动数据生成，再到Alpaca/Vicuna的开源平民化浪潮。">

<title>第23章：指令微调——让模型听话 – Tech Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-1b3db88def35042d172274863c1cdcf0.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-6ee47bd5d569ce80d002539aadcc850f.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-ea2c01f27a86cd888be845a75ab84aaf.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<!-- Force refresh if cache is stale -->

<script>

(function() {

  var SITE_VERSION = '2025-11-14-v2'; // Update this to force all users to refresh

  var stored = localStorage.getItem('site_version');

  if (stored !== SITE_VERSION) {

    localStorage.setItem('site_version', SITE_VERSION);

    if (stored !== null) {

      // Not first visit, force reload from server

      window.location.reload(true);

    }

  }

})();

</script>

<script>

// Default to dark scheme on first visit (no prior preference stored)

try {

  var key = 'quarto-color-scheme';

  if (window && window.localStorage && window.localStorage.getItem(key) === null) {

    window.localStorage.setItem(key, 'alternate');

  }

} catch (e) {

  // ignore storage errors (privacy mode, etc.)

}

</script>

<!-- Aggressive cache prevention for HTML pages -->

<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate, max-age=0">

<meta http-equiv="Pragma" content="no-cache">

<meta http-equiv="Expires" content="0">

<meta name="revisit-after" content="1 days">

<meta name="robots" content="noarchive">




  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tech Notes</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../home.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts_en.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tags.html"> 
<span class="menu-text">Tags</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#从上一章说起" id="toc-从上一章说起" class="nav-link active" data-scroll-target="#从上一章说起"><span class="header-section-number">1</span> 从上一章说起</a></li>
  <li><a href="#问题的本质是什么" id="toc-问题的本质是什么" class="nav-link" data-scroll-target="#问题的本质是什么"><span class="header-section-number">2</span> 问题的本质是什么？</a>
  <ul class="collapse">
  <li><a href="#预训练模型的能力-可用性鸿沟" id="toc-预训练模型的能力-可用性鸿沟" class="nav-link" data-scroll-target="#预训练模型的能力-可用性鸿沟"><span class="header-section-number">2.1</span> 预训练模型的”能力-可用性”鸿沟</a></li>
  <li><a href="#之前的解决方案为何不够" id="toc-之前的解决方案为何不够" class="nav-link" data-scroll-target="#之前的解决方案为何不够"><span class="header-section-number">2.2</span> 之前的解决方案为何不够</a></li>
  <li><a href="#我们需要什么样的解决方案" id="toc-我们需要什么样的解决方案" class="nav-link" data-scroll-target="#我们需要什么样的解决方案"><span class="header-section-number">2.3</span> 我们需要什么样的解决方案？</a></li>
  </ul></li>
  <li><a href="#核心思想与直觉" id="toc-核心思想与直觉" class="nav-link" data-scroll-target="#核心思想与直觉"><span class="header-section-number">3</span> 核心思想与直觉</a>
  <ul class="collapse">
  <li><a href="#关键洞察教模型读指令做任务" id="toc-关键洞察教模型读指令做任务" class="nav-link" data-scroll-target="#关键洞察教模型读指令做任务"><span class="header-section-number">3.1</span> 关键洞察：教模型”读指令、做任务”</a></li>
  <li><a href="#设计动机为什么多任务是关键" id="toc-设计动机为什么多任务是关键" class="nav-link" data-scroll-target="#设计动机为什么多任务是关键"><span class="header-section-number">3.2</span> 设计动机：为什么多任务是关键？</a></li>
  </ul></li>
  <li><a href="#技术细节" id="toc-技术细节" class="nav-link" data-scroll-target="#技术细节"><span class="header-section-number">4</span> 技术细节</a>
  <ul class="collapse">
  <li><a href="#flan指令微调的先驱" id="toc-flan指令微调的先驱" class="nav-link" data-scroll-target="#flan指令微调的先驱"><span class="header-section-number">4.1</span> FLAN：指令微调的先驱</a></li>
  <li><a href="#消融实验什么因素最重要" id="toc-消融实验什么因素最重要" class="nav-link" data-scroll-target="#消融实验什么因素最重要"><span class="header-section-number">4.2</span> 消融实验：什么因素最重要？</a></li>
  <li><a href="#从-flan-到-flan-v2规模的力量" id="toc-从-flan-到-flan-v2规模的力量" class="nav-link" data-scroll-target="#从-flan-到-flan-v2规模的力量"><span class="header-section-number">4.3</span> 从 FLAN 到 FLAN v2：规模的力量</a></li>
  <li><a href="#instructgpt-的-sft-阶段人工标注的力量" id="toc-instructgpt-的-sft-阶段人工标注的力量" class="nav-link" data-scroll-target="#instructgpt-的-sft-阶段人工标注的力量"><span class="header-section-number">4.4</span> InstructGPT 的 SFT 阶段：人工标注的力量</a></li>
  <li><a href="#指令数据的构建从人工到自动" id="toc-指令数据的构建从人工到自动" class="nav-link" data-scroll-target="#指令数据的构建从人工到自动"><span class="header-section-number">4.5</span> 指令数据的构建：从人工到自动</a></li>
  <li><a href="#完整数值示例从种子到生成" id="toc-完整数值示例从种子到生成" class="nav-link" data-scroll-target="#完整数值示例从种子到生成"><span class="header-section-number">4.6</span> 完整数值示例：从种子到生成</a></li>
  <li><a href="#alpaca-与-vicuna开源指令微调的平民化浪潮" id="toc-alpaca-与-vicuna开源指令微调的平民化浪潮" class="nav-link" data-scroll-target="#alpaca-与-vicuna开源指令微调的平民化浪潮"><span class="header-section-number">4.7</span> Alpaca 与 Vicuna：开源指令微调的平民化浪潮</a></li>
  <li><a href="#多任务指令微调的设计原则" id="toc-多任务指令微调的设计原则" class="nav-link" data-scroll-target="#多任务指令微调的设计原则"><span class="header-section-number">4.8</span> 多任务指令微调的设计原则</a></li>
  </ul></li>
  <li><a href="#工程实践" id="toc-工程实践" class="nav-link" data-scroll-target="#工程实践"><span class="header-section-number">5</span> 工程实践</a>
  <ul class="collapse">
  <li><a href="#从零构建指令微调数据集" id="toc-从零构建指令微调数据集" class="nav-link" data-scroll-target="#从零构建指令微调数据集"><span class="header-section-number">5.1</span> 从零构建指令微调数据集</a></li>
  <li><a href="#使用-hugging-face-进行指令微调" id="toc-使用-hugging-face-进行指令微调" class="nav-link" data-scroll-target="#使用-hugging-face-进行指令微调"><span class="header-section-number">5.2</span> 使用 Hugging Face 进行指令微调</a></li>
  </ul></li>
  <li><a href="#深入理解" id="toc-深入理解" class="nav-link" data-scroll-target="#深入理解"><span class="header-section-number">6</span> 深入理解</a>
  <ul class="collapse">
  <li><a href="#为什么有效理论视角" id="toc-为什么有效理论视角" class="nav-link" data-scroll-target="#为什么有效理论视角"><span class="header-section-number">6.1</span> 为什么有效？——理论视角</a></li>
  <li><a href="#边界条件与失效模式" id="toc-边界条件与失效模式" class="nav-link" data-scroll-target="#边界条件与失效模式"><span class="header-section-number">6.2</span> 边界条件与失效模式</a></li>
  <li><a href="#开放研究问题" id="toc-开放研究问题" class="nav-link" data-scroll-target="#开放研究问题"><span class="header-section-number">6.3</span> 开放研究问题</a></li>
  </ul></li>
  <li><a href="#局限性与未解决的问题" id="toc-局限性与未解决的问题" class="nav-link" data-scroll-target="#局限性与未解决的问题"><span class="header-section-number">7</span> 局限性与未解决的问题</a>
  <ul class="collapse">
  <li><a href="#指令微调的根本局限" id="toc-指令微调的根本局限" class="nav-link" data-scroll-target="#指令微调的根本局限"><span class="header-section-number">7.1</span> 指令微调的根本局限</a></li>
  <li><a href="#这些局限导向了什么" id="toc-这些局限导向了什么" class="nav-link" data-scroll-target="#这些局限导向了什么"><span class="header-section-number">7.2</span> 这些局限导向了什么？</a></li>
  </ul></li>
  <li><a href="#本章小结" id="toc-本章小结" class="nav-link" data-scroll-target="#本章小结"><span class="header-section-number">8</span> 本章小结</a>
  <ul class="collapse">
  <li><a href="#核心要点回顾" id="toc-核心要点回顾" class="nav-link" data-scroll-target="#核心要点回顾"><span class="header-section-number">8.1</span> 核心要点回顾</a></li>
  <li><a href="#关键公式速查" id="toc-关键公式速查" class="nav-link" data-scroll-target="#关键公式速查"><span class="header-section-number">8.2</span> 关键公式速查</a></li>
  <li><a href="#思考题" id="toc-思考题" class="nav-link" data-scroll-target="#思考题"><span class="header-section-number">8.3</span> 思考题</a></li>
  </ul></li>
  <li><a href="#延伸阅读" id="toc-延伸阅读" class="nav-link" data-scroll-target="#延伸阅读"><span class="header-section-number">9</span> 延伸阅读</a>
  <ul class="collapse">
  <li><a href="#核心论文必读" id="toc-核心论文必读" class="nav-link" data-scroll-target="#核心论文必读"><span class="header-section-number">9.1</span> 核心论文（必读）</a></li>
  <li><a href="#方法改进" id="toc-方法改进" class="nav-link" data-scroll-target="#方法改进"><span class="header-section-number">9.2</span> 方法改进</a></li>
  <li><a href="#开源实践" id="toc-开源实践" class="nav-link" data-scroll-target="#开源实践"><span class="header-section-number">9.3</span> 开源实践</a></li>
  <li><a href="#批判性视角" id="toc-批判性视角" class="nav-link" data-scroll-target="#批判性视角"><span class="header-section-number">9.4</span> 批判性视角</a></li>
  <li><a href="#综述" id="toc-综述" class="nav-link" data-scroll-target="#综述"><span class="header-section-number">9.5</span> 综述</a></li>
  <li><a href="#代码资源" id="toc-代码资源" class="nav-link" data-scroll-target="#代码资源"><span class="header-section-number">9.6</span> 代码资源</a></li>
  </ul></li>
  <li><a href="#历史注脚" id="toc-历史注脚" class="nav-link" data-scroll-target="#历史注脚"><span class="header-section-number">10</span> 历史注脚</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">第23章：指令微调——让模型听话</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Instruction Tuning: From Raw Language Models to Helpful Assistants</p>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">Deep Learning</div>
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Instruction Tuning</div>
    <div class="quarto-category">Alignment</div>
  </div>
  </div>

<div>
  <div class="description">
    上一章的评测方法论揭示了一个深刻的困境：我们连’什么是好的模型输出’都还没有共识，就已经在训练越来越大的模型了。GPT-3拥有1750亿参数和惊人的few-shot能力，但它本质上只是一个’补全机器’——你必须精心设计prompt才能让它做正确的事。本章讲述指令微调（Instruction Tuning）如何将语言模型从被动的文本补全器变为主动的任务执行者：从FLAN的多任务指令微调，到Self-Instruct的自动数据生成，再到Alpaca/Vicuna的开源平民化浪潮。
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ying Zha </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 28, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p><strong>核心问题</strong>：如何让语言模型从”补全文本”变为”遵循指令”？</p>
<p><strong>历史坐标</strong>：2021–2023 | FLAN → InstructGPT SFT → Self-Instruct → Alpaca/Vicuna | 从手工标注到自动生成指令数据</p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>本章参考来源
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<section id="论文" class="level3" data-number="0.1">
<h3 data-number="0.1" class="anchored" data-anchor-id="论文"><span class="header-section-number">0.1</span> 论文</h3>
<ul>
<li><strong>Wei et al.&nbsp;(2022)</strong> “Finetuned Language Models Are Zero-Shot Learners” (<a href="https://arxiv.org/abs/2109.01652">arXiv:2109.01652</a>) — 参考了 Section 2（方法）、Section 4（消融实验）、Figure 1（instruction tuning 总览）、Figure 2（三范式对比）；从论文提取了2张原图（Figure 1, Figure 2）</li>
<li><strong>Chung et al.&nbsp;(2022)</strong> “Scaling Instruction-Finetuned Language Models” (<a href="https://arxiv.org/abs/2210.11416">arXiv:2210.11416</a>) — 参考了 Section 2-3（scaling 实验）；FLAN-T5/FLAN-PaLM 结果</li>
<li><strong>Longpre et al.&nbsp;(2023)</strong> “The Flan Collection: Designing Data and Methods for Effective Instruction Tuning” (<a href="https://arxiv.org/abs/2301.13688">arXiv:2301.13688</a>) — 参考了 Section 3（数据设计决策）、Table 1（任务混合策略）</li>
<li><strong>Ouyang et al.&nbsp;(2022)</strong> “Training language models to follow instructions with human feedback” (<a href="https://arxiv.org/abs/2203.02155">arXiv:2203.02155</a>) — 参考了 Section 3.1-3.2（SFT数据构建）、Figure 2（三阶段流水线）；从论文提取了1张原图（Figure 2）</li>
<li><strong>Wang et al.&nbsp;(2023)</strong> “Self-Instruct: Aligning Language Models with Self-Generated Instructions” (<a href="https://arxiv.org/abs/2212.10560">arXiv:2212.10560</a>) — 参考了 Section 3（pipeline 设计）、Figure 2（Self-Instruct 流程图）、Algorithm 1；从论文提取了1张原图（Figure 2）</li>
<li><strong>Taori et al.&nbsp;(2023)</strong> “Stanford Alpaca: An Instruction-Following LLaMA Model” (<a href="https://github.com/tatsu-lab/stanford_alpaca">GitHub</a>) — 参考了数据生成方法、训练配置</li>
<li><strong>Chiang et al.&nbsp;(2023)</strong> “Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality” (<a href="https://lmsys.org/blog/2023-03-30-vicuna/">LMSYS Blog</a>) — 参考了 ShareGPT 数据源、多轮对话训练</li>
<li><strong>Sanh et al.&nbsp;(2022)</strong> “Multitask Prompted Training Enables Zero-Shot Task Generalization” (<a href="https://arxiv.org/abs/2110.08207">arXiv:2110.08207</a>) — 参考了 T0 的 prompt template 设计</li>
</ul>
</section>
<section id="教材" class="level3" data-number="0.2">
<h3 data-number="0.2" class="anchored" data-anchor-id="教材"><span class="header-section-number">0.2</span> 教材</h3>
<ul>
<li>SLP3 Chapter 11-12 — 参考了 LLM 与指令微调的教学组织</li>
</ul>
</section>
<section id="课程" class="level3" data-number="0.3">
<h3 data-number="0.3" class="anchored" data-anchor-id="课程"><span class="header-section-number">0.3</span> 课程</h3>
<ul>
<li>Stanford CS224N Lecture 10 (Winter 2025): “Instruction Finetuning, and RLHF” — 参考了 Diyi Yang / Jesse Mu 的讲解角度和 slides 组织</li>
</ul>
</section>
</div>
</div>
</div>
<section id="从上一章说起" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="从上一章说起"><span class="header-section-number">1</span> 从上一章说起</h2>
<p>上一章我们系统讨论了评测方法论的演进：从 BLEU/ROUGE 等自动指标到 GLUE/SuperGLUE 等静态 benchmark，再到 LLM-as-Judge 和 Chatbot Arena 等新范式。这些评测手段试图回答一个根本性的问题——“模型变好了吗？”然而，评测方法论的核心洞察反而揭示了一个更深层的困境：<strong>度量本身会影响我们对能力的判断</strong>。Goodhart 定律告诉我们，一旦某个度量成为优化目标，它就不再是一个好的度量。</p>
<p>但这里有一个更直接的问题。假设你手上有一个 GPT-3 级别的大模型——1750 亿参数，在海量文本上训练过，具备令人印象深刻的 few-shot 能力。你想让它帮你”把这段英文翻译成中文”。你会怎么做？</p>
<p>如果你直接输入”把这段英文翻译成中文：Hello world”，GPT-3 可能会继续”补全”这段文本，输出类似”把这段英文翻译成法文：Bonjour le monde”——它把你的指令当成了某个文档的一部分，然后接着”续写”了。要让它真正翻译，你需要精心设计 prompt，比如”English: Hello world:“，还得祈祷它理解你的格式意图。</p>
<p>这不是 GPT-3 的 bug，而是它训练目标的必然结果。语言模型的预训练目标是<strong>预测下一个 token</strong>——它学到的是文本的统计分布，而不是”遵循人类指令”。一个在互联网文本上训练的模型，看到一段文字后最可能做的事情就是继续这段文字的风格和内容。想让它变成一个有用的助手，你必须让它学会一种新的行为模式：<strong>读取指令，执行任务，返回结果</strong>。</p>
<p>这就是本章的核心主题：指令微调（Instruction Tuning）。</p>
<blockquote class="blockquote">
<p>💡 <strong>本章核心洞察</strong>：通过在大量”指令→输出”格式的数据上微调预训练语言模型，可以让它从被动的文本补全器变成主动的任务执行者——而且这种能力可以泛化到训练时从未见过的任务类型。</p>
</blockquote>
</section>
<section id="问题的本质是什么" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="问题的本质是什么"><span class="header-section-number">2</span> 问题的本质是什么？</h2>
<section id="预训练模型的能力-可用性鸿沟" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="预训练模型的能力-可用性鸿沟"><span class="header-section-number">2.1</span> 预训练模型的”能力-可用性”鸿沟</h3>
<p>让我们先精确定义问题。GPT-3 等大型预训练模型存在一个悖论：它们的<strong>潜在能力</strong>远超<strong>可用能力</strong>。在 few-shot 设置下，GPT-3 能做翻译、摘要、问答、推理等各种任务——但前提是你得知道正确的 prompt 格式。这被称为<strong>能力-可用性鸿沟</strong>（capability-usability gap）。</p>
<p>这个鸿沟有多大？Ouyang et al.&nbsp;(2022) 在 InstructGPT 论文中给出了一个直观的例子：当用户输入”Explain the moon landing to a 6 year old”时，GPT-3 的典型输出不是一段面向儿童的解释，而是继续列举更多类似的 prompt（“Explain the theory of gravity to a 6 year old”），因为在它的训练数据中，这种格式更可能出现在一个”prompt 列表”的语境下。</p>
<p>这个问题的根源在于<strong>训练目标与使用方式的错配</strong>。预训练的目标是最大化下一个 token 的预测概率：</p>
<p><span class="math display">\[
\mathcal{L}_{\text{pretrain}} = -\sum_{t=1}^{T} \log P(x_t \mid x_1, \ldots, x_{t-1}; \theta)
\]</span></p>
<p>这个目标让模型学会了语言的统计规律，但没有教它”当用户给出指令时，应该执行指令而不是续写文本”。</p>
</section>
<section id="之前的解决方案为何不够" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="之前的解决方案为何不够"><span class="header-section-number">2.2</span> 之前的解决方案为何不够</h3>
<p>在指令微调出现之前，人们主要用两种方式来弥合这个鸿沟。</p>
<p><strong>方式一：任务特定的微调（Pretrain-Finetune）</strong>。对于每个下游任务，收集该任务的标注数据，然后在预训练模型上进行有监督微调。BERT 时代的做法就是这样：情感分析有情感分析的微调模型，NER 有 NER 的微调模型。这种方式的问题显而易见——你需要为<strong>每个任务</strong>分别训练一个模型，无法处理训练时没见过的任务。</p>
<p><strong>方式二：Prompt Engineering</strong>。GPT-3 的 few-shot 能力开辟了一条新路：不修改模型参数，而是通过设计精巧的 prompt 来引导模型行为。但 prompt engineering 高度依赖人的经验和创造力，不同的 prompt 格式可能导致截然不同的结果，而且对于复杂任务，few-shot 的 prompt 会占用大量的上下文窗口。</p>
</section>
<section id="我们需要什么样的解决方案" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="我们需要什么样的解决方案"><span class="header-section-number">2.3</span> 我们需要什么样的解决方案？</h3>
<p>理想的方案应该同时具备以下特性：<strong>单一模型</strong>处理多种任务，无需任务特定的微调；在<strong>未见过的任务</strong>上也能工作（zero-shot 泛化）；用户可以用<strong>自然语言指令</strong>描述任务，而不是依赖精心设计的 prompt 格式。</p>
<div id="fig-three-paradigms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-three-paradigms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-23/original/fig2-flan-three-paradigms.png" class="img-fluid figure-img" style="width:95.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-three-paradigms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Pretrain-Finetune、Prompting 与 Instruction Tuning 三种范式的对比。(A) 传统微调需要为每个任务训练专门模型；(B) Prompting 通过设计输入格式来引导行为；(C) Instruction Tuning 通过在多任务指令数据上微调，获得对未见任务的 zero-shot 泛化能力。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Wei et al.&nbsp;(2022) “Finetuned Language Models Are Zero-Shot Learners”, Figure 2</em></p>
</div>
<p><a href="#fig-three-paradigms" class="quarto-xref">Figure&nbsp;1</a> 清楚地展示了三种范式的差异。Instruction Tuning 的关键洞察是：如果我们在<strong>足够多样的任务</strong>上微调模型，并且每个任务都以自然语言指令的形式描述，那么模型可以学会一种通用的”遵循指令”能力，从而泛化到全新的任务。</p>
</section>
</section>
<section id="核心思想与直觉" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="核心思想与直觉"><span class="header-section-number">3</span> 核心思想与直觉</h2>
<section id="关键洞察教模型读指令做任务" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="关键洞察教模型读指令做任务"><span class="header-section-number">3.1</span> 关键洞察：教模型”读指令、做任务”</h3>
<p>指令微调的核心思想可以用一个简单的类比来理解。想象你在培训一个新入职的员工。如果你只让他做 A 任务，他就只会 A 任务（这是传统微调）。如果你给他看一本操作手册然后期望他自己悟（这是 prompting），效果取决于手册写得好不好以及他的悟性。但如果你让他在<strong>多种不同的任务</strong>上都实际操练过——今天翻译文档，明天写摘要，后天做数据分析——并且每次都告诉他”你的任务是做 X”，那么当他遇到一个没做过的新任务时，他已经学会了一种<strong>通用的工作模式</strong>：读取任务描述 → 理解要求 → 执行并输出结果。</p>
<p>这就是指令微调的核心直觉。</p>
<p>形式化地说，指令微调将每个训练样本构造为”指令 + 输入 → 输出”的三元组格式：</p>
<p><span class="math display">\[
(\text{instruction}, \text{input}, \text{output})
\]</span></p>
<p>例如：</p>
<blockquote class="blockquote">
<p><strong>Instruction</strong>: Translate the following sentence to French. <strong>Input</strong>: The weather is beautiful today. <strong>Output</strong>: Le temps est magnifique aujourd’hui.</p>
</blockquote>
<p>然后在这些三元组上进行标准的有监督微调（Supervised Fine-Tuning, SFT），优化目标与预训练相同——预测下一个 token——只是训练数据的格式变了：</p>
<p><span class="math display">\[
\mathcal{L}_{\text{SFT}} = -\sum_{t=1}^{|\text{output}|} \log P(y_t \mid \text{instruction}, \text{input}, y_1, \ldots, y_{t-1}; \theta)
\]</span></p>
<p>注意一个微妙但重要的细节：<strong>损失函数只计算在 output 部分的 token 上</strong>，instruction 和 input 部分不参与损失计算。这是因为我们希望模型学会的是”给定指令，生成正确输出”，而不是”生成指令本身”。</p>
</section>
<section id="设计动机为什么多任务是关键" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="设计动机为什么多任务是关键"><span class="header-section-number">3.2</span> 设计动机：为什么多任务是关键？</h3>
<p>一个自然的问题是：如果只在翻译指令上微调，模型能学会做摘要吗？答案是不能——单任务的指令微调只是传统微调的换皮版本。指令微调的威力来自于<strong>多任务的多样性</strong>。当模型在翻译、摘要、问答、推理、分类等<strong>数十种任务类型</strong>上都见过”指令→输出”的模式后，它抽象出的不再是某个具体任务的解法，而是一种<strong>元能力</strong>——理解自然语言指令并执行相应操作。</p>
<p>这里的理论直觉类似于元学习（meta-learning）：模型不是在学习某个具体任务，而是在学习”如何根据任务描述来完成任务”。</p>
</section>
</section>
<section id="技术细节" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="技术细节"><span class="header-section-number">4</span> 技术细节</h2>
<section id="flan指令微调的先驱" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="flan指令微调的先驱"><span class="header-section-number">4.1</span> FLAN：指令微调的先驱</h3>
<p>2021 年 9 月，Google Research 的 Jason Wei 等人发表了 FLAN（Finetuned Language Net）——第一个系统性验证指令微调有效性的工作。</p>
<div id="fig-flan-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-flan-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-23/original/fig1-flan-instruction-tuning-overview.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-flan-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: FLAN 的整体流程：在多种任务上以自然语言指令的形式微调预训练模型，然后在完全未见过的任务上进行 zero-shot 评估。底部的柱状图展示了 FLAN 在 NLI、阅读理解和封闭域 QA 三类未见任务上均大幅超越 GPT-3 的 zero-shot 和 few-shot 表现。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Wei et al.&nbsp;(2022) “Finetuned Language Models Are Zero-Shot Learners”, Figure 1</em></p>
</div>
<p><strong>任务组织与模板设计</strong>。FLAN 的实验设计体现了极高的方法论严谨性。作者收集了 62 个 NLP 数据集，将它们按任务类型分成 12 个<strong>任务簇</strong>（task clusters）：自然语言推理、阅读理解、封闭域问答、翻译、常识推理、指代消解、结构化到文本等。对于每个数据集，作者手工编写了<strong>10个不同的指令模板</strong>（instruction templates），用自然语言描述该任务。</p>
<p>例如，对于自然语言推理任务（判断两个句子的关系），10 个模板中的几个可能是：</p>
<ul>
<li>“Does the premise entail the hypothesis? Answer yes, no, or maybe.”</li>
<li>“Read the following two sentences and determine if they agree, disagree, or are neutral.”</li>
<li>“Based on the premise, is the hypothesis true, false, or inconclusive?”</li>
</ul>
<p>同一个语义任务用不同的自然语言表达来描述，这迫使模型真正理解<strong>指令的含义</strong>，而不是记住特定的模板格式。</p>
<p><strong>评估策略的精妙之处</strong>。FLAN 的评估采用了一种<strong>留出任务簇</strong>（hold-out task clusters）的策略。在评估模型对某一类任务的 zero-shot 泛化时，整个任务簇的所有数据集都不参与训练。例如，要评估模型在 NLI 上的泛化能力，训练时会排除所有 NLI 相关的数据集（MNLI, SNLI, QNLI, RTE 等）。这比简单的数据集级别的留出更加严格——它确保模型真正面对的是一种<strong>全新的任务类型</strong>，而不仅仅是同类型任务的不同数据集。</p>
<p><strong>关键结果</strong>。基于 137B 参数的 LaMDA-PT，FLAN 在 20/25 个评估任务上超越了 175B 的 GPT-3 的 zero-shot 表现，甚至在 ANLI、RTE、BoolQ 等任务上超越了 GPT-3 的 few-shot 表现。这是一个令人震惊的结果：通过指令微调，模型的 zero-shot 能力可以超越更大模型的 few-shot 能力。</p>
</section>
<section id="消融实验什么因素最重要" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="消融实验什么因素最重要"><span class="header-section-number">4.2</span> 消融实验：什么因素最重要？</h3>
<p>FLAN 的消融实验揭示了三个关键发现。</p>
<p><strong>第一，任务数量至关重要</strong>。随着训练时使用的任务簇从 1 个增加到 7 个，held-out 任务上的性能持续提升。这表明多样性是指令微调成功的关键——模型确实在从多任务中学习一种通用的指令遵循能力。</p>
<p><strong>第二，模型规模存在阈值效应</strong>。在较小的模型（如 422M、2B 参数）上，指令微调反而<strong>损害</strong>了 zero-shot 性能。只有当模型规模达到 68B 以上时，指令微调才开始带来一致的提升。这暗示指令微调不是在”注入”新能力，而是在”激活”预训练中已经学到的潜在能力——如果底层能力不够强，微调反而会破坏原有的泛化。</p>
<p><strong>第三，自然语言指令格式是关键</strong>。当把指令模板替换为简单的数据集名称（如”MNLI”而非”Does the premise entail the hypothesis?“），性能大幅下降。这证实了自然语言形式的指令是让模型理解任务意图的关键，而不仅仅是多任务混合训练本身。</p>
</section>
<section id="从-flan-到-flan-v2规模的力量" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="从-flan-到-flan-v2规模的力量"><span class="header-section-number">4.3</span> 从 FLAN 到 FLAN v2：规模的力量</h3>
<p>FLAN 的成功引发了一系列后续工作。2022 年，Chung et al.&nbsp;将指令微调扩展到更大的规模，推出了 FLAN-T5 和 FLAN-PaLM：</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>维度</th>
<th>FLAN (v1)</th>
<th>FLAN v2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>任务数量</strong></td>
<td>62 个数据集 / 12 个簇</td>
<td>1,836 个任务</td>
</tr>
<tr class="even">
<td><strong>模型</strong></td>
<td>LaMDA-PT 137B</td>
<td>T5 (80M–11B), PaLM (8B–540B)</td>
</tr>
<tr class="odd">
<td><strong>模板策略</strong></td>
<td>10 个手写模板/任务</td>
<td>混合 zero-shot + few-shot + CoT</td>
</tr>
<tr class="even">
<td><strong>关键创新</strong></td>
<td>证明指令微调有效</td>
<td>混合 prompt 格式、任务平衡</td>
</tr>
</tbody>
</table>
<p>FLAN v2 的一个关键发现是<strong>混合 prompt 格式训练</strong>的价值。在训练时同时使用 zero-shot 模板、few-shot 示例和 Chain-of-Thought 模板，比只用其中一种格式的效果更好——在所有评估设置下都有 2% 以上的提升。这意味着指令微调的训练数据不仅要多样化任务类型，还要多样化<strong>交互格式</strong>。</p>
<p>同一时期，BigScience 开源社区推出了 T0（Sanh et al., 2022），采用了类似的多任务 prompted training 理念，在 T5 架构上用 PromptSource 收集的高质量模板进行训练。T0 11B 在多个未见任务上达到了 GPT-3 175B 的水平，进一步验证了指令微调的普适性。</p>
</section>
<section id="instructgpt-的-sft-阶段人工标注的力量" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="instructgpt-的-sft-阶段人工标注的力量"><span class="header-section-number">4.4</span> InstructGPT 的 SFT 阶段：人工标注的力量</h3>
<p>与 FLAN 的”将已有数据集改写为指令格式”不同，OpenAI 的 InstructGPT（Ouyang et al., 2022）走了一条更直接的路：<strong>直接让人类标注员从头编写指令和期望的输出</strong>。</p>
<div id="fig-instructgpt-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-instructgpt-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-23/original/fig3-instructgpt-three-steps.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-instructgpt-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: InstructGPT 的三阶段训练流程：Step 1 使用人类标注的指令-输出对进行有监督微调（SFT）；Step 2 收集人类对多个输出的排序来训练奖励模型；Step 3 使用 PPO 进一步优化。本章聚焦 Step 1（SFT），Step 2-3 将在下一章详述。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Ouyang et al.&nbsp;(2022) “Training language models to follow instructions with human feedback”, Figure 2</em></p>
</div>
<p>本章聚焦的是 <a href="#fig-instructgpt-pipeline" class="quarto-xref">Figure&nbsp;3</a> 中的 <strong>Step 1</strong>——有监督微调（SFT）。InstructGPT 的 SFT 数据来自两个渠道：一是标注员自己编写的 prompt（约 13,000 条），覆盖生成、问答、对话、摘要、改写、分类等多种任务类型；二是通过 OpenAI API 提交的真实用户 prompt（经过去重和脱敏处理）。</p>
<p>与 FLAN 的关键区别在于数据的<strong>来源和性质</strong>。FLAN 使用的是将已有 NLP benchmark 改写成指令格式的数据——这些任务虽然多样，但本质上仍是学术任务。而 InstructGPT 的数据反映了<strong>真实用户想让模型做的事情</strong>：写邮件、编故事、解释概念、头脑风暴、写代码——这些任务更加开放和多样化，也更贴近实际使用场景。</p>
<p>InstructGPT 的一个令人震惊的结果是：仅用 13K 条标注数据进行 SFT 的 1.3B 参数模型，在人类评估中就被认为优于 175B 的原始 GPT-3。这说明<strong>数据的质量和格式</strong>比数据的数量或模型的规模更为关键。</p>
</section>
<section id="指令数据的构建从人工到自动" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="指令数据的构建从人工到自动"><span class="header-section-number">4.5</span> 指令数据的构建：从人工到自动</h3>
<p>FLAN 和 InstructGPT 都依赖人类来创建或改写指令数据，这面临一个根本性的瓶颈：人工标注既昂贵又难以规模化。一个自然的问题是：<strong>能否让模型自己生成指令数据？</strong></p>
<p>2022 年 12 月，Wang et al.&nbsp;提出了 Self-Instruct——一个开创性的框架，通过让预训练语言模型自举（bootstrap）来生成指令微调数据。</p>
<div id="fig-self-instruct" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-self-instruct-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figures/chapter-23/original/fig4-self-instruct-pipeline.png" class="img-fluid figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-self-instruct-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Self-Instruct 的流程：从 175 个人工编写的种子任务出发，通过四个步骤迭代生成新的指令数据——指令生成（Step 1）→ 分类判断（Step 2）→ 实例生成（Step 3）→ 质量过滤（Step 4），然后将合格的数据加入任务池继续迭代。
</figcaption>
</figure>
</div>
<div class="figure-caption">
<p><em>Source: Wang et al.&nbsp;(2023) “Self-Instruct: Aligning Language Models with Self-Generated Instructions”, Figure 2</em></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Algorithm: Self-Instruct Pipeline (Wang et al., 2023)
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>输入: 种子任务集 S = {(instruction, input, output)_1, ..., (instruction, input, output)_175}
输出: 大规模指令数据集 D

初始化: 任务池 TaskPool ← S

重复以下步骤直到 |TaskPool| 足够大:
  Step 1 — 指令生成:
    从 TaskPool 中采样 8 个任务作为 in-context 示例
    使用 LM 生成新的 instruction

  Step 2 — 分类判断:
    使用 LM 判断该 instruction 是否为分类任务
    (这决定 Step 3 使用哪种生成策略)

  Step 3 — 实例生成:
    IF 分类任务:
      使用 output-first 策略（先生成类别标签，再生成对应输入）
    ELSE:
      使用 input-first 策略（先生成输入，再生成输出）

  Step 4 — 质量过滤:
    过滤掉: 与已有任务太相似的（ROUGE-L &gt; 0.7）
             格式不合规的（缺少字段、输出为空等）
             包含敏感内容的
    将通过过滤的样本加入 TaskPool

返回 TaskPool 作为最终数据集 D</code></pre>
<p><em>改编自: Wang et al.&nbsp;(2023) “Self-Instruct: Aligning Language Models with Self-Generated Instructions”, Section 3</em></p>
</div>
</div>
<p>Self-Instruct 的巧妙之处在于<strong>分类任务的特殊处理</strong>。对于分类任务（如情感分析），如果先生成输入再让模型分类，模型往往会偏向某个类别。因此 Self-Instruct 采用了 <strong>output-first</strong> 策略：先指定一个类别标签，然后让模型生成对应该标签的输入文本。这种”先有答案再编题”的思路有效地改善了类别平衡。</p>
</section>
<section id="完整数值示例从种子到生成" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="完整数值示例从种子到生成"><span class="header-section-number">4.6</span> 完整数值示例：从种子到生成</h3>
<p>让我们用一个具体的数值例子来走一遍 Self-Instruct 的流程。</p>
<p><strong>设定</strong>：假设任务池中已有以下 3 个种子任务（实际是 175 个，这里简化）：</p>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 41%">
<col style="width: 22%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>#</th>
<th>Instruction</th>
<th>Input</th>
<th>Output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Translate the sentence to Spanish.</td>
<td>“The cat is sleeping.”</td>
<td>“El gato está durmiendo.”</td>
</tr>
<tr class="even">
<td>2</td>
<td>Is this review positive or negative?</td>
<td>“The food was terrible.”</td>
<td>Negative</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Write a haiku about autumn.</td>
<td>(empty)</td>
<td>Crimson leaves descend / Whispers of the cooling breeze / Summer bids farewell</td>
</tr>
</tbody>
</table>
<p><strong>Step 1 — 指令生成</strong>：将这 3 个种子任务作为 in-context 示例，prompt 语言模型生成新指令。</p>
<pre><code>Given the following tasks:
Task 1: Translate the sentence to Spanish.
Task 2: Is this review positive or negative?
Task 3: Write a haiku about autumn.

Generate a new, different task instruction:
Task 4: Summarize the following paragraph in one sentence.</code></pre>
<p>模型生成了一个新指令：“Summarize the following paragraph in one sentence.”</p>
<p><strong>Step 2 — 分类判断</strong>：模型判断这个指令是否是分类任务。答案是 <strong>No</strong>（摘要是生成任务，不是分类任务）。</p>
<p><strong>Step 3 — 实例生成（input-first）</strong>：因为不是分类任务，使用 input-first 策略。</p>
<pre><code>Instruction: Summarize the following paragraph in one sentence.
Input: "Climate change is causing significant shifts in global weather
patterns. Rising temperatures lead to more frequent heat waves, stronger
hurricanes, and unpredictable rainfall. These changes affect agriculture,
water supply, and human health across all continents."
Output: "Climate change is disrupting global weather patterns, leading to
extreme events that impact agriculture, water supply, and health worldwide."</code></pre>
<p><strong>Step 4 — 质量过滤</strong>：计算新指令与已有指令的 ROUGE-L 相似度。“Summarize the following paragraph in one sentence” 与已有 3 条指令的 ROUGE-L 分数均低于 0.7 → <strong>通过过滤</strong>，加入任务池。</p>
<p>通过反复迭代，Self-Instruct 从 175 个种子任务生成了约 <strong>52K 条</strong>高质量指令数据。将这些数据用于微调 GPT-3（vanilla，非 InstructGPT），在 Super-NaturalInstructions 上获得了 <strong>33%</strong> 的绝对提升，接近 InstructGPT-001 的水平——而后者使用的是昂贵的人类标注数据。</p>
</section>
<section id="alpaca-与-vicuna开源指令微调的平民化浪潮" class="level3" data-number="4.7">
<h3 data-number="4.7" class="anchored" data-anchor-id="alpaca-与-vicuna开源指令微调的平民化浪潮"><span class="header-section-number">4.7</span> Alpaca 与 Vicuna：开源指令微调的平民化浪潮</h3>
<p>Self-Instruct 的成功在 2023 年初引发了一场”开源指令微调”的爆发。两个里程碑式的项目——Stanford Alpaca 和 LMSYS Vicuna——彻底改变了指令微调的生态。</p>
<p><strong>Stanford Alpaca (2023 年 3 月)</strong>。Taori et al.&nbsp;将 Self-Instruct 与 Meta 刚开源的 LLaMA 7B 结合，用 text-davinci-003 生成了 52K 条指令数据，然后在 LLaMA 上微调。整个过程的成本不到 <strong>600 美元</strong>（数据生成 500 美元 + 训练 100 美元），而产出的模型在定性评估中与 text-davinci-003 表现相当。Alpaca 证明了：<strong>高质量的指令数据 + 好的基座模型 = 用极低成本复制商业模型的行为</strong>。</p>
<p><strong>Vicuna (2023 年 3 月)</strong>。来自 UC Berkeley、CMU、Stanford 和 UCSD 的团队走了另一条路：不用模型生成数据，而是利用 <strong>ShareGPT</strong> 上用户分享的真实 ChatGPT 对话。他们收集了约 70K 条多轮对话，在 LLaMA 13B 上微调，训练成本仅约 300 美元。Vicuna 的一个关键创新是<strong>多轮对话的损失设计</strong>：只在助手的回复部分计算损失，忽略用户的输入部分。GPT-4 评估显示 Vicuna 达到了 ChatGPT 约 90% 的质量。</p>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>模型</th>
<th>基座模型</th>
<th>数据来源</th>
<th>数据量</th>
<th>成本</th>
<th>关键创新</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Alpaca</strong></td>
<td>LLaMA 7B</td>
<td>Self-Instruct (text-davinci-003 生成)</td>
<td>52K 条指令</td>
<td>~$600</td>
<td>低成本复现商业模型行为</td>
</tr>
<tr class="even">
<td><strong>Vicuna</strong></td>
<td>LLaMA 13B</td>
<td>ShareGPT 用户真实对话</td>
<td>70K 条对话</td>
<td>~$300</td>
<td>多轮对话 + 真实分布数据</td>
</tr>
</tbody>
</table>
<p>这场开源浪潮揭示了一个深刻的事实：<strong>指令微调的核心瓶颈不在模型架构或训练算法，而在指令数据的质量和多样性</strong>。一个好的基座模型加上高质量的指令数据，就能以极低成本产出表现优异的助手模型。</p>
</section>
<section id="多任务指令微调的设计原则" class="level3" data-number="4.8">
<h3 data-number="4.8" class="anchored" data-anchor-id="多任务指令微调的设计原则"><span class="header-section-number">4.8</span> 多任务指令微调的设计原则</h3>
<p>从 FLAN 到 Alpaca，指令微调的实践积累了一系列设计原则。Longpre et al.&nbsp;(2023) 在 “The Flan Collection” 论文中系统地研究了这些设计决策：</p>
<p><strong>任务平衡是关键但常被忽视</strong>。不同任务的数据量可能差距巨大（翻译数据可能有百万条，而逻辑推理只有几千条）。如果不做平衡，模型会被大数据集主导，在小数据集任务上表现不佳。Flan Collection 使用了<strong>按任务均匀采样</strong>（每个任务采样相同数量的样本）或<strong>按任务簇加权</strong>的策略。</p>
<p><strong>输入倒置（Input Inversion）提升鲁棒性</strong>。对于有明确输入-输出对的任务，将输入输出互换可以创造新的训练样本。例如，一个翻译任务 “Translate English to French: Hello → Bonjour” 可以倒置为 “Translate French to English: Bonjour → Hello”。这种数据增强技术在不增加标注成本的情况下有效提升了泛化能力。</p>
<p><strong>混合 prompt 格式带来全面提升</strong>。训练时混合使用 zero-shot 模板（只有指令）、few-shot 模板（指令 + 几个示例）和 Chain-of-Thought 模板（指令 + 推理步骤），在所有评估设置下都带来了提升。这说明模型从多种交互格式中学到了更通用的能力。</p>
</section>
</section>
<section id="工程实践" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="工程实践"><span class="header-section-number">5</span> 工程实践</h2>
<section id="从零构建指令微调数据集" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="从零构建指令微调数据集"><span class="header-section-number">5.1</span> 从零构建指令微调数据集</h3>
<p>下面的代码展示了如何使用 Self-Instruct 的核心思路，用一个已有的语言模型来自动生成指令数据：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 种子任务（实际应准备 175 个）</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>seed_tasks <span class="op">=</span> [</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Translate the following sentence to French."</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">"The weather is beautiful today."</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Le temps est magnifique aujourd'hui."</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Is this movie review positive or negative?"</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">"This movie was a complete waste of time."</span>,</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Negative"</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Write a short poem about the ocean."</span>,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">""</span>,</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Waves crash upon the shore,</span><span class="ch">\n</span><span class="st">Whispering tales of ancient lore..."</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_instruction(seed_tasks, n_examples<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Step 1: 使用种子任务生成新指令"""</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    examples <span class="op">=</span> random.sample(seed_tasks, <span class="bu">min</span>(n_examples, <span class="bu">len</span>(seed_tasks)))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="st">"Below are some example tasks:</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, task <span class="kw">in</span> <span class="bu">enumerate</span>(examples, <span class="dv">1</span>):</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">+=</span> <span class="ss">f"Task </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>task[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">+=</span> <span class="ss">f"</span><span class="ch">\n</span><span class="ss">Generate a new, creative task instruction that is different from the above:</span><span class="ch">\n</span><span class="ss">Task </span><span class="sc">{</span><span class="bu">len</span>(examples)<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content.strip()</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_instance(instruction, is_classification<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Step 3: 为指令生成 input-output 对"""</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_classification:</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output-first: 先生成标签，再生成对应输入</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"""Task: </span><span class="sc">{</span>instruction<span class="sc">}</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="ss">First, list possible output labels. Then generate an input example for one of the labels.</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="ss">Format:</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="ss">Input: [your input]</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a><span class="ss">Output: [the label]"""</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Input-first: 先生成输入，再生成输出</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"""Task: </span><span class="sc">{</span>instruction<span class="sc">}</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="ss">Generate an example input and the corresponding output.</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="ss">Format:</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a><span class="ss">Input: [your input]</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="ss">Output: [your output]"""</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> parse_input_output(response.choices[<span class="dv">0</span>].message.content)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_input_output(text):</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""解析模型输出为 input/output 对"""</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    input_text, output_text <span class="op">=</span> <span class="st">""</span>, <span class="st">""</span></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> text.strip().split(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>):</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> line.startswith(<span class="st">"Input:"</span>):</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>            input_text <span class="op">=</span> line[<span class="bu">len</span>(<span class="st">"Input:"</span>):].strip()</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> line.startswith(<span class="st">"Output:"</span>):</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>            output_text <span class="op">=</span> line[<span class="bu">len</span>(<span class="st">"Output:"</span>):].strip()</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> input_text, output_text</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="co"># 主循环：生成指令数据</span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>generated_data <span class="op">=</span> []</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>task_pool <span class="op">=</span> seed_tasks.copy()</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):  <span class="co"># 实际应迭代数千次</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: 生成新指令</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>    new_instruction <span class="op">=</span> generate_instruction(task_pool)</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: 判断是否为分类任务（简化版）</span></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>    is_clf <span class="op">=</span> <span class="bu">any</span>(kw <span class="kw">in</span> new_instruction.lower()</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> kw <span class="kw">in</span> [<span class="st">"classify"</span>, <span class="st">"positive or negative"</span>,</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>                           <span class="st">"true or false"</span>, <span class="st">"yes or no"</span>, <span class="st">"categorize"</span>])</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: 生成实例</span></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>    input_text, output_text <span class="op">=</span> generate_instance(</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>        new_instruction, is_classification<span class="op">=</span>is_clf</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: 质量过滤（简化版 — 实际应计算 ROUGE-L）</span></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_text <span class="kw">and</span> <span class="bu">len</span>(output_text) <span class="op">&gt;</span> <span class="dv">5</span>:</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>        new_task <span class="op">=</span> {</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>            <span class="st">"instruction"</span>: new_instruction,</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>            <span class="st">"input"</span>: input_text,</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>            <span class="st">"output"</span>: output_text</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>        generated_data.append(new_task)</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>        task_pool.append(new_task)</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"[</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>new_instruction[:<span class="dv">60</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Generated </span><span class="sc">{</span><span class="bu">len</span>(generated_data)<span class="sc">}</span><span class="ss"> instruction-output pairs"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="使用-hugging-face-进行指令微调" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="使用-hugging-face-进行指令微调"><span class="header-section-number">5.2</span> 使用 Hugging Face 进行指令微调</h3>
<p>有了指令数据后，微调过程本身相当标准。以下代码展示了在 Hugging Face 生态中微调一个小型模型的完整流程：</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    AutoModelForCausalLM, AutoTokenizer,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    TrainingArguments, Trainer</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 加载模型和分词器</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"meta-llama/Llama-3.2-1B"</span>  <span class="co"># 使用小模型演示</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 确保有 pad token</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> tokenizer.pad_token <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 格式化指令数据</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_instruction(sample):</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""将指令三元组格式化为模型输入"""</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sample[<span class="st">"input"</span>]:</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> (</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Input:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'input'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> (</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Tokenize（关键：只在 Response 部分计算损失）</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_with_labels(sample):</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    formatted <span class="op">=</span> format_instruction(sample)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    tokenized <span class="op">=</span> tokenizer(</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        formatted, truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span>, padding<span class="op">=</span><span class="st">"max_length"</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 找到 "### Response:\n" 的位置</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    response_marker <span class="op">=</span> <span class="st">"### Response:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    response_start <span class="op">=</span> formatted.find(response_marker) <span class="op">+</span> <span class="bu">len</span>(response_marker)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    response_token_start <span class="op">=</span> <span class="bu">len</span>(tokenizer.encode(</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        formatted[:response_start], add_special_tokens<span class="op">=</span><span class="va">False</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 将 instruction/input 部分的 label 设为 -100（不参与损失）</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> tokenized[<span class="st">"input_ids"</span>].copy()</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    labels[:response_token_start] <span class="op">=</span> [<span class="op">-</span><span class="dv">100</span>] <span class="op">*</span> response_token_start</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    tokenized[<span class="st">"labels"</span>] <span class="op">=</span> labels</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenized</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. 准备数据集</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_list(generated_data)  <span class="co"># 使用前面生成的数据</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_with_labels)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. 训练配置</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"./instruction-tuned-model"</span>,</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span><span class="fl">0.03</span>,</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>    bf16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. 训练</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset,</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>注意代码中 <code>tokenize_with_labels</code> 函数的关键设计：将 instruction 和 input 部分的 label 设为 <code>-100</code>，使得损失函数只在 response 部分计算。这是指令微调区别于普通语言模型训练的核心工程细节。</p>
</section>
</section>
<section id="深入理解" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="深入理解"><span class="header-section-number">6</span> 深入理解</h2>
<blockquote class="blockquote">
<p><strong>研究者必读</strong>：这一节探讨指令微调的理论基础、边界条件和开放问题</p>
</blockquote>
<section id="为什么有效理论视角" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="为什么有效理论视角"><span class="header-section-number">6.1</span> 为什么有效？——理论视角</h3>
<p>指令微调的有效性可以从多个角度理解。</p>
<p><strong>任务向量假说</strong>。一种流行的解释是，预训练模型在其参数空间中已经编码了执行各种任务的能力，但这些能力分散在不同的”区域”。指令微调的作用相当于在参数空间中找到一个<strong>公共方向</strong>——一个”任务向量”——使得模型在面对自然语言指令时，能正确地激活相应的任务执行能力。这与 Ilharco et al.&nbsp;(2023) 的”task arithmetic”研究相呼应：通过对模型权重进行简单的算术运算，就可以组合或移除特定的任务能力。</p>
<p><strong>分布对齐视角</strong>。从更实际的角度看，预训练模型在互联网文本上学到的条件分布 <span class="math inline">\(P(y|x)\)</span> 并不匹配”指令→输出”的分布。互联网上的文本更多是文章、对话、代码等——很少有”任务指令 + 标准答案”的格式。指令微调本质上是在做<strong>分布对齐</strong>（distribution alignment）：将模型的输出分布从”最可能出现在互联网上的下一段文字”调整为”最可能满足用户指令的回答”。</p>
<p><strong>元学习视角</strong>。最有启发性的理论框架可能是将指令微调理解为一种隐式的元学习（implicit meta-learning）。在传统元学习中，模型显式地学习”如何学习新任务”。指令微调则通过多任务训练，让模型隐式地学会了一种元能力——“根据自然语言描述执行任务”。这解释了为什么多任务多样性如此重要：只有见过足够多种类的”指令→执行”模式，模型才能抽象出通用的指令遵循能力。</p>
</section>
<section id="边界条件与失效模式" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="边界条件与失效模式"><span class="header-section-number">6.2</span> 边界条件与失效模式</h3>
<p>指令微调有几个值得注意的失效场景。</p>
<p><strong>规模阈值</strong>。正如 FLAN 的消融实验所示，指令微调在小模型上可能适得其反。研究表明，这个阈值大约在 <strong>10B–60B 参数</strong>之间，取决于具体任务。对于参数量低于阈值的模型，指令微调可能导致模型”忘记”预训练中学到的通用能力，转而过拟合到训练集中的特定格式。</p>
<p><strong>任务多样性 vs.&nbsp;任务深度的权衡</strong>。虽然更多的任务通常带来更好的泛化，但对于特别复杂的任务（如多步推理、数学证明），少量高质量的该任务数据可能比大量简单任务更有效。这暗示了一个设计原则：指令微调的数据应该在<strong>广度</strong>（任务多样性）和<strong>深度</strong>（复杂任务的充分覆盖）之间找到平衡。</p>
<p><strong>数据污染的隐患</strong>。当使用强大的语言模型（如 GPT-4）来生成指令数据时，生成的数据不可避免地带有该模型的偏见和风格。用这些数据微调出的模型可能在某些评估中表现很好（因为评估也使用类似风格的数据），但在真实场景中的多样性和创造性可能受限。Gudibande et al.&nbsp;(2023) 的研究指出，模型蒸馏生成的指令数据主要帮助模型<strong>模仿风格</strong>，而非提升基础能力。</p>
<p><strong>指令遵循 ≠ 回答正确</strong>。指令微调让模型学会了”听指令并给出格式正确的回答”，但这不等于回答的内容是正确的。一个经过指令微调的模型可能以非常流畅和自信的语气给出完全错误的答案。这被称为<strong>表面对齐</strong>（surface alignment）问题——模型学会了”看起来在做正确的事”，而不是”真正在做正确的事”。</p>
</section>
<section id="开放研究问题" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="开放研究问题"><span class="header-section-number">6.3</span> 开放研究问题</h3>
<p><strong>最优数据混合比例</strong>。当同时使用多种来源的指令数据（NLP benchmark、人工标注、模型生成、真实用户对话）时，最优的混合比例是什么？目前没有理论指导，主要依赖经验性的消融实验。FLAN Collection 的研究是这个方向的初步尝试，但远未给出定论。</p>
<p><strong>指令微调与预训练数据的交互</strong>。指令微调的效果高度依赖基座模型的预训练质量，但两者之间的确切关系还不清楚。同样的指令数据在不同的基座模型上可能产生截然不同的效果。理解这种交互关系对于高效地设计训练流程至关重要。</p>
<p><strong>自动化质量评估</strong>。Self-Instruct 使用 ROUGE-L 来过滤低质量数据，但这是一个非常粗糙的代理。如何自动评估指令数据的质量——包括指令的清晰度、输出的正确性、任务的多样性——是一个重要的开放问题。</p>
</section>
</section>
<section id="局限性与未解决的问题" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="局限性与未解决的问题"><span class="header-section-number">7</span> 局限性与未解决的问题</h2>
<section id="指令微调的根本局限" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="指令微调的根本局限"><span class="header-section-number">7.1</span> 指令微调的根本局限</h3>
<p>尽管指令微调取得了巨大成功，它有几个根本性的局限。</p>
<p>第一个局限是<strong>格式对齐 ≠ 价值对齐</strong>。指令微调让模型学会了”理解指令并生成格式正确的输出”，但它并没有教模型区分”好的回答”和”不好的回答”。一个指令微调后的模型可能同样热心地回答”如何帮助邻居”和”如何伤害邻居”——它学会了遵循指令的格式，但没有学会判断指令的善恶。这不是指令微调能解决的问题，因为 SFT 的训练信号只有”正确答案长什么样”，没有”什么是好的、什么是坏的”这种偏好信号。</p>
<p>第二个局限是<strong>确定性的训练目标</strong>。SFT 为每条指令提供一个”标准答案”，模型被训练为精确复现这个答案。但对于开放性问题（如”写一首关于春天的诗”），好的回答有无数种，将模型锁定在一种风格上反而限制了多样性。更深层地说，人类对”什么是好答案”的判断本身就是主观的，不同的标注员可能给出不同的”标准答案”。</p>
<p>第三个局限是<strong>缺乏拒绝能力</strong>。指令微调教会了模型”有问必答”，但没有教它”何时应该拒绝回答”。模型不知道什么时候自己的知识不够用（应该说”我不确定”），什么时候问题本身有问题（应该指出问题的错误假设），什么时候回答可能造成伤害（应该拒绝）。</p>
</section>
<section id="这些局限导向了什么" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="这些局限导向了什么"><span class="header-section-number">7.2</span> 这些局限导向了什么？</h3>
<p>这些局限指向了一个核心需求：我们不仅需要告诉模型”正确答案长什么样”（SFT），还需要告诉模型<strong>什么样的回答更好</strong>（偏好学习）。仅靠”指令→标准答案”的二元训练信号是不够的；我们需要一种能编码<strong>人类偏好排序</strong>（“回答 A 比回答 B 更好”）的训练方法。</p>
<p>这正是下一章——RLHF（Reinforcement Learning from Human Feedback）——要解决的问题。InstructGPT 的三阶段流水线中，SFT 只是第一步；真正让 ChatGPT 变得”有用、诚实、无害”的，是后续的奖励模型训练和 PPO 优化。</p>
</section>
</section>
<section id="本章小结" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="本章小结"><span class="header-section-number">8</span> 本章小结</h2>
<section id="核心要点回顾" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="核心要点回顾"><span class="header-section-number">8.1</span> 核心要点回顾</h3>
<ol type="1">
<li><strong>问题</strong>：预训练语言模型存在”能力-可用性鸿沟”——它们潜力巨大，但不知道如何遵循人类指令</li>
<li><strong>洞察</strong>：通过在多任务、多格式的”指令→输出”数据上进行有监督微调，模型可以学会一种通用的指令遵循元能力</li>
<li><strong>方法</strong>：FLAN（学术任务改写）→ InstructGPT SFT（人工标注）→ Self-Instruct（自动生成）→ Alpaca/Vicuna（开源平民化）</li>
<li><strong>意义</strong>：指令微调是将语言模型从”文本补全器”变为”AI 助手”的第一步，但仅靠 SFT 无法解决价值对齐问题</li>
</ol>
</section>
<section id="关键公式速查" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="关键公式速查"><span class="header-section-number">8.2</span> 关键公式速查</h3>
<ul>
<li><strong>预训练目标</strong>：<span class="math inline">\(\mathcal{L}_{\text{pretrain}} = -\sum_{t} \log P(x_t \mid x_{&lt;t}; \theta)\)</span></li>
<li><strong>SFT 目标</strong>（只在 output 上计算损失）：<span class="math inline">\(\mathcal{L}_{\text{SFT}} = -\sum_{t=1}^{|y|} \log P(y_t \mid \text{instruction}, \text{input}, y_{&lt;t}; \theta)\)</span></li>
</ul>
</section>
<section id="思考题" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="思考题"><span class="header-section-number">8.3</span> 思考题</h3>
<ol type="1">
<li><p><strong>[概念理解]</strong> FLAN 为什么要按任务簇（而非单个数据集）来做 hold-out 评估？这种设计与普通的 train/test split 有什么区别？如果只按数据集做 hold-out，可能导致什么问题？</p></li>
<li><p><strong>[数学推导]</strong> 假设 SFT 的损失函数在整个序列（包括 instruction 部分）上计算，而非只在 output 部分计算。用一个具体的例子说明这会导致什么问题。（提示：考虑不同长度的 instruction 对梯度的影响。）</p></li>
<li><p><strong><a href="#工程实践">工程实践</a></strong> 使用 Self-Instruct 方法，从 5 个种子任务出发，生成 50 条指令数据。分析生成数据的质量分布——有多少是高质量的？哪些类型的指令更难自动生成？</p></li>
<li><p><strong>[开放思考]</strong> Self-Instruct 用模型自己的输出来训练自己，这是否会导致”回音室效应”——模型的偏见被不断放大？如何设计机制来检测和缓解这种风险？这与 Gudibande et al.&nbsp;(2023) 关于”模仿模型”的批评有什么关联？</p></li>
</ol>
<hr>
</section>
</section>
<section id="延伸阅读" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="延伸阅读"><span class="header-section-number">9</span> 延伸阅读</h2>
<section id="核心论文必读" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="核心论文必读"><span class="header-section-number">9.1</span> 核心论文（必读）</h3>
<ul>
<li><strong>Finetuned Language Models Are Zero-Shot Learners (Wei et al., 2022)</strong>：指令微调的奠基之作
<ul>
<li>重点读：Section 2（方法设计）、Section 4（消融实验）</li>
<li>可跳过：Appendix 中的具体模板细节</li>
</ul></li>
<li><strong>Training language models to follow instructions with human feedback (Ouyang et al., 2022)</strong>：InstructGPT 全文
<ul>
<li>重点读：Section 3.1-3.2（SFT 阶段的数据和方法）</li>
<li>Section 3.3-3.4（RM 和 PPO）留到下一章</li>
</ul></li>
</ul>
</section>
<section id="方法改进" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="方法改进"><span class="header-section-number">9.2</span> 方法改进</h3>
<ul>
<li><strong>Scaling Instruction-Finetuned Language Models (Chung et al., 2022)</strong>：FLAN v2，将任务数扩展到 1800+</li>
<li><strong>The Flan Collection (Longpre et al., 2023)</strong>：指令数据设计的系统性研究</li>
<li><strong>Self-Instruct (Wang et al., 2023)</strong>：自动生成指令数据的开创性框架</li>
</ul>
</section>
<section id="开源实践" class="level3" data-number="9.3">
<h3 data-number="9.3" class="anchored" data-anchor-id="开源实践"><span class="header-section-number">9.3</span> 开源实践</h3>
<ul>
<li><strong>Stanford Alpaca (Taori et al., 2023)</strong>：<a href="https://github.com/tatsu-lab/stanford_alpaca">github.com/tatsu-lab/stanford_alpaca</a></li>
<li><strong>Vicuna (Chiang et al., 2023)</strong>：<a href="https://lmsys.org/blog/2023-03-30-vicuna/">lmsys.org/blog/2023-03-30-vicuna</a></li>
</ul>
</section>
<section id="批判性视角" class="level3" data-number="9.4">
<h3 data-number="9.4" class="anchored" data-anchor-id="批判性视角"><span class="header-section-number">9.4</span> 批判性视角</h3>
<ul>
<li><strong>The False Promise of Imitating Proprietary LLMs (Gudibande et al., 2023)</strong>：对模型蒸馏式指令数据的质疑</li>
</ul>
</section>
<section id="综述" class="level3" data-number="9.5">
<h3 data-number="9.5" class="anchored" data-anchor-id="综述"><span class="header-section-number">9.5</span> 综述</h3>
<ul>
<li><strong>A Survey on Instruction Tuning (Zhang et al., 2023)</strong>：指令微调的全面综述</li>
</ul>
</section>
<section id="代码资源" class="level3" data-number="9.6">
<h3 data-number="9.6" class="anchored" data-anchor-id="代码资源"><span class="header-section-number">9.6</span> 代码资源</h3>
<ul>
<li>Hugging Face TRL 库：<a href="https://github.com/huggingface/trl">github.com/huggingface/trl</a></li>
<li>Self-Instruct 官方实现：<a href="https://github.com/yizhongw/self-instruct">github.com/yizhongw/self-instruct</a></li>
</ul>
<hr>
</section>
</section>
<section id="历史注脚" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="历史注脚"><span class="header-section-number">10</span> 历史注脚</h2>
<p>FLAN 这个名字的全称是 “Finetuned Language Net”，但更广为人知的是它与一种甜点的谐音——焦糖布丁（flan）。Google Research 的团队似乎很享受用食物命名他们的模型：PaLM（虽然不是食物但读起来像 palm fruit）、Bard（不是食物但…）。</p>
<p>Stanford Alpaca 的命名则来自羊驼（alpaca），因为它建立在 Meta 的 LLaMA（大驼、llama）之上——这开启了 LLM 社区中一连串的”骆驼科动物”命名传统：Vicuna（骆马）、Guanaco、Camel 等。这个看似随意的命名传统背后，反映了开源社区对 LLaMA 生态的认同和归属感。</p>
<p>更有趣的是时间线。FLAN 论文提交于 2021 年 9 月，但在此之前的 2020 年底，OpenAI 已经在内部开始了 InstructGPT 的研究（Ouyang et al.&nbsp;报告他们的数据收集始于 2020 年初）。这意味着 Google 和 OpenAI 几乎同时独立地意识到了指令微调的重要性——一个从学术角度（FLAN），一个从产品角度（InstructGPT），殊途同归。最终，InstructGPT 的后续产品 ChatGPT 在 2022 年 11 月的发布引爆了 AI 革命——而它的基础，正是本章讨论的指令微调技术。</p>


<!-- -->

</section>

</main> <!-- /main -->
﻿<script>

// Simple EN / 中文 language toggle for posts; robust via meta[quarto:offset]

(function() {

  const KEY = 'siteLang'; // 'en' | 'zh'

  const defaultLang = 'en';

  const POSTS_EN = 'posts_en.html';

  const POSTS_ZH = 'posts_zh.html';

  const TAGS = 'tags.html';



  function currentLang() { try { return localStorage.getItem(KEY) || defaultLang; } catch(e) { return defaultLang; } }

  function setLang(v) { try { localStorage.setItem(KEY, v); } catch(e) {} }

  function offset() {

    const meta = document.querySelector('meta[name="quarto:offset"]');

    const off = meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

    return off;

  }

  function targetFor(lang) { return lang === 'zh' ? POSTS_ZH : POSTS_EN; }

  function goToLang(lang) {

    const off = offset();

    const path = window.location.pathname;

    setLang(lang);

    if (path.endsWith('/' + TAGS) || path.endsWith(TAGS)) {

      window.location.href = off + TAGS;

    } else {

      window.location.href = off + targetFor(lang);

    }

  }

  function updateNavbarPostsLink() {

    const off = offset();

    const href = off + targetFor(currentLang());

    const links = document.querySelectorAll('header .navbar a.nav-link');

    links.forEach((a) => {

      const h = a.getAttribute('href') || '';

      if (h.endsWith(POSTS_EN) || h.endsWith(POSTS_ZH)) a.setAttribute('href', href);

    });

  }

  function mountToggle() {

    const tools = document.querySelector('.quarto-navbar-tools');

    if (!tools) return;

    const wrapper = document.createElement('div');

    wrapper.style.display = 'inline-flex';

    wrapper.style.alignItems = 'center';

    wrapper.style.gap = '0.35rem';

    wrapper.style.marginLeft = '0.35rem';



    const en = document.createElement('a');

    en.href = '';

    en.textContent = 'EN';

    en.className = 'quarto-navigation-tool px-1';

    en.onclick = function(){ goToLang('en'); return false; };



    const sep = document.createElement('span');

    sep.textContent = '|';

    sep.style.opacity = '0.6';



    const zh = document.createElement('a');

    zh.href = '';

    zh.textContent = '中文';

    zh.className = 'quarto-navigation-tool px-1';

    zh.onclick = function(){ goToLang('zh'); return false; };



    const lang = currentLang();

    (lang === 'en' ? en : zh).style.fontWeight = '700';



    wrapper.appendChild(en);

    wrapper.appendChild(sep);

    wrapper.appendChild(zh);

    tools.appendChild(wrapper);

    updateNavbarPostsLink();

  }

  document.addEventListener('DOMContentLoaded', mountToggle);

})();

</script>

<script>

(function(){

  function offset(){

    var meta = document.querySelector('meta[name="quarto:offset"]');

    return meta && meta.getAttribute('content') ? meta.getAttribute('content') : './';

  }

  document.addEventListener('DOMContentLoaded', function(){

    var brand = document.querySelector('header .navbar a.navbar-brand');

    if (brand) {

      brand.setAttribute('href', offset() + 'home.html');

    }

  });

})();

</script>



<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "第23章：指令微调——让模型听话"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Instruction Tuning: From Raw Language Models to Helpful Assistants"</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Ying Zha"</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2026-01-28"</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [NLP, Deep Learning, LLM, Instruction Tuning, Alignment]</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="an">tags:</span><span class="co"> [FLAN, InstructGPT, Self-Instruct, Alpaca, Vicuna, T0, Instruction Following, SFT, Multi-task, Zero-shot]</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "上一章的评测方法论揭示了一个深刻的困境：我们连'什么是好的模型输出'都还没有共识，就已经在训练越来越大的模型了。GPT-3拥有1750亿参数和惊人的few-shot能力，但它本质上只是一个'补全机器'——你必须精心设计prompt才能让它做正确的事。本章讲述指令微调（Instruction Tuning）如何将语言模型从被动的文本补全器变为主动的任务执行者：从FLAN的多任务指令微调，到Self-Instruct的自动数据生成，再到Alpaca/Vicuna的开源平民化浪潮。"</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "figures/chapter-23/original/fig2-flan-three-paradigms.png"</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="an">toc-depth:</span><span class="co"> 3</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-cap-location: bottom</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **核心问题**：如何让语言模型从"补全文本"变为"遵循指令"？</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="at">&gt;</span></span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **历史坐标**：2021–2023 </span><span class="pp">|</span><span class="at"> FLAN → InstructGPT SFT → Self-Instruct → Alpaca/Vicuna </span><span class="pp">|</span><span class="at"> 从手工标注到自动生成指令数据</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## 本章参考来源</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="fu">### 论文</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Wei et al. (2022)** "Finetuned Language Models Are Zero-Shot Learners" (<span class="co">[</span><span class="ot">arXiv:2109.01652</span><span class="co">](https://arxiv.org/abs/2109.01652)</span>) — 参考了 Section 2（方法）、Section 4（消融实验）、Figure 1（instruction tuning 总览）、Figure 2（三范式对比）；从论文提取了2张原图（Figure 1, Figure 2）</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Chung et al. (2022)** "Scaling Instruction-Finetuned Language Models" (<span class="co">[</span><span class="ot">arXiv:2210.11416</span><span class="co">](https://arxiv.org/abs/2210.11416)</span>) — 参考了 Section 2-3（scaling 实验）；FLAN-T5/FLAN-PaLM 结果</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Longpre et al. (2023)** "The Flan Collection: Designing Data and Methods for Effective Instruction Tuning" (<span class="co">[</span><span class="ot">arXiv:2301.13688</span><span class="co">](https://arxiv.org/abs/2301.13688)</span>) — 参考了 Section 3（数据设计决策）、Table 1（任务混合策略）</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Ouyang et al. (2022)** "Training language models to follow instructions with human feedback" (<span class="co">[</span><span class="ot">arXiv:2203.02155</span><span class="co">](https://arxiv.org/abs/2203.02155)</span>) — 参考了 Section 3.1-3.2（SFT数据构建）、Figure 2（三阶段流水线）；从论文提取了1张原图（Figure 2）</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Wang et al. (2023)** "Self-Instruct: Aligning Language Models with Self-Generated Instructions" (<span class="co">[</span><span class="ot">arXiv:2212.10560</span><span class="co">](https://arxiv.org/abs/2212.10560)</span>) — 参考了 Section 3（pipeline 设计）、Figure 2（Self-Instruct 流程图）、Algorithm 1；从论文提取了1张原图（Figure 2）</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Taori et al. (2023)** "Stanford Alpaca: An Instruction-Following LLaMA Model" (<span class="co">[</span><span class="ot">GitHub</span><span class="co">](https://github.com/tatsu-lab/stanford_alpaca)</span>) — 参考了数据生成方法、训练配置</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Chiang et al. (2023)** "Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality" (<span class="co">[</span><span class="ot">LMSYS Blog</span><span class="co">](https://lmsys.org/blog/2023-03-30-vicuna/)</span>) — 参考了 ShareGPT 数据源、多轮对话训练</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sanh et al. (2022)** "Multitask Prompted Training Enables Zero-Shot Task Generalization" (<span class="co">[</span><span class="ot">arXiv:2110.08207</span><span class="co">](https://arxiv.org/abs/2110.08207)</span>) — 参考了 T0 的 prompt template 设计</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="fu">### 教材</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>SLP3 Chapter 11-12 — 参考了 LLM 与指令微调的教学组织</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="fu">### 课程</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Stanford CS224N Lecture 10 (Winter 2025): "Instruction Finetuning, and RLHF" — 参考了 Diyi Yang / Jesse Mu 的讲解角度和 slides 组织</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="fu">## 从上一章说起</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>上一章我们系统讨论了评测方法论的演进：从 BLEU/ROUGE 等自动指标到 GLUE/SuperGLUE 等静态 benchmark，再到 LLM-as-Judge 和 Chatbot Arena 等新范式。这些评测手段试图回答一个根本性的问题——"模型变好了吗？"然而，评测方法论的核心洞察反而揭示了一个更深层的困境：**度量本身会影响我们对能力的判断**。Goodhart 定律告诉我们，一旦某个度量成为优化目标，它就不再是一个好的度量。</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>但这里有一个更直接的问题。假设你手上有一个 GPT-3 级别的大模型——1750 亿参数，在海量文本上训练过，具备令人印象深刻的 few-shot 能力。你想让它帮你"把这段英文翻译成中文"。你会怎么做？</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>如果你直接输入"把这段英文翻译成中文：Hello world"，GPT-3 可能会继续"补全"这段文本，输出类似"把这段英文翻译成法文：Bonjour le monde"——它把你的指令当成了某个文档的一部分，然后接着"续写"了。要让它真正翻译，你需要精心设计 prompt，比如"English: Hello world\nChinese:"，还得祈祷它理解你的格式意图。</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>这不是 GPT-3 的 bug，而是它训练目标的必然结果。语言模型的预训练目标是**预测下一个 token**——它学到的是文本的统计分布，而不是"遵循人类指令"。一个在互联网文本上训练的模型，看到一段文字后最可能做的事情就是继续这段文字的风格和内容。想让它变成一个有用的助手，你必须让它学会一种新的行为模式：**读取指令，执行任务，返回结果**。</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>这就是本章的核心主题：指令微调（Instruction Tuning）。</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 💡 **本章核心洞察**：通过在大量"指令→输出"格式的数据上微调预训练语言模型，可以让它从被动的文本补全器变成主动的任务执行者——而且这种能力可以泛化到训练时从未见过的任务类型。</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="fu">## 问题的本质是什么？</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="fu">### 预训练模型的"能力-可用性"鸿沟</span></span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>让我们先精确定义问题。GPT-3 等大型预训练模型存在一个悖论：它们的**潜在能力**远超**可用能力**。在 few-shot 设置下，GPT-3 能做翻译、摘要、问答、推理等各种任务——但前提是你得知道正确的 prompt 格式。这被称为**能力-可用性鸿沟**（capability-usability gap）。</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>这个鸿沟有多大？Ouyang et al. (2022) 在 InstructGPT 论文中给出了一个直观的例子：当用户输入"Explain the moon landing to a 6 year old"时，GPT-3 的典型输出不是一段面向儿童的解释，而是继续列举更多类似的 prompt（"Explain the theory of gravity to a 6 year old"），因为在它的训练数据中，这种格式更可能出现在一个"prompt 列表"的语境下。</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>这个问题的根源在于**训练目标与使用方式的错配**。预训练的目标是最大化下一个 token 的预测概率：</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{\text{pretrain}} = -\sum_{t=1}^{T} \log P(x_t \mid x_1, \ldots, x_{t-1}; \theta)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>这个目标让模型学会了语言的统计规律，但没有教它"当用户给出指令时，应该执行指令而不是续写文本"。</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a><span class="fu">### 之前的解决方案为何不够</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>在指令微调出现之前，人们主要用两种方式来弥合这个鸿沟。</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>**方式一：任务特定的微调（Pretrain-Finetune）**。对于每个下游任务，收集该任务的标注数据，然后在预训练模型上进行有监督微调。BERT 时代的做法就是这样：情感分析有情感分析的微调模型，NER 有 NER 的微调模型。这种方式的问题显而易见——你需要为**每个任务**分别训练一个模型，无法处理训练时没见过的任务。</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>**方式二：Prompt Engineering**。GPT-3 的 few-shot 能力开辟了一条新路：不修改模型参数，而是通过设计精巧的 prompt 来引导模型行为。但 prompt engineering 高度依赖人的经验和创造力，不同的 prompt 格式可能导致截然不同的结果，而且对于复杂任务，few-shot 的 prompt 会占用大量的上下文窗口。</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a><span class="fu">### 我们需要什么样的解决方案？</span></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>理想的方案应该同时具备以下特性：**单一模型**处理多种任务，无需任务特定的微调；在**未见过的任务**上也能工作（zero-shot 泛化）；用户可以用**自然语言指令**描述任务，而不是依赖精心设计的 prompt 格式。</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a><span class="al">![Pretrain-Finetune、Prompting 与 Instruction Tuning 三种范式的对比。(A) 传统微调需要为每个任务训练专门模型；(B) Prompting 通过设计输入格式来引导行为；(C) Instruction Tuning 通过在多任务指令数据上微调，获得对未见任务的 zero-shot 泛化能力。](figures/chapter-23/original/fig2-flan-three-paradigms.png)</span>{#fig-three-paradigms width=95%}</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>*Source: Wei et al. (2022) "Finetuned Language Models Are Zero-Shot Learners", Figure 2*</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>@fig-three-paradigms 清楚地展示了三种范式的差异。Instruction Tuning 的关键洞察是：如果我们在**足够多样的任务**上微调模型，并且每个任务都以自然语言指令的形式描述，那么模型可以学会一种通用的"遵循指令"能力，从而泛化到全新的任务。</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a><span class="fu">## 核心思想与直觉</span></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a><span class="fu">### 关键洞察：教模型"读指令、做任务"</span></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>指令微调的核心思想可以用一个简单的类比来理解。想象你在培训一个新入职的员工。如果你只让他做 A 任务，他就只会 A 任务（这是传统微调）。如果你给他看一本操作手册然后期望他自己悟（这是 prompting），效果取决于手册写得好不好以及他的悟性。但如果你让他在**多种不同的任务**上都实际操练过——今天翻译文档，明天写摘要，后天做数据分析——并且每次都告诉他"你的任务是做 X"，那么当他遇到一个没做过的新任务时，他已经学会了一种**通用的工作模式**：读取任务描述 → 理解要求 → 执行并输出结果。</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>这就是指令微调的核心直觉。</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>形式化地说，指令微调将每个训练样本构造为"指令 + 输入 → 输出"的三元组格式：</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>(\text{instruction}, \text{input}, \text{output})</span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>例如：</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **Instruction**: Translate the following sentence to French.</span></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **Input**: The weather is beautiful today.</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **Output**: Le temps est magnifique aujourd'hui.</span></span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>然后在这些三元组上进行标准的有监督微调（Supervised Fine-Tuning, SFT），优化目标与预训练相同——预测下一个 token——只是训练数据的格式变了：</span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>\mathcal{L}_{\text{SFT}} = -\sum_{t=1}^{|\text{output}|} \log P(y_t \mid \text{instruction}, \text{input}, y_1, \ldots, y_{t-1}; \theta)</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>注意一个微妙但重要的细节：**损失函数只计算在 output 部分的 token 上**，instruction 和 input 部分不参与损失计算。这是因为我们希望模型学会的是"给定指令，生成正确输出"，而不是"生成指令本身"。</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a><span class="fu">### 设计动机：为什么多任务是关键？</span></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a>一个自然的问题是：如果只在翻译指令上微调，模型能学会做摘要吗？答案是不能——单任务的指令微调只是传统微调的换皮版本。指令微调的威力来自于**多任务的多样性**。当模型在翻译、摘要、问答、推理、分类等**数十种任务类型**上都见过"指令→输出"的模式后，它抽象出的不再是某个具体任务的解法，而是一种**元能力**——理解自然语言指令并执行相应操作。</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>这里的理论直觉类似于元学习（meta-learning）：模型不是在学习某个具体任务，而是在学习"如何根据任务描述来完成任务"。</span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a><span class="fu">## 技术细节</span></span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a><span class="fu">### FLAN：指令微调的先驱</span></span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>2021 年 9 月，Google Research 的 Jason Wei 等人发表了 FLAN（Finetuned Language Net）——第一个系统性验证指令微调有效性的工作。</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a><span class="al">![FLAN 的整体流程：在多种任务上以自然语言指令的形式微调预训练模型，然后在完全未见过的任务上进行 zero-shot 评估。底部的柱状图展示了 FLAN 在 NLI、阅读理解和封闭域 QA 三类未见任务上均大幅超越 GPT-3 的 zero-shot 和 few-shot 表现。](figures/chapter-23/original/fig1-flan-instruction-tuning-overview.png)</span>{#fig-flan-overview width=90%}</span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>*Source: Wei et al. (2022) "Finetuned Language Models Are Zero-Shot Learners", Figure 1*</span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>**任务组织与模板设计**。FLAN 的实验设计体现了极高的方法论严谨性。作者收集了 62 个 NLP 数据集，将它们按任务类型分成 12 个**任务簇**（task clusters）：自然语言推理、阅读理解、封闭域问答、翻译、常识推理、指代消解、结构化到文本等。对于每个数据集，作者手工编写了**10个不同的指令模板**（instruction templates），用自然语言描述该任务。</span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>例如，对于自然语言推理任务（判断两个句子的关系），10 个模板中的几个可能是：</span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Does the premise entail the hypothesis? Answer yes, no, or maybe."</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Read the following two sentences and determine if they agree, disagree, or are neutral."</span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Based on the premise, is the hypothesis true, false, or inconclusive?"</span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a>同一个语义任务用不同的自然语言表达来描述，这迫使模型真正理解**指令的含义**，而不是记住特定的模板格式。</span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>**评估策略的精妙之处**。FLAN 的评估采用了一种**留出任务簇**（hold-out task clusters）的策略。在评估模型对某一类任务的 zero-shot 泛化时，整个任务簇的所有数据集都不参与训练。例如，要评估模型在 NLI 上的泛化能力，训练时会排除所有 NLI 相关的数据集（MNLI, SNLI, QNLI, RTE 等）。这比简单的数据集级别的留出更加严格——它确保模型真正面对的是一种**全新的任务类型**，而不仅仅是同类型任务的不同数据集。</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a>**关键结果**。基于 137B 参数的 LaMDA-PT，FLAN 在 20/25 个评估任务上超越了 175B 的 GPT-3 的 zero-shot 表现，甚至在 ANLI、RTE、BoolQ 等任务上超越了 GPT-3 的 few-shot 表现。这是一个令人震惊的结果：通过指令微调，模型的 zero-shot 能力可以超越更大模型的 few-shot 能力。</span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a><span class="fu">### 消融实验：什么因素最重要？</span></span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a>FLAN 的消融实验揭示了三个关键发现。</span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a>**第一，任务数量至关重要**。随着训练时使用的任务簇从 1 个增加到 7 个，held-out 任务上的性能持续提升。这表明多样性是指令微调成功的关键——模型确实在从多任务中学习一种通用的指令遵循能力。</span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>**第二，模型规模存在阈值效应**。在较小的模型（如 422M、2B 参数）上，指令微调反而**损害**了 zero-shot 性能。只有当模型规模达到 68B 以上时，指令微调才开始带来一致的提升。这暗示指令微调不是在"注入"新能力，而是在"激活"预训练中已经学到的潜在能力——如果底层能力不够强，微调反而会破坏原有的泛化。</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a>**第三，自然语言指令格式是关键**。当把指令模板替换为简单的数据集名称（如"MNLI"而非"Does the premise entail the hypothesis?"），性能大幅下降。这证实了自然语言形式的指令是让模型理解任务意图的关键，而不仅仅是多任务混合训练本身。</span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a><span class="fu">### 从 FLAN 到 FLAN v2：规模的力量</span></span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a>FLAN 的成功引发了一系列后续工作。2022 年，Chung et al. 将指令微调扩展到更大的规模，推出了 FLAN-T5 和 FLAN-PaLM：</span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 维度 <span class="pp">|</span> FLAN (v1) <span class="pp">|</span> FLAN v2 <span class="pp">|</span></span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|-----------|---------|</span></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **任务数量** <span class="pp">|</span> 62 个数据集 / 12 个簇 <span class="pp">|</span> 1,836 个任务 <span class="pp">|</span></span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **模型** <span class="pp">|</span> LaMDA-PT 137B <span class="pp">|</span> T5 (80M–11B), PaLM (8B–540B) <span class="pp">|</span></span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **模板策略** <span class="pp">|</span> 10 个手写模板/任务 <span class="pp">|</span> 混合 zero-shot + few-shot + CoT <span class="pp">|</span></span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **关键创新** <span class="pp">|</span> 证明指令微调有效 <span class="pp">|</span> 混合 prompt 格式、任务平衡 <span class="pp">|</span></span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a>FLAN v2 的一个关键发现是**混合 prompt 格式训练**的价值。在训练时同时使用 zero-shot 模板、few-shot 示例和 Chain-of-Thought 模板，比只用其中一种格式的效果更好——在所有评估设置下都有 2% 以上的提升。这意味着指令微调的训练数据不仅要多样化任务类型，还要多样化**交互格式**。</span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>同一时期，BigScience 开源社区推出了 T0（Sanh et al., 2022），采用了类似的多任务 prompted training 理念，在 T5 架构上用 PromptSource 收集的高质量模板进行训练。T0 11B 在多个未见任务上达到了 GPT-3 175B 的水平，进一步验证了指令微调的普适性。</span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### InstructGPT 的 SFT 阶段：人工标注的力量</span></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a>与 FLAN 的"将已有数据集改写为指令格式"不同，OpenAI 的 InstructGPT（Ouyang et al., 2022）走了一条更直接的路：**直接让人类标注员从头编写指令和期望的输出**。</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a><span class="al">![InstructGPT 的三阶段训练流程：Step 1 使用人类标注的指令-输出对进行有监督微调（SFT）；Step 2 收集人类对多个输出的排序来训练奖励模型；Step 3 使用 PPO 进一步优化。本章聚焦 Step 1（SFT），Step 2-3 将在下一章详述。](figures/chapter-23/original/fig3-instructgpt-three-steps.png)</span>{#fig-instructgpt-pipeline width=90%}</span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>*Source: Ouyang et al. (2022) "Training language models to follow instructions with human feedback", Figure 2*</span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a>本章聚焦的是 @fig-instructgpt-pipeline 中的 **Step 1**——有监督微调（SFT）。InstructGPT 的 SFT 数据来自两个渠道：一是标注员自己编写的 prompt（约 13,000 条），覆盖生成、问答、对话、摘要、改写、分类等多种任务类型；二是通过 OpenAI API 提交的真实用户 prompt（经过去重和脱敏处理）。</span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a>与 FLAN 的关键区别在于数据的**来源和性质**。FLAN 使用的是将已有 NLP benchmark 改写成指令格式的数据——这些任务虽然多样，但本质上仍是学术任务。而 InstructGPT 的数据反映了**真实用户想让模型做的事情**：写邮件、编故事、解释概念、头脑风暴、写代码——这些任务更加开放和多样化，也更贴近实际使用场景。</span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>InstructGPT 的一个令人震惊的结果是：仅用 13K 条标注数据进行 SFT 的 1.3B 参数模型，在人类评估中就被认为优于 175B 的原始 GPT-3。这说明**数据的质量和格式**比数据的数量或模型的规模更为关键。</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a><span class="fu">### 指令数据的构建：从人工到自动</span></span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a>FLAN 和 InstructGPT 都依赖人类来创建或改写指令数据，这面临一个根本性的瓶颈：人工标注既昂贵又难以规模化。一个自然的问题是：**能否让模型自己生成指令数据？**</span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a>2022 年 12 月，Wang et al. 提出了 Self-Instruct——一个开创性的框架，通过让预训练语言模型自举（bootstrap）来生成指令微调数据。</span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a><span class="al">![Self-Instruct 的流程：从 175 个人工编写的种子任务出发，通过四个步骤迭代生成新的指令数据——指令生成（Step 1）→ 分类判断（Step 2）→ 实例生成（Step 3）→ 质量过滤（Step 4），然后将合格的数据加入任务池继续迭代。](figures/chapter-23/original/fig4-self-instruct-pipeline.png)</span>{#fig-self-instruct width=85%}</span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a>::: {.figure-caption}</span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a>*Source: Wang et al. (2023) "Self-Instruct: Aligning Language Models with Self-Generated Instructions", Figure 2*</span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a><span class="fu">## Algorithm: Self-Instruct Pipeline (Wang et al., 2023)</span></span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a><span class="in">输入: 种子任务集 S = {(instruction, input, output)_1, ..., (instruction, input, output)_175}</span></span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a><span class="in">输出: 大规模指令数据集 D</span></span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a><span class="in">初始化: 任务池 TaskPool ← S</span></span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a><span class="in">重复以下步骤直到 |TaskPool| 足够大:</span></span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a><span class="in">  Step 1 — 指令生成:</span></span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a><span class="in">    从 TaskPool 中采样 8 个任务作为 in-context 示例</span></span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a><span class="in">    使用 LM 生成新的 instruction</span></span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a><span class="in">  Step 2 — 分类判断:</span></span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a><span class="in">    使用 LM 判断该 instruction 是否为分类任务</span></span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a><span class="in">    (这决定 Step 3 使用哪种生成策略)</span></span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a><span class="in">  Step 3 — 实例生成:</span></span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a><span class="in">    IF 分类任务:</span></span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a><span class="in">      使用 output-first 策略（先生成类别标签，再生成对应输入）</span></span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a><span class="in">    ELSE:</span></span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a><span class="in">      使用 input-first 策略（先生成输入，再生成输出）</span></span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a><span class="in">  Step 4 — 质量过滤:</span></span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a><span class="in">    过滤掉: 与已有任务太相似的（ROUGE-L &gt; 0.7）</span></span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a><span class="in">             格式不合规的（缺少字段、输出为空等）</span></span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a><span class="in">             包含敏感内容的</span></span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a><span class="in">    将通过过滤的样本加入 TaskPool</span></span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a><span class="in">返回 TaskPool 作为最终数据集 D</span></span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>*改编自: Wang et al. (2023) "Self-Instruct: Aligning Language Models with Self-Generated Instructions", Section 3*</span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>Self-Instruct 的巧妙之处在于**分类任务的特殊处理**。对于分类任务（如情感分析），如果先生成输入再让模型分类，模型往往会偏向某个类别。因此 Self-Instruct 采用了 **output-first** 策略：先指定一个类别标签，然后让模型生成对应该标签的输入文本。这种"先有答案再编题"的思路有效地改善了类别平衡。</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a><span class="fu">### 完整数值示例：从种子到生成</span></span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a>让我们用一个具体的数值例子来走一遍 Self-Instruct 的流程。</span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>**设定**：假设任务池中已有以下 3 个种子任务（实际是 175 个，这里简化）：</span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> # <span class="pp">|</span> Instruction <span class="pp">|</span> Input <span class="pp">|</span> Output <span class="pp">|</span></span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a><span class="pp">|---|-------------|-------|--------|</span></span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 1 <span class="pp">|</span> Translate the sentence to Spanish. <span class="pp">|</span> "The cat is sleeping." <span class="pp">|</span> "El gato está durmiendo." <span class="pp">|</span></span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 2 <span class="pp">|</span> Is this review positive or negative? <span class="pp">|</span> "The food was terrible." <span class="pp">|</span> Negative <span class="pp">|</span></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 3 <span class="pp">|</span> Write a haiku about autumn. <span class="pp">|</span> (empty) <span class="pp">|</span> Crimson leaves descend / Whispers of the cooling breeze / Summer bids farewell <span class="pp">|</span></span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a>**Step 1 — 指令生成**：将这 3 个种子任务作为 in-context 示例，prompt 语言模型生成新指令。</span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a><span class="in">Given the following tasks:</span></span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a><span class="in">Task 1: Translate the sentence to Spanish.</span></span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a><span class="in">Task 2: Is this review positive or negative?</span></span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a><span class="in">Task 3: Write a haiku about autumn.</span></span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a><span class="in">Generate a new, different task instruction:</span></span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a><span class="in">Task 4: Summarize the following paragraph in one sentence.</span></span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a>模型生成了一个新指令："Summarize the following paragraph in one sentence."</span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a>**Step 2 — 分类判断**：模型判断这个指令是否是分类任务。答案是 **No**（摘要是生成任务，不是分类任务）。</span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>**Step 3 — 实例生成（input-first）**：因为不是分类任务，使用 input-first 策略。</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a><span class="in">Instruction: Summarize the following paragraph in one sentence.</span></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a><span class="in">Input: "Climate change is causing significant shifts in global weather</span></span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a><span class="in">patterns. Rising temperatures lead to more frequent heat waves, stronger</span></span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a><span class="in">hurricanes, and unpredictable rainfall. These changes affect agriculture,</span></span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a><span class="in">water supply, and human health across all continents."</span></span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a><span class="in">Output: "Climate change is disrupting global weather patterns, leading to</span></span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a><span class="in">extreme events that impact agriculture, water supply, and health worldwide."</span></span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a>**Step 4 — 质量过滤**：计算新指令与已有指令的 ROUGE-L 相似度。"Summarize the following paragraph in one sentence" 与已有 3 条指令的 ROUGE-L 分数均低于 0.7 → **通过过滤**，加入任务池。</span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a>通过反复迭代，Self-Instruct 从 175 个种子任务生成了约 **52K 条**高质量指令数据。将这些数据用于微调 GPT-3（vanilla，非 InstructGPT），在 Super-NaturalInstructions 上获得了 **33%** 的绝对提升，接近 InstructGPT-001 的水平——而后者使用的是昂贵的人类标注数据。</span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a><span class="fu">### Alpaca 与 Vicuna：开源指令微调的平民化浪潮</span></span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a>Self-Instruct 的成功在 2023 年初引发了一场"开源指令微调"的爆发。两个里程碑式的项目——Stanford Alpaca 和 LMSYS Vicuna——彻底改变了指令微调的生态。</span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>**Stanford Alpaca (2023 年 3 月)**。Taori et al. 将 Self-Instruct 与 Meta 刚开源的 LLaMA 7B 结合，用 text-davinci-003 生成了 52K 条指令数据，然后在 LLaMA 上微调。整个过程的成本不到 **600 美元**（数据生成 500 美元 + 训练 100 美元），而产出的模型在定性评估中与 text-davinci-003 表现相当。Alpaca 证明了：**高质量的指令数据 + 好的基座模型 = 用极低成本复制商业模型的行为**。</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a>**Vicuna (2023 年 3 月)**。来自 UC Berkeley、CMU、Stanford 和 UCSD 的团队走了另一条路：不用模型生成数据，而是利用 **ShareGPT** 上用户分享的真实 ChatGPT 对话。他们收集了约 70K 条多轮对话，在 LLaMA 13B 上微调，训练成本仅约 300 美元。Vicuna 的一个关键创新是**多轮对话的损失设计**：只在助手的回复部分计算损失，忽略用户的输入部分。GPT-4 评估显示 Vicuna 达到了 ChatGPT 约 90% 的质量。</span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> 模型 <span class="pp">|</span> 基座模型 <span class="pp">|</span> 数据来源 <span class="pp">|</span> 数据量 <span class="pp">|</span> 成本 <span class="pp">|</span> 关键创新 <span class="pp">|</span></span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a><span class="pp">|------|----------|----------|--------|------|----------|</span></span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Alpaca** <span class="pp">|</span> LLaMA 7B <span class="pp">|</span> Self-Instruct (text-davinci-003 生成) <span class="pp">|</span> 52K 条指令 <span class="pp">|</span> ~$600 <span class="pp">|</span> 低成本复现商业模型行为 <span class="pp">|</span></span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> **Vicuna** <span class="pp">|</span> LLaMA 13B <span class="pp">|</span> ShareGPT 用户真实对话 <span class="pp">|</span> 70K 条对话 <span class="pp">|</span> ~$300 <span class="pp">|</span> 多轮对话 + 真实分布数据 <span class="pp">|</span></span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>这场开源浪潮揭示了一个深刻的事实：**指令微调的核心瓶颈不在模型架构或训练算法，而在指令数据的质量和多样性**。一个好的基座模型加上高质量的指令数据，就能以极低成本产出表现优异的助手模型。</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a><span class="fu">### 多任务指令微调的设计原则</span></span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>从 FLAN 到 Alpaca，指令微调的实践积累了一系列设计原则。Longpre et al. (2023) 在 "The Flan Collection" 论文中系统地研究了这些设计决策：</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>**任务平衡是关键但常被忽视**。不同任务的数据量可能差距巨大（翻译数据可能有百万条，而逻辑推理只有几千条）。如果不做平衡，模型会被大数据集主导，在小数据集任务上表现不佳。Flan Collection 使用了**按任务均匀采样**（每个任务采样相同数量的样本）或**按任务簇加权**的策略。</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>**输入倒置（Input Inversion）提升鲁棒性**。对于有明确输入-输出对的任务，将输入输出互换可以创造新的训练样本。例如，一个翻译任务 "Translate English to French: Hello → Bonjour" 可以倒置为 "Translate French to English: Bonjour → Hello"。这种数据增强技术在不增加标注成本的情况下有效提升了泛化能力。</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>**混合 prompt 格式带来全面提升**。训练时混合使用 zero-shot 模板（只有指令）、few-shot 模板（指令 + 几个示例）和 Chain-of-Thought 模板（指令 + 推理步骤），在所有评估设置下都带来了提升。这说明模型从多种交互格式中学到了更通用的能力。</span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a><span class="fu">## 工程实践</span></span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a><span class="fu">### 从零构建指令微调数据集</span></span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>下面的代码展示了如何使用 Self-Instruct 的核心思路，用一个已有的语言模型来自动生成指令数据：</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a><span class="co"># 种子任务（实际应准备 175 个）</span></span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>seed_tasks <span class="op">=</span> [</span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Translate the following sentence to French."</span>,</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">"The weather is beautiful today."</span>,</span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Le temps est magnifique aujourd'hui."</span></span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Is this movie review positive or negative?"</span>,</span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">"This movie was a complete waste of time."</span>,</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Negative"</span></span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a>        <span class="st">"instruction"</span>: <span class="st">"Write a short poem about the ocean."</span>,</span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input"</span>: <span class="st">""</span>,</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a>        <span class="st">"output"</span>: <span class="st">"Waves crash upon the shore,</span><span class="ch">\n</span><span class="st">Whispering tales of ancient lore..."</span></span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_instruction(seed_tasks, n_examples<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Step 1: 使用种子任务生成新指令"""</span></span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a>    examples <span class="op">=</span> random.sample(seed_tasks, <span class="bu">min</span>(n_examples, <span class="bu">len</span>(seed_tasks)))</span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="st">"Below are some example tasks:</span><span class="ch">\n\n</span><span class="st">"</span></span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, task <span class="kw">in</span> <span class="bu">enumerate</span>(examples, <span class="dv">1</span>):</span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">+=</span> <span class="ss">f"Task </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>task[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">+=</span> <span class="ss">f"</span><span class="ch">\n</span><span class="ss">Generate a new, creative task instruction that is different from the above:</span><span class="ch">\n</span><span class="ss">Task </span><span class="sc">{</span><span class="bu">len</span>(examples)<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.choices[<span class="dv">0</span>].message.content.strip()</span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_instance(instruction, is_classification<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Step 3: 为指令生成 input-output 对"""</span></span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> is_classification:</span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Output-first: 先生成标签，再生成对应输入</span></span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"""Task: </span><span class="sc">{</span>instruction<span class="sc">}</span></span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a><span class="ss">First, list possible output labels. Then generate an input example for one of the labels.</span></span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a><span class="ss">Format:</span></span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a><span class="ss">Input: [your input]</span></span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a><span class="ss">Output: [the label]"""</span></span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Input-first: 先生成输入，再生成输出</span></span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a>        prompt <span class="op">=</span> <span class="ss">f"""Task: </span><span class="sc">{</span>instruction<span class="sc">}</span></span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a><span class="ss">Generate an example input and the corresponding output.</span></span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a><span class="ss">Format:</span></span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a><span class="ss">Input: [your input]</span></span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a><span class="ss">Output: [your output]"""</span></span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt}],</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a>        max_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span><span class="fl">0.7</span></span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> parse_input_output(response.choices[<span class="dv">0</span>].message.content)</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_input_output(text):</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""解析模型输出为 input/output 对"""</span></span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a>    input_text, output_text <span class="op">=</span> <span class="st">""</span>, <span class="st">""</span></span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> text.strip().split(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>):</span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> line.startswith(<span class="st">"Input:"</span>):</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a>            input_text <span class="op">=</span> line[<span class="bu">len</span>(<span class="st">"Input:"</span>):].strip()</span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> line.startswith(<span class="st">"Output:"</span>):</span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a>            output_text <span class="op">=</span> line[<span class="bu">len</span>(<span class="st">"Output:"</span>):].strip()</span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> input_text, output_text</span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a><span class="co"># 主循环：生成指令数据</span></span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a>generated_data <span class="op">=</span> []</span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a>task_pool <span class="op">=</span> seed_tasks.copy()</span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):  <span class="co"># 实际应迭代数千次</span></span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: 生成新指令</span></span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a>    new_instruction <span class="op">=</span> generate_instruction(task_pool)</span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: 判断是否为分类任务（简化版）</span></span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a>    is_clf <span class="op">=</span> <span class="bu">any</span>(kw <span class="kw">in</span> new_instruction.lower()</span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> kw <span class="kw">in</span> [<span class="st">"classify"</span>, <span class="st">"positive or negative"</span>,</span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a>                           <span class="st">"true or false"</span>, <span class="st">"yes or no"</span>, <span class="st">"categorize"</span>])</span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: 生成实例</span></span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a>    input_text, output_text <span class="op">=</span> generate_instance(</span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a>        new_instruction, is_classification<span class="op">=</span>is_clf</span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: 质量过滤（简化版 — 实际应计算 ROUGE-L）</span></span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_text <span class="kw">and</span> <span class="bu">len</span>(output_text) <span class="op">&gt;</span> <span class="dv">5</span>:</span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a>        new_task <span class="op">=</span> {</span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a>            <span class="st">"instruction"</span>: new_instruction,</span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>            <span class="st">"input"</span>: input_text,</span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>            <span class="st">"output"</span>: output_text</span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>        generated_data.append(new_task)</span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>        task_pool.append(new_task)</span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"[</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>new_instruction[:<span class="dv">60</span>]<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Generated </span><span class="sc">{</span><span class="bu">len</span>(generated_data)<span class="sc">}</span><span class="ss"> instruction-output pairs"</span>)</span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a><span class="fu">### 使用 Hugging Face 进行指令微调</span></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a>有了指令数据后，微调过程本身相当标准。以下代码展示了在 Hugging Face 生态中微调一个小型模型的完整流程：</span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a>    AutoModelForCausalLM, AutoTokenizer,</span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a>    TrainingArguments, Trainer</span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 加载模型和分词器</span></span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">"meta-llama/Llama-3.2-1B"</span>  <span class="co"># 使用小模型演示</span></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb6-444"><a href="#cb6-444" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span>
<span id="cb6-445"><a href="#cb6-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a><span class="co"># 确保有 pad token</span></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> tokenizer.pad_token <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a>    tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 格式化指令数据</span></span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_instruction(sample):</span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""将指令三元组格式化为模型输入"""</span></span>
<span id="cb6-453"><a href="#cb6-453" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sample[<span class="st">"input"</span>]:</span>
<span id="cb6-454"><a href="#cb6-454" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> (</span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Input:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'input'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> (</span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Instruction:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'instruction'</span>]<span class="sc">}</span><span class="ch">\n\n</span><span class="ss">"</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"### Response:</span><span class="ch">\n</span><span class="sc">{</span>sample[<span class="st">'output'</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Tokenize（关键：只在 Response 部分计算损失）</span></span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize_with_labels(sample):</span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a>    formatted <span class="op">=</span> format_instruction(sample)</span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a>    tokenized <span class="op">=</span> tokenizer(</span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a>        formatted, truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span><span class="dv">512</span>, padding<span class="op">=</span><span class="st">"max_length"</span></span>
<span id="cb6-472"><a href="#cb6-472" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-473"><a href="#cb6-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 找到 "### Response:\n" 的位置</span></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a>    response_marker <span class="op">=</span> <span class="st">"### Response:</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a>    response_start <span class="op">=</span> formatted.find(response_marker) <span class="op">+</span> <span class="bu">len</span>(response_marker)</span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a>    response_token_start <span class="op">=</span> <span class="bu">len</span>(tokenizer.encode(</span>
<span id="cb6-478"><a href="#cb6-478" aria-hidden="true" tabindex="-1"></a>        formatted[:response_start], add_special_tokens<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-479"><a href="#cb6-479" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 将 instruction/input 部分的 label 设为 -100（不参与损失）</span></span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> tokenized[<span class="st">"input_ids"</span>].copy()</span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a>    labels[:response_token_start] <span class="op">=</span> [<span class="op">-</span><span class="dv">100</span>] <span class="op">*</span> response_token_start</span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a>    tokenized[<span class="st">"labels"</span>] <span class="op">=</span> labels</span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokenized</span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. 准备数据集</span></span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> Dataset.from_list(generated_data)  <span class="co"># 使用前面生成的数据</span></span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a>tokenized_dataset <span class="op">=</span> dataset.<span class="bu">map</span>(tokenize_with_labels)</span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. 训练配置</span></span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span><span class="st">"./instruction-tuned-model"</span>,</span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a>    num_train_epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a>    gradient_accumulation_steps<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a>    warmup_ratio<span class="op">=</span><span class="fl">0.03</span>,</span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a>    lr_scheduler_type<span class="op">=</span><span class="st">"cosine"</span>,</span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>    bf16<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a>    logging_steps<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,</span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. 训练</span></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>    train_dataset<span class="op">=</span>tokenized_dataset,</span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>trainer.train()</span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>注意代码中 <span class="in">`tokenize_with_labels`</span> 函数的关键设计：将 instruction 和 input 部分的 label 设为 <span class="in">`-100`</span>，使得损失函数只在 response 部分计算。这是指令微调区别于普通语言模型训练的核心工程细节。</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a><span class="fu">## 深入理解</span></span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; **研究者必读**：这一节探讨指令微调的理论基础、边界条件和开放问题</span></span>
<span id="cb6-520"><a href="#cb6-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-521"><a href="#cb6-521" aria-hidden="true" tabindex="-1"></a><span class="fu">### 为什么有效？——理论视角</span></span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a>指令微调的有效性可以从多个角度理解。</span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a>**任务向量假说**。一种流行的解释是，预训练模型在其参数空间中已经编码了执行各种任务的能力，但这些能力分散在不同的"区域"。指令微调的作用相当于在参数空间中找到一个**公共方向**——一个"任务向量"——使得模型在面对自然语言指令时，能正确地激活相应的任务执行能力。这与 Ilharco et al. (2023) 的"task arithmetic"研究相呼应：通过对模型权重进行简单的算术运算，就可以组合或移除特定的任务能力。</span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a>**分布对齐视角**。从更实际的角度看，预训练模型在互联网文本上学到的条件分布 $P(y|x)$ 并不匹配"指令→输出"的分布。互联网上的文本更多是文章、对话、代码等——很少有"任务指令 + 标准答案"的格式。指令微调本质上是在做**分布对齐**（distribution alignment）：将模型的输出分布从"最可能出现在互联网上的下一段文字"调整为"最可能满足用户指令的回答"。</span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-529"><a href="#cb6-529" aria-hidden="true" tabindex="-1"></a>**元学习视角**。最有启发性的理论框架可能是将指令微调理解为一种隐式的元学习（implicit meta-learning）。在传统元学习中，模型显式地学习"如何学习新任务"。指令微调则通过多任务训练，让模型隐式地学会了一种元能力——"根据自然语言描述执行任务"。这解释了为什么多任务多样性如此重要：只有见过足够多种类的"指令→执行"模式，模型才能抽象出通用的指令遵循能力。</span>
<span id="cb6-530"><a href="#cb6-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-531"><a href="#cb6-531" aria-hidden="true" tabindex="-1"></a><span class="fu">### 边界条件与失效模式</span></span>
<span id="cb6-532"><a href="#cb6-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-533"><a href="#cb6-533" aria-hidden="true" tabindex="-1"></a>指令微调有几个值得注意的失效场景。</span>
<span id="cb6-534"><a href="#cb6-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-535"><a href="#cb6-535" aria-hidden="true" tabindex="-1"></a>**规模阈值**。正如 FLAN 的消融实验所示，指令微调在小模型上可能适得其反。研究表明，这个阈值大约在 **10B–60B 参数**之间，取决于具体任务。对于参数量低于阈值的模型，指令微调可能导致模型"忘记"预训练中学到的通用能力，转而过拟合到训练集中的特定格式。</span>
<span id="cb6-536"><a href="#cb6-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-537"><a href="#cb6-537" aria-hidden="true" tabindex="-1"></a>**任务多样性 vs. 任务深度的权衡**。虽然更多的任务通常带来更好的泛化，但对于特别复杂的任务（如多步推理、数学证明），少量高质量的该任务数据可能比大量简单任务更有效。这暗示了一个设计原则：指令微调的数据应该在**广度**（任务多样性）和**深度**（复杂任务的充分覆盖）之间找到平衡。</span>
<span id="cb6-538"><a href="#cb6-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-539"><a href="#cb6-539" aria-hidden="true" tabindex="-1"></a>**数据污染的隐患**。当使用强大的语言模型（如 GPT-4）来生成指令数据时，生成的数据不可避免地带有该模型的偏见和风格。用这些数据微调出的模型可能在某些评估中表现很好（因为评估也使用类似风格的数据），但在真实场景中的多样性和创造性可能受限。Gudibande et al. (2023) 的研究指出，模型蒸馏生成的指令数据主要帮助模型**模仿风格**，而非提升基础能力。</span>
<span id="cb6-540"><a href="#cb6-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-541"><a href="#cb6-541" aria-hidden="true" tabindex="-1"></a>**指令遵循 ≠ 回答正确**。指令微调让模型学会了"听指令并给出格式正确的回答"，但这不等于回答的内容是正确的。一个经过指令微调的模型可能以非常流畅和自信的语气给出完全错误的答案。这被称为**表面对齐**（surface alignment）问题——模型学会了"看起来在做正确的事"，而不是"真正在做正确的事"。</span>
<span id="cb6-542"><a href="#cb6-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-543"><a href="#cb6-543" aria-hidden="true" tabindex="-1"></a><span class="fu">### 开放研究问题</span></span>
<span id="cb6-544"><a href="#cb6-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-545"><a href="#cb6-545" aria-hidden="true" tabindex="-1"></a>**最优数据混合比例**。当同时使用多种来源的指令数据（NLP benchmark、人工标注、模型生成、真实用户对话）时，最优的混合比例是什么？目前没有理论指导，主要依赖经验性的消融实验。FLAN Collection 的研究是这个方向的初步尝试，但远未给出定论。</span>
<span id="cb6-546"><a href="#cb6-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-547"><a href="#cb6-547" aria-hidden="true" tabindex="-1"></a>**指令微调与预训练数据的交互**。指令微调的效果高度依赖基座模型的预训练质量，但两者之间的确切关系还不清楚。同样的指令数据在不同的基座模型上可能产生截然不同的效果。理解这种交互关系对于高效地设计训练流程至关重要。</span>
<span id="cb6-548"><a href="#cb6-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-549"><a href="#cb6-549" aria-hidden="true" tabindex="-1"></a>**自动化质量评估**。Self-Instruct 使用 ROUGE-L 来过滤低质量数据，但这是一个非常粗糙的代理。如何自动评估指令数据的质量——包括指令的清晰度、输出的正确性、任务的多样性——是一个重要的开放问题。</span>
<span id="cb6-550"><a href="#cb6-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-551"><a href="#cb6-551" aria-hidden="true" tabindex="-1"></a><span class="fu">## 局限性与未解决的问题</span></span>
<span id="cb6-552"><a href="#cb6-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-553"><a href="#cb6-553" aria-hidden="true" tabindex="-1"></a><span class="fu">### 指令微调的根本局限</span></span>
<span id="cb6-554"><a href="#cb6-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-555"><a href="#cb6-555" aria-hidden="true" tabindex="-1"></a>尽管指令微调取得了巨大成功，它有几个根本性的局限。</span>
<span id="cb6-556"><a href="#cb6-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-557"><a href="#cb6-557" aria-hidden="true" tabindex="-1"></a>第一个局限是**格式对齐 ≠ 价值对齐**。指令微调让模型学会了"理解指令并生成格式正确的输出"，但它并没有教模型区分"好的回答"和"不好的回答"。一个指令微调后的模型可能同样热心地回答"如何帮助邻居"和"如何伤害邻居"——它学会了遵循指令的格式，但没有学会判断指令的善恶。这不是指令微调能解决的问题，因为 SFT 的训练信号只有"正确答案长什么样"，没有"什么是好的、什么是坏的"这种偏好信号。</span>
<span id="cb6-558"><a href="#cb6-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-559"><a href="#cb6-559" aria-hidden="true" tabindex="-1"></a>第二个局限是**确定性的训练目标**。SFT 为每条指令提供一个"标准答案"，模型被训练为精确复现这个答案。但对于开放性问题（如"写一首关于春天的诗"），好的回答有无数种，将模型锁定在一种风格上反而限制了多样性。更深层地说，人类对"什么是好答案"的判断本身就是主观的，不同的标注员可能给出不同的"标准答案"。</span>
<span id="cb6-560"><a href="#cb6-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-561"><a href="#cb6-561" aria-hidden="true" tabindex="-1"></a>第三个局限是**缺乏拒绝能力**。指令微调教会了模型"有问必答"，但没有教它"何时应该拒绝回答"。模型不知道什么时候自己的知识不够用（应该说"我不确定"），什么时候问题本身有问题（应该指出问题的错误假设），什么时候回答可能造成伤害（应该拒绝）。</span>
<span id="cb6-562"><a href="#cb6-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-563"><a href="#cb6-563" aria-hidden="true" tabindex="-1"></a><span class="fu">### 这些局限导向了什么？</span></span>
<span id="cb6-564"><a href="#cb6-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-565"><a href="#cb6-565" aria-hidden="true" tabindex="-1"></a>这些局限指向了一个核心需求：我们不仅需要告诉模型"正确答案长什么样"（SFT），还需要告诉模型**什么样的回答更好**（偏好学习）。仅靠"指令→标准答案"的二元训练信号是不够的；我们需要一种能编码**人类偏好排序**（"回答 A 比回答 B 更好"）的训练方法。</span>
<span id="cb6-566"><a href="#cb6-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-567"><a href="#cb6-567" aria-hidden="true" tabindex="-1"></a>这正是下一章——RLHF（Reinforcement Learning from Human Feedback）——要解决的问题。InstructGPT 的三阶段流水线中，SFT 只是第一步；真正让 ChatGPT 变得"有用、诚实、无害"的，是后续的奖励模型训练和 PPO 优化。</span>
<span id="cb6-568"><a href="#cb6-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-569"><a href="#cb6-569" aria-hidden="true" tabindex="-1"></a><span class="fu">## 本章小结</span></span>
<span id="cb6-570"><a href="#cb6-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-571"><a href="#cb6-571" aria-hidden="true" tabindex="-1"></a><span class="fu">### 核心要点回顾</span></span>
<span id="cb6-572"><a href="#cb6-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-573"><a href="#cb6-573" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**问题**：预训练语言模型存在"能力-可用性鸿沟"——它们潜力巨大，但不知道如何遵循人类指令</span>
<span id="cb6-574"><a href="#cb6-574" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**洞察**：通过在多任务、多格式的"指令→输出"数据上进行有监督微调，模型可以学会一种通用的指令遵循元能力</span>
<span id="cb6-575"><a href="#cb6-575" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**方法**：FLAN（学术任务改写）→ InstructGPT SFT（人工标注）→ Self-Instruct（自动生成）→ Alpaca/Vicuna（开源平民化）</span>
<span id="cb6-576"><a href="#cb6-576" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**意义**：指令微调是将语言模型从"文本补全器"变为"AI 助手"的第一步，但仅靠 SFT 无法解决价值对齐问题</span>
<span id="cb6-577"><a href="#cb6-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-578"><a href="#cb6-578" aria-hidden="true" tabindex="-1"></a><span class="fu">### 关键公式速查</span></span>
<span id="cb6-579"><a href="#cb6-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-580"><a href="#cb6-580" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**预训练目标**：$\mathcal{L}_{\text{pretrain}} = -\sum_{t} \log P(x_t \mid x_{&lt;t}; \theta)$</span>
<span id="cb6-581"><a href="#cb6-581" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**SFT 目标**（只在 output 上计算损失）：$\mathcal{L}_{\text{SFT}} = -\sum_{t=1}^{|y|} \log P(y_t \mid \text{instruction}, \text{input}, y_{&lt;t}; \theta)$</span>
<span id="cb6-582"><a href="#cb6-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-583"><a href="#cb6-583" aria-hidden="true" tabindex="-1"></a><span class="fu">### 思考题</span></span>
<span id="cb6-584"><a href="#cb6-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-585"><a href="#cb6-585" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**[概念理解]** FLAN 为什么要按任务簇（而非单个数据集）来做 hold-out 评估？这种设计与普通的 train/test split 有什么区别？如果只按数据集做 hold-out，可能导致什么问题？</span>
<span id="cb6-586"><a href="#cb6-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-587"><a href="#cb6-587" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**[数学推导]** 假设 SFT 的损失函数在整个序列（包括 instruction 部分）上计算，而非只在 output 部分计算。用一个具体的例子说明这会导致什么问题。（提示：考虑不同长度的 instruction 对梯度的影响。）</span>
<span id="cb6-588"><a href="#cb6-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-589"><a href="#cb6-589" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**[工程实践]** 使用 Self-Instruct 方法，从 5 个种子任务出发，生成 50 条指令数据。分析生成数据的质量分布——有多少是高质量的？哪些类型的指令更难自动生成？</span>
<span id="cb6-590"><a href="#cb6-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-591"><a href="#cb6-591" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**[开放思考]** Self-Instruct 用模型自己的输出来训练自己，这是否会导致"回音室效应"——模型的偏见被不断放大？如何设计机制来检测和缓解这种风险？这与 Gudibande et al. (2023) 关于"模仿模型"的批评有什么关联？</span>
<span id="cb6-592"><a href="#cb6-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-593"><a href="#cb6-593" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-594"><a href="#cb6-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-595"><a href="#cb6-595" aria-hidden="true" tabindex="-1"></a><span class="fu">## 延伸阅读</span></span>
<span id="cb6-596"><a href="#cb6-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-597"><a href="#cb6-597" aria-hidden="true" tabindex="-1"></a><span class="fu">### 核心论文（必读）</span></span>
<span id="cb6-598"><a href="#cb6-598" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Finetuned Language Models Are Zero-Shot Learners (Wei et al., 2022)**：指令微调的奠基之作</span>
<span id="cb6-599"><a href="#cb6-599" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>重点读：Section 2（方法设计）、Section 4（消融实验）</span>
<span id="cb6-600"><a href="#cb6-600" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>可跳过：Appendix 中的具体模板细节</span>
<span id="cb6-601"><a href="#cb6-601" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Training language models to follow instructions with human feedback (Ouyang et al., 2022)**：InstructGPT 全文</span>
<span id="cb6-602"><a href="#cb6-602" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>重点读：Section 3.1-3.2（SFT 阶段的数据和方法）</span>
<span id="cb6-603"><a href="#cb6-603" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Section 3.3-3.4（RM 和 PPO）留到下一章</span>
<span id="cb6-604"><a href="#cb6-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-605"><a href="#cb6-605" aria-hidden="true" tabindex="-1"></a><span class="fu">### 方法改进</span></span>
<span id="cb6-606"><a href="#cb6-606" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Scaling Instruction-Finetuned Language Models (Chung et al., 2022)**：FLAN v2，将任务数扩展到 1800+</span>
<span id="cb6-607"><a href="#cb6-607" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**The Flan Collection (Longpre et al., 2023)**：指令数据设计的系统性研究</span>
<span id="cb6-608"><a href="#cb6-608" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Self-Instruct (Wang et al., 2023)**：自动生成指令数据的开创性框架</span>
<span id="cb6-609"><a href="#cb6-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-610"><a href="#cb6-610" aria-hidden="true" tabindex="-1"></a><span class="fu">### 开源实践</span></span>
<span id="cb6-611"><a href="#cb6-611" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Stanford Alpaca (Taori et al., 2023)**：<span class="co">[</span><span class="ot">github.com/tatsu-lab/stanford_alpaca</span><span class="co">](https://github.com/tatsu-lab/stanford_alpaca)</span></span>
<span id="cb6-612"><a href="#cb6-612" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Vicuna (Chiang et al., 2023)**：<span class="co">[</span><span class="ot">lmsys.org/blog/2023-03-30-vicuna</span><span class="co">](https://lmsys.org/blog/2023-03-30-vicuna/)</span></span>
<span id="cb6-613"><a href="#cb6-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-614"><a href="#cb6-614" aria-hidden="true" tabindex="-1"></a><span class="fu">### 批判性视角</span></span>
<span id="cb6-615"><a href="#cb6-615" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**The False Promise of Imitating Proprietary LLMs (Gudibande et al., 2023)**：对模型蒸馏式指令数据的质疑</span>
<span id="cb6-616"><a href="#cb6-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-617"><a href="#cb6-617" aria-hidden="true" tabindex="-1"></a><span class="fu">### 综述</span></span>
<span id="cb6-618"><a href="#cb6-618" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**A Survey on Instruction Tuning (Zhang et al., 2023)**：指令微调的全面综述</span>
<span id="cb6-619"><a href="#cb6-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-620"><a href="#cb6-620" aria-hidden="true" tabindex="-1"></a><span class="fu">### 代码资源</span></span>
<span id="cb6-621"><a href="#cb6-621" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hugging Face TRL 库：<span class="co">[</span><span class="ot">github.com/huggingface/trl</span><span class="co">](https://github.com/huggingface/trl)</span></span>
<span id="cb6-622"><a href="#cb6-622" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Self-Instruct 官方实现：<span class="co">[</span><span class="ot">github.com/yizhongw/self-instruct</span><span class="co">](https://github.com/yizhongw/self-instruct)</span></span>
<span id="cb6-623"><a href="#cb6-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-624"><a href="#cb6-624" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb6-625"><a href="#cb6-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-626"><a href="#cb6-626" aria-hidden="true" tabindex="-1"></a><span class="fu">## 历史注脚</span></span>
<span id="cb6-627"><a href="#cb6-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-628"><a href="#cb6-628" aria-hidden="true" tabindex="-1"></a>FLAN 这个名字的全称是 "Finetuned Language Net"，但更广为人知的是它与一种甜点的谐音——焦糖布丁（flan）。Google Research 的团队似乎很享受用食物命名他们的模型：PaLM（虽然不是食物但读起来像 palm fruit）、Bard（不是食物但...）。</span>
<span id="cb6-629"><a href="#cb6-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-630"><a href="#cb6-630" aria-hidden="true" tabindex="-1"></a>Stanford Alpaca 的命名则来自羊驼（alpaca），因为它建立在 Meta 的 LLaMA（大驼、llama）之上——这开启了 LLM 社区中一连串的"骆驼科动物"命名传统：Vicuna（骆马）、Guanaco、Camel 等。这个看似随意的命名传统背后，反映了开源社区对 LLaMA 生态的认同和归属感。</span>
<span id="cb6-631"><a href="#cb6-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-632"><a href="#cb6-632" aria-hidden="true" tabindex="-1"></a>更有趣的是时间线。FLAN 论文提交于 2021 年 9 月，但在此之前的 2020 年底，OpenAI 已经在内部开始了 InstructGPT 的研究（Ouyang et al. 报告他们的数据收集始于 2020 年初）。这意味着 Google 和 OpenAI 几乎同时独立地意识到了指令微调的重要性——一个从学术角度（FLAN），一个从产品角度（InstructGPT），殊途同归。最终，InstructGPT 的后续产品 ChatGPT 在 2022 年 11 月的发布引爆了 AI 革命——而它的基础，正是本章讨论的指令微调技术。</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>