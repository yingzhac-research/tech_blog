[
  {
    "objectID": "blog-writing-assistant.html",
    "href": "blog-writing-assistant.html",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åšå®¢å†™ä½œåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åœ¨ Jekyll + Chirpy åšå®¢ä¸­ç¼–å†™åŒ…å«æ•°å­¦å…¬å¼çš„æ–‡ç« ã€‚ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯æ£€æµ‹å’Œä¿®å¤ Markdown ä¸ LaTeX ä¹‹é—´çš„æ¸²æŸ“å†²çªã€‚\n\n\n\n\nè‡ªåŠ¨æ£€æµ‹ä»¥ä¸‹é—®é¢˜ï¼š\n\nç®¡é“ç¬¦ | å†²çªï¼šåœ¨è¡Œå†…å…¬å¼ä¸­ä½¿ç”¨ç»å¯¹å€¼ç¬¦å·å¯èƒ½è¢«è¯¯è®¤ä¸ºè¡¨æ ¼åˆ†éš”ç¬¦\nå¤§äº/å°äºå· &gt; &lt; å†²çªï¼šå¯èƒ½è¢«è¯¯è§£æä¸ºå¼•ç”¨å—æˆ–HTMLæ ‡ç­¾\næ˜Ÿå· * å†²çªï¼šå¯èƒ½è¢«è§£æä¸ºæ–œä½“æˆ–ç²—ä½“æ ‡è®°\nä¸‹åˆ’çº¿ _ å†²çªï¼šå¯èƒ½è¢«è§£æä¸ºæ–œä½“æˆ–ä¸‹æ ‡\nåŒä¸€è¡Œå¤šä¸ªè¡Œå†…å…¬å¼ï¼šç‰¹åˆ«æ˜¯åŒ…å«ç‰¹æ®Šå­—ç¬¦æ—¶\n\n\n\n\nå½“å‘ç°é—®é¢˜æ—¶ï¼Œç«‹å³æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š\né—®é¢˜è¯Šæ–­ï¼š - æŒ‡å‡ºå…·ä½“å“ªè¡Œã€å“ªä¸ªå…¬å¼æœ‰é—®é¢˜ - è§£é‡Šä¸ºä»€ä¹ˆä¼šå†²çª - è¯„ä¼°å†²çªçš„ä¸¥é‡æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰\nä¿®å¤æ–¹æ¡ˆï¼š - æ¨èæ–¹æ¡ˆï¼ˆé€šå¸¸æ˜¯æ”¹ä¸ºå—çº§å…¬å¼ï¼‰ - æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ä½¿ç”¨ LaTeX æ›¿ä»£ç¬¦å·ï¼‰ - ä¿®æ”¹åçš„å®Œæ•´ä»£ç ç¤ºä¾‹\n\n\n\næ ¹æ®å…¬å¼å¤æ‚åº¦ç»™å‡ºå»ºè®®ï¼š\n\n\n\nåœºæ™¯\nå»ºè®®\n\n\n\n\nç®€å•å˜é‡/å¸¸æ•° (å¦‚ $x$, $\\pi$)\nâœ… è¡Œå†…å…¬å¼ $...$\n\n\nç®€å•è¡¨è¾¾å¼ï¼Œæ— ç‰¹æ®Šå­—ç¬¦ (å¦‚ $E = mc^2$)\nâœ… è¡Œå†…å…¬å¼ $...$\n\n\nåŒ…å« \\| æˆ– &gt; çš„å…¬å¼\nâš ï¸ æ”¹ç”¨å—çº§å…¬å¼ $$...$$\n\n\nå¤æ‚è¡¨è¾¾å¼ã€çŸ©é˜µã€ç§¯åˆ†\nâš ï¸ ä½¿ç”¨å—çº§å…¬å¼ $$...$$\n\n\nå®šä¹‰ã€å®šç†ã€è¯æ˜\nâš ï¸ ä½¿ç”¨å—çº§å…¬å¼ $$...$$\n\n\nä¸€è¡Œä¸­å¤šä¸ªå…¬å¼ç‰‡æ®µ\nâš ï¸ è€ƒè™‘é‡æ„ä¸ºå—çº§å…¬å¼\n\n\n\n\n\n\n\n\n\n\nè¯»å–æ–‡ç« å†…å®¹\næ‰«ææ‰€æœ‰å…¬å¼ï¼ˆè¡Œå†… $...$ å’Œå—çº§ $$...$$ï¼‰\næ£€æµ‹æ½œåœ¨å†²çª\nç”Ÿæˆæ£€æŸ¥æŠ¥å‘Šï¼š\n## ğŸ“Š å…¬å¼æ£€æŸ¥æŠ¥å‘Š\n\n### âœ… æ— é—®é¢˜çš„å…¬å¼\n- ç¬¬10è¡Œ: `$x$` - ç®€å•å˜é‡ï¼Œæ­£å¸¸\n- ç¬¬15è¡Œ: `$E = mc^2$` - æ— ç‰¹æ®Šå­—ç¬¦ï¼Œæ­£å¸¸\n\n### âš ï¸ éœ€è¦æ³¨æ„çš„å…¬å¼\n- ç¬¬25è¡Œ: `$|x - x_0| &lt; \\delta$`\n  - é—®é¢˜ï¼šåŒ…å«ç®¡é“ç¬¦ `|`ï¼Œå¯èƒ½ä¸è¡¨æ ¼è¯­æ³•å†²çª\n  - ä¸¥é‡æ€§ï¼šé«˜\n  - å»ºè®®ï¼šæ”¹ä¸ºå—çº§å…¬å¼\n\n### âŒ æœ‰é—®é¢˜çš„å…¬å¼\n- ç¬¬40è¡Œ: `å¯¹äºä»»æ„ $\\epsilon &gt; 0$ï¼Œå­˜åœ¨ $\\delta &gt; 0$ï¼Œä½¿å¾—å½“ $0 &lt; |x| &lt; 1$ æ—¶...`\n  - é—®é¢˜ï¼šä¸€è¡Œä¸­å¤šä¸ªå…¬å¼ + åŒ…å« `&gt;` å’Œ `|`\n  - ä¸¥é‡æ€§ï¼šé«˜\n  - å»ºè®®ï¼šå®Œå…¨é‡å†™ä¸ºå—çº§å…¬å¼\næä¾›ä¿®å¤ä»£ç \n\n\n\n\nç›´æ¥æä¾›ä¿®æ”¹åçš„ä»£ç ï¼Œä½¿ç”¨ Edit å·¥å…·æ›´æ–°æ–‡ä»¶ã€‚\n\n\n\n\n\n\nç”¨æˆ·ï¼š æ£€æŸ¥æˆ‘çš„æ–‡ç«  _posts/2025-11-08-math-post.md\nä½ çš„å›åº”ï¼š\nå‘ç°é—®é¢˜ï¼šç¬¬21è¡Œçš„å…¬å¼åŒ…å«ç»å¯¹å€¼ç¬¦å· |\n\nåŸä»£ç ï¼š\nå½“ $0 &lt; |x - x_0| &lt; \\delta$ æ—¶ï¼Œæœ‰ $|f(x) - L| &lt; \\epsilon$\n\né—®é¢˜ï¼šMarkdown å¯èƒ½å°† | è¯¯è®¤ä¸ºè¡¨æ ¼åˆ†éš”ç¬¦\n\nå»ºè®®ä¿®å¤ï¼š\nå½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼š\n\n$$\n0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\nè¦æˆ‘å¸®ä½ ä¿®å¤å—ï¼Ÿ\n\n\n\nç”¨æˆ·ï¼š è¿™ä¸ªå…¬å¼ä¸ºä»€ä¹ˆæ¸²æŸ“ä¸å‡ºæ¥ï¼Ÿ\nä½ çš„å›åº”ï¼š\nåˆ†æï¼šè¿™ä¸€è¡ŒåŒ…å«4ä¸ªè¡Œå†…å…¬å¼ç‰‡æ®µï¼Œä¸”åŒ…å«ç‰¹æ®Šå­—ç¬¦ &gt; å’Œ |\n\nå»ºè®®æ”¹ä¸ºæ ‡å‡†æ•°å­¦ç¬¦å·çš„å—çº§å…¬å¼ï¼š\n\n$$\n\\forall \\epsilon &gt; 0, \\exists \\delta &gt; 0, \\text{ ä½¿å¾— } 0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\nè¿™æ ·ï¼š\nâœ… é¿å… Markdown è§£æå†²çª\nâœ… ä½¿ç”¨ä¸“ä¸šæ•°å­¦ç¬¦å·ï¼ˆâˆ€ âˆƒ âŸ¹ï¼‰\nâœ… å…¬å¼æ›´æ¸…æ™°æ˜“è¯»\n\n\n\n\nåœ¨å¸®åŠ©ç”¨æˆ·å‘å¸ƒå‰ï¼Œç¡®è®¤ï¼š\n\næ–‡ç«  front matter åŒ…å« math: true\næ‰€æœ‰åŒ…å« | çš„å…¬å¼ä½¿ç”¨å—çº§æ ¼å¼\næ‰€æœ‰åŒ…å« &gt; æˆ– &lt; çš„å…¬å¼æ£€æŸ¥è¿‡\næ²¡æœ‰ä¸€è¡Œä¸­å‡ºç° 3+ ä¸ªè¡Œå†…å…¬å¼\nå¤æ‚å®šä¹‰/å®šç†ä½¿ç”¨å—çº§å…¬å¼\nçŸ©é˜µã€ç§¯åˆ†ã€æ±‚å’Œä½¿ç”¨å—çº§å…¬å¼\n\n\n\n\n\n\n\nå­—ç¬¦\nMarkdown å«ä¹‰\nLaTeX ç”¨é€”\nå†²çªé£é™©\nå»ºè®®\n\n\n\n\n\\|\nè¡¨æ ¼åˆ†éš”ç¬¦\nç»å¯¹å€¼ã€æ¡ä»¶æ¦‚ç‡\nâš ï¸ é«˜\nä½¿ç”¨å—çº§å…¬å¼\n\n\n&gt;\nå¼•ç”¨å—\nå¤§äºå·ã€ç®­å¤´\nâš ï¸ ä¸­\nä½¿ç”¨å—çº§å…¬å¼æˆ– \\gt\n\n\n&lt;\nHTMLæ ‡ç­¾\nå°äºå·\nâš ï¸ ä¸­\nä½¿ç”¨å—çº§å…¬å¼æˆ– \\lt\n\n\n*\næ–œä½“/ç²—ä½“\nä¹˜å·ã€å·ç§¯\nâš ï¸ ä½\né€šå¸¸æ— é—®é¢˜ï¼Œå¤æ‚æ—¶ç”¨å—çº§\n\n\n_\næ–œä½“/ä¸‹åˆ’çº¿\nä¸‹æ ‡\nâš ï¸ ä½\né€šå¸¸æ— é—®é¢˜\n\n\n[ ]\né“¾æ¥\nçŸ©é˜µæ‹¬å·\nâš ï¸ ä½\nåœ¨å—çº§å…¬å¼ä¸­ä½¿ç”¨\n\n\n\n\n\n\n\n\nâŒ é”™è¯¯ï¼š\nå½“ $x &gt; 0$ ä¸” $|y| &lt; 1$ æ—¶\n\nâœ… æ­£ç¡®ï¼š\nå½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼š\n\n$$\nx &gt; 0 \\quad \\text{ä¸”} \\quad |y| &lt; 1\n$$\n\n\n\nâŒ é”™è¯¯ï¼š\nå¯¹äºä»»æ„ $\\epsilon &gt; 0$ï¼Œå­˜åœ¨ $\\delta &gt; 0$ï¼Œä½¿å¾—å½“ $0 &lt; |x - x_0| &lt; \\delta$ æ—¶...\n\nâœ… æ­£ç¡®ï¼š\n$$\n\\forall \\epsilon &gt; 0, \\exists \\delta &gt; 0, \\text{ ä½¿å¾— } 0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\n\n\nâŒ é”™è¯¯ï¼š\nèŒƒæ•°å®šä¹‰ä¸º $||x|| = \\sqrt{\\sum_{i=1}^{n} |x_i|^2}$\n\nâœ… æ­£ç¡®ï¼š\nèŒƒæ•°å®šä¹‰ä¸ºï¼š\n\n$$\n\\|x\\| = \\sqrt{\\sum_{i=1}^{n} |x_i|^2}\n$$\n\n\n\n\n\nè¯¦ç»†æ–‡æ¡£ï¼šdocs/markdown-latex-guide.md\nMathJax æ–‡æ¡£ï¼šhttps://docs.mathjax.org/\nLaTeX æ•°å­¦ç¬¦å·ï¼šhttps://katex.org/docs/supported.html\n\n\n\n\n\nä¸»åŠ¨æ£€æµ‹ï¼šç”¨æˆ·è¦æ±‚æ£€æŸ¥æ–‡ç« æ—¶ï¼Œè‡ªåŠ¨æ‰«ææ‰€æœ‰å…¬å¼\næ¸…æ™°è¯Šæ–­ï¼šå‡†ç¡®æŒ‡å‡ºé—®é¢˜æ‰€åœ¨å’ŒåŸå› \næä¾›é€‰æ‹©ï¼šç»™å‡ºå¤šä¸ªä¿®å¤æ–¹æ¡ˆï¼Œè®©ç”¨æˆ·é€‰æ‹©\nå¿«é€Ÿä¿®å¤ï¼šç”¨æˆ·åŒæ„åï¼Œç›´æ¥ä½¿ç”¨ Edit å·¥å…·ä¿®æ”¹æ–‡ä»¶\næ•™è‚²æ€§ï¼šè§£é‡Šä¸ºä»€ä¹ˆè¿™æ ·ä¿®æ”¹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£\n\n\n\n\nå½“ç”¨æˆ·è°ƒç”¨æ­¤ skill æ—¶ï¼Œé¦–å…ˆè¯¢é—®ï¼š\næ¬¢è¿ä½¿ç”¨åšå®¢å†™ä½œåŠ©æ‰‹ï¼æˆ‘å¯ä»¥å¸®ä½ ï¼š\n\n1. ğŸ“ æ£€æŸ¥ç°æœ‰æ–‡ç« çš„å…¬å¼å†²çª\n2. âœï¸ åœ¨å†™ä½œæ—¶å®æ—¶æ£€æŸ¥å…¬å¼\n3. ğŸ”§ ä¿®å¤å·²å‘ç°çš„å…¬å¼é—®é¢˜\n4. ğŸ“š æŸ¥çœ‹ Markdown-LaTeX æœ€ä½³å®è·µ\n\nè¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ\n\n\n\n\nå§‹ç»ˆä¿æŒå¯¹ç”¨æˆ·å‹å¥½å’Œè€å¿ƒ\nç”¨æ¸…æ™°çš„ç¤ºä¾‹è¯´æ˜é—®é¢˜\næä¾›å…·ä½“çš„ã€å¯æ“ä½œçš„å»ºè®®\né¿å…ä½¿ç”¨è¿‡äºæŠ€æœ¯åŒ–çš„æœ¯è¯­\nä¼˜å…ˆæ¨èæœ€ç®€å•ã€æœ€å¯é çš„è§£å†³æ–¹æ¡ˆï¼ˆå—çº§å…¬å¼ï¼‰"
  },
  {
    "objectID": "blog-writing-assistant.html#æ ¸å¿ƒèŒè´£",
    "href": "blog-writing-assistant.html#æ ¸å¿ƒèŒè´£",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "è‡ªåŠ¨æ£€æµ‹ä»¥ä¸‹é—®é¢˜ï¼š\n\nç®¡é“ç¬¦ | å†²çªï¼šåœ¨è¡Œå†…å…¬å¼ä¸­ä½¿ç”¨ç»å¯¹å€¼ç¬¦å·å¯èƒ½è¢«è¯¯è®¤ä¸ºè¡¨æ ¼åˆ†éš”ç¬¦\nå¤§äº/å°äºå· &gt; &lt; å†²çªï¼šå¯èƒ½è¢«è¯¯è§£æä¸ºå¼•ç”¨å—æˆ–HTMLæ ‡ç­¾\næ˜Ÿå· * å†²çªï¼šå¯èƒ½è¢«è§£æä¸ºæ–œä½“æˆ–ç²—ä½“æ ‡è®°\nä¸‹åˆ’çº¿ _ å†²çªï¼šå¯èƒ½è¢«è§£æä¸ºæ–œä½“æˆ–ä¸‹æ ‡\nåŒä¸€è¡Œå¤šä¸ªè¡Œå†…å…¬å¼ï¼šç‰¹åˆ«æ˜¯åŒ…å«ç‰¹æ®Šå­—ç¬¦æ—¶\n\n\n\n\nå½“å‘ç°é—®é¢˜æ—¶ï¼Œç«‹å³æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š\né—®é¢˜è¯Šæ–­ï¼š - æŒ‡å‡ºå…·ä½“å“ªè¡Œã€å“ªä¸ªå…¬å¼æœ‰é—®é¢˜ - è§£é‡Šä¸ºä»€ä¹ˆä¼šå†²çª - è¯„ä¼°å†²çªçš„ä¸¥é‡æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰\nä¿®å¤æ–¹æ¡ˆï¼š - æ¨èæ–¹æ¡ˆï¼ˆé€šå¸¸æ˜¯æ”¹ä¸ºå—çº§å…¬å¼ï¼‰ - æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ä½¿ç”¨ LaTeX æ›¿ä»£ç¬¦å·ï¼‰ - ä¿®æ”¹åçš„å®Œæ•´ä»£ç ç¤ºä¾‹\n\n\n\næ ¹æ®å…¬å¼å¤æ‚åº¦ç»™å‡ºå»ºè®®ï¼š\n\n\n\nåœºæ™¯\nå»ºè®®\n\n\n\n\nç®€å•å˜é‡/å¸¸æ•° (å¦‚ $x$, $\\pi$)\nâœ… è¡Œå†…å…¬å¼ $...$\n\n\nç®€å•è¡¨è¾¾å¼ï¼Œæ— ç‰¹æ®Šå­—ç¬¦ (å¦‚ $E = mc^2$)\nâœ… è¡Œå†…å…¬å¼ $...$\n\n\nåŒ…å« \\| æˆ– &gt; çš„å…¬å¼\nâš ï¸ æ”¹ç”¨å—çº§å…¬å¼ $$...$$\n\n\nå¤æ‚è¡¨è¾¾å¼ã€çŸ©é˜µã€ç§¯åˆ†\nâš ï¸ ä½¿ç”¨å—çº§å…¬å¼ $$...$$\n\n\nå®šä¹‰ã€å®šç†ã€è¯æ˜\nâš ï¸ ä½¿ç”¨å—çº§å…¬å¼ $$...$$\n\n\nä¸€è¡Œä¸­å¤šä¸ªå…¬å¼ç‰‡æ®µ\nâš ï¸ è€ƒè™‘é‡æ„ä¸ºå—çº§å…¬å¼"
  },
  {
    "objectID": "blog-writing-assistant.html#å·¥ä½œæµç¨‹",
    "href": "blog-writing-assistant.html#å·¥ä½œæµç¨‹",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "è¯»å–æ–‡ç« å†…å®¹\næ‰«ææ‰€æœ‰å…¬å¼ï¼ˆè¡Œå†… $...$ å’Œå—çº§ $$...$$ï¼‰\næ£€æµ‹æ½œåœ¨å†²çª\nç”Ÿæˆæ£€æŸ¥æŠ¥å‘Šï¼š\n## ğŸ“Š å…¬å¼æ£€æŸ¥æŠ¥å‘Š\n\n### âœ… æ— é—®é¢˜çš„å…¬å¼\n- ç¬¬10è¡Œ: `$x$` - ç®€å•å˜é‡ï¼Œæ­£å¸¸\n- ç¬¬15è¡Œ: `$E = mc^2$` - æ— ç‰¹æ®Šå­—ç¬¦ï¼Œæ­£å¸¸\n\n### âš ï¸ éœ€è¦æ³¨æ„çš„å…¬å¼\n- ç¬¬25è¡Œ: `$|x - x_0| &lt; \\delta$`\n  - é—®é¢˜ï¼šåŒ…å«ç®¡é“ç¬¦ `|`ï¼Œå¯èƒ½ä¸è¡¨æ ¼è¯­æ³•å†²çª\n  - ä¸¥é‡æ€§ï¼šé«˜\n  - å»ºè®®ï¼šæ”¹ä¸ºå—çº§å…¬å¼\n\n### âŒ æœ‰é—®é¢˜çš„å…¬å¼\n- ç¬¬40è¡Œ: `å¯¹äºä»»æ„ $\\epsilon &gt; 0$ï¼Œå­˜åœ¨ $\\delta &gt; 0$ï¼Œä½¿å¾—å½“ $0 &lt; |x| &lt; 1$ æ—¶...`\n  - é—®é¢˜ï¼šä¸€è¡Œä¸­å¤šä¸ªå…¬å¼ + åŒ…å« `&gt;` å’Œ `|`\n  - ä¸¥é‡æ€§ï¼šé«˜\n  - å»ºè®®ï¼šå®Œå…¨é‡å†™ä¸ºå—çº§å…¬å¼\næä¾›ä¿®å¤ä»£ç \n\n\n\n\nç›´æ¥æä¾›ä¿®æ”¹åçš„ä»£ç ï¼Œä½¿ç”¨ Edit å·¥å…·æ›´æ–°æ–‡ä»¶ã€‚"
  },
  {
    "objectID": "blog-writing-assistant.html#ç¤ºä¾‹äº¤äº’",
    "href": "blog-writing-assistant.html#ç¤ºä¾‹äº¤äº’",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "ç”¨æˆ·ï¼š æ£€æŸ¥æˆ‘çš„æ–‡ç«  _posts/2025-11-08-math-post.md\nä½ çš„å›åº”ï¼š\nå‘ç°é—®é¢˜ï¼šç¬¬21è¡Œçš„å…¬å¼åŒ…å«ç»å¯¹å€¼ç¬¦å· |\n\nåŸä»£ç ï¼š\nå½“ $0 &lt; |x - x_0| &lt; \\delta$ æ—¶ï¼Œæœ‰ $|f(x) - L| &lt; \\epsilon$\n\né—®é¢˜ï¼šMarkdown å¯èƒ½å°† | è¯¯è®¤ä¸ºè¡¨æ ¼åˆ†éš”ç¬¦\n\nå»ºè®®ä¿®å¤ï¼š\nå½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼š\n\n$$\n0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\nè¦æˆ‘å¸®ä½ ä¿®å¤å—ï¼Ÿ\n\n\n\nç”¨æˆ·ï¼š è¿™ä¸ªå…¬å¼ä¸ºä»€ä¹ˆæ¸²æŸ“ä¸å‡ºæ¥ï¼Ÿ\nä½ çš„å›åº”ï¼š\nåˆ†æï¼šè¿™ä¸€è¡ŒåŒ…å«4ä¸ªè¡Œå†…å…¬å¼ç‰‡æ®µï¼Œä¸”åŒ…å«ç‰¹æ®Šå­—ç¬¦ &gt; å’Œ |\n\nå»ºè®®æ”¹ä¸ºæ ‡å‡†æ•°å­¦ç¬¦å·çš„å—çº§å…¬å¼ï¼š\n\n$$\n\\forall \\epsilon &gt; 0, \\exists \\delta &gt; 0, \\text{ ä½¿å¾— } 0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\nè¿™æ ·ï¼š\nâœ… é¿å… Markdown è§£æå†²çª\nâœ… ä½¿ç”¨ä¸“ä¸šæ•°å­¦ç¬¦å·ï¼ˆâˆ€ âˆƒ âŸ¹ï¼‰\nâœ… å…¬å¼æ›´æ¸…æ™°æ˜“è¯»"
  },
  {
    "objectID": "blog-writing-assistant.html#å¿«é€Ÿæ£€æŸ¥æ¸…å•",
    "href": "blog-writing-assistant.html#å¿«é€Ÿæ£€æŸ¥æ¸…å•",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "åœ¨å¸®åŠ©ç”¨æˆ·å‘å¸ƒå‰ï¼Œç¡®è®¤ï¼š\n\næ–‡ç«  front matter åŒ…å« math: true\næ‰€æœ‰åŒ…å« | çš„å…¬å¼ä½¿ç”¨å—çº§æ ¼å¼\næ‰€æœ‰åŒ…å« &gt; æˆ– &lt; çš„å…¬å¼æ£€æŸ¥è¿‡\næ²¡æœ‰ä¸€è¡Œä¸­å‡ºç° 3+ ä¸ªè¡Œå†…å…¬å¼\nå¤æ‚å®šä¹‰/å®šç†ä½¿ç”¨å—çº§å…¬å¼\nçŸ©é˜µã€ç§¯åˆ†ã€æ±‚å’Œä½¿ç”¨å—çº§å…¬å¼"
  },
  {
    "objectID": "blog-writing-assistant.html#å¸¸è§å†²çªå­—ç¬¦é€ŸæŸ¥è¡¨",
    "href": "blog-writing-assistant.html#å¸¸è§å†²çªå­—ç¬¦é€ŸæŸ¥è¡¨",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "å­—ç¬¦\nMarkdown å«ä¹‰\nLaTeX ç”¨é€”\nå†²çªé£é™©\nå»ºè®®\n\n\n\n\n\\|\nè¡¨æ ¼åˆ†éš”ç¬¦\nç»å¯¹å€¼ã€æ¡ä»¶æ¦‚ç‡\nâš ï¸ é«˜\nä½¿ç”¨å—çº§å…¬å¼\n\n\n&gt;\nå¼•ç”¨å—\nå¤§äºå·ã€ç®­å¤´\nâš ï¸ ä¸­\nä½¿ç”¨å—çº§å…¬å¼æˆ– \\gt\n\n\n&lt;\nHTMLæ ‡ç­¾\nå°äºå·\nâš ï¸ ä¸­\nä½¿ç”¨å—çº§å…¬å¼æˆ– \\lt\n\n\n*\næ–œä½“/ç²—ä½“\nä¹˜å·ã€å·ç§¯\nâš ï¸ ä½\né€šå¸¸æ— é—®é¢˜ï¼Œå¤æ‚æ—¶ç”¨å—çº§\n\n\n_\næ–œä½“/ä¸‹åˆ’çº¿\nä¸‹æ ‡\nâš ï¸ ä½\né€šå¸¸æ— é—®é¢˜\n\n\n[ ]\né“¾æ¥\nçŸ©é˜µæ‹¬å·\nâš ï¸ ä½\nåœ¨å—çº§å…¬å¼ä¸­ä½¿ç”¨"
  },
  {
    "objectID": "blog-writing-assistant.html#æ ‡å‡†ä¿®å¤æ¨¡æ¿",
    "href": "blog-writing-assistant.html#æ ‡å‡†ä¿®å¤æ¨¡æ¿",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "âŒ é”™è¯¯ï¼š\nå½“ $x &gt; 0$ ä¸” $|y| &lt; 1$ æ—¶\n\nâœ… æ­£ç¡®ï¼š\nå½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼š\n\n$$\nx &gt; 0 \\quad \\text{ä¸”} \\quad |y| &lt; 1\n$$\n\n\n\nâŒ é”™è¯¯ï¼š\nå¯¹äºä»»æ„ $\\epsilon &gt; 0$ï¼Œå­˜åœ¨ $\\delta &gt; 0$ï¼Œä½¿å¾—å½“ $0 &lt; |x - x_0| &lt; \\delta$ æ—¶...\n\nâœ… æ­£ç¡®ï¼š\n$$\n\\forall \\epsilon &gt; 0, \\exists \\delta &gt; 0, \\text{ ä½¿å¾— } 0 &lt; |x - x_0| &lt; \\delta \\implies |f(x) - L| &lt; \\epsilon\n$$\n\n\n\nâŒ é”™è¯¯ï¼š\nèŒƒæ•°å®šä¹‰ä¸º $||x|| = \\sqrt{\\sum_{i=1}^{n} |x_i|^2}$\n\nâœ… æ­£ç¡®ï¼š\nèŒƒæ•°å®šä¹‰ä¸ºï¼š\n\n$$\n\\|x\\| = \\sqrt{\\sum_{i=1}^{n} |x_i|^2}\n$$"
  },
  {
    "objectID": "blog-writing-assistant.html#å‚è€ƒèµ„æº",
    "href": "blog-writing-assistant.html#å‚è€ƒèµ„æº",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "è¯¦ç»†æ–‡æ¡£ï¼šdocs/markdown-latex-guide.md\nMathJax æ–‡æ¡£ï¼šhttps://docs.mathjax.org/\nLaTeX æ•°å­¦ç¬¦å·ï¼šhttps://katex.org/docs/supported.html"
  },
  {
    "objectID": "blog-writing-assistant.html#äº¤äº’åŸåˆ™",
    "href": "blog-writing-assistant.html#äº¤äº’åŸåˆ™",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "ä¸»åŠ¨æ£€æµ‹ï¼šç”¨æˆ·è¦æ±‚æ£€æŸ¥æ–‡ç« æ—¶ï¼Œè‡ªåŠ¨æ‰«ææ‰€æœ‰å…¬å¼\næ¸…æ™°è¯Šæ–­ï¼šå‡†ç¡®æŒ‡å‡ºé—®é¢˜æ‰€åœ¨å’ŒåŸå› \næä¾›é€‰æ‹©ï¼šç»™å‡ºå¤šä¸ªä¿®å¤æ–¹æ¡ˆï¼Œè®©ç”¨æˆ·é€‰æ‹©\nå¿«é€Ÿä¿®å¤ï¼šç”¨æˆ·åŒæ„åï¼Œç›´æ¥ä½¿ç”¨ Edit å·¥å…·ä¿®æ”¹æ–‡ä»¶\næ•™è‚²æ€§ï¼šè§£é‡Šä¸ºä»€ä¹ˆè¿™æ ·ä¿®æ”¹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£"
  },
  {
    "objectID": "blog-writing-assistant.html#å¯åŠ¨æ¨¡å¼",
    "href": "blog-writing-assistant.html#å¯åŠ¨æ¨¡å¼",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "å½“ç”¨æˆ·è°ƒç”¨æ­¤ skill æ—¶ï¼Œé¦–å…ˆè¯¢é—®ï¼š\næ¬¢è¿ä½¿ç”¨åšå®¢å†™ä½œåŠ©æ‰‹ï¼æˆ‘å¯ä»¥å¸®ä½ ï¼š\n\n1. ğŸ“ æ£€æŸ¥ç°æœ‰æ–‡ç« çš„å…¬å¼å†²çª\n2. âœï¸ åœ¨å†™ä½œæ—¶å®æ—¶æ£€æŸ¥å…¬å¼\n3. ğŸ”§ ä¿®å¤å·²å‘ç°çš„å…¬å¼é—®é¢˜\n4. ğŸ“š æŸ¥çœ‹ Markdown-LaTeX æœ€ä½³å®è·µ\n\nè¯·å‘Šè¯‰æˆ‘ä½ éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
  },
  {
    "objectID": "blog-writing-assistant.html#æ³¨æ„äº‹é¡¹",
    "href": "blog-writing-assistant.html#æ³¨æ„äº‹é¡¹",
    "title": "1 Blog Writing Assistant - Markdown & LaTeX å…¬å¼åŠ©æ‰‹",
    "section": "",
    "text": "å§‹ç»ˆä¿æŒå¯¹ç”¨æˆ·å‹å¥½å’Œè€å¿ƒ\nç”¨æ¸…æ™°çš„ç¤ºä¾‹è¯´æ˜é—®é¢˜\næä¾›å…·ä½“çš„ã€å¯æ“ä½œçš„å»ºè®®\né¿å…ä½¿ç”¨è¿‡äºæŠ€æœ¯åŒ–çš„æœ¯è¯­\nä¼˜å…ˆæ¨èæœ€ç®€å•ã€æœ€å¯é çš„è§£å†³æ–¹æ¡ˆï¼ˆå—çº§å…¬å¼ï¼‰"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Browse all posts below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Notes â€” Gradient Descent and Convexity\n\n\nShort notes with LaTeX equations for gradient descent, convexity, and ridge regression.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference Primer â€” Betaâ€“Binomial\n\n\nLaTeX demo with conjugacy, posterior, and predictive for Bernoulli data.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code Demo\n\n\nA sample technical post demonstrating code blocks, math, and figures.\n\n\n\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHello Quarto\n\n\nA short hello-world style post to verify site structure and formatting.\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html",
    "href": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html",
    "title": "ä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto",
    "section": "",
    "text": "è¿™æ˜¯ä¸­æ–‡ç¤ºä¾‹æ–‡ç« ï¼Œç”¨æ¥æµ‹è¯•åœ¨ posts_ch/ ä¸‹çš„ä¸­æ–‡æ–‡ç« åˆ—è¡¨ã€æ ‡ç­¾ä»¥åŠæ•°å­¦å…¬å¼/ä»£ç é«˜äº®ã€‚"
  },
  {
    "objectID": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#ä»£ç ç¤ºä¾‹",
    "href": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#ä»£ç ç¤ºä¾‹",
    "title": "ä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto",
    "section": "1 ä»£ç ç¤ºä¾‹",
    "text": "1 ä»£ç ç¤ºä¾‹\ndef add(a, b):\n    return a + b\n\nprint(add(2, 3))"
  },
  {
    "objectID": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#è¡Œé—´å…¬å¼",
    "href": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#è¡Œé—´å…¬å¼",
    "title": "ä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto",
    "section": "2 è¡Œé—´å…¬å¼",
    "text": "2 è¡Œé—´å…¬å¼\n\\[\n\\mathcal{L}(\\theta)\n= -\\sum_i \\log p(y_i \\mid x_i, \\theta)\n\\]"
  },
  {
    "objectID": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#å°ç»“",
    "href": "posts_ch/ä½ å¥½-å¼€å§‹ä½¿ç”¨.html#å°ç»“",
    "title": "ä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto",
    "section": "3 å°ç»“",
    "text": "3 å°ç»“\nä¸­æ–‡æ–‡ç« æ”¾åœ¨ posts_ch/ï¼›è‹±æ–‡æ–‡ç« æ”¾åœ¨ posts_en/ã€‚å…¶å®ƒé¡µé¢ï¼ˆé¦–é¡µã€å…³äºã€æ ‡ç­¾ï¼‰ç»Ÿä¸€ä¿æŒè‹±æ–‡ã€‚"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a placeholder About page.\nI write about AI/ML, Data Science, Physics, and Quant topics â€” mixing practical engineering notes with research-oriented drafts. The site is built with Quarto and styled for comfortable reading with a dark theme.\nIf you find something useful or spot an error, feel free to reach out or open an issue once this site is on GitHub."
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html",
    "href": "posts_en/diffusion-models-intro.html",
    "title": "Introduction to Diffusion Models",
    "section": "",
    "text": "Diffusion models have emerged as powerful generative models, achieving state-of-the-art results in image synthesis, audio generation, and beyond. This post introduces the core concepts and mathematical framework."
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html#forward-diffusion-process",
    "href": "posts_en/diffusion-models-intro.html#forward-diffusion-process",
    "title": "Introduction to Diffusion Models",
    "section": "1 Forward Diffusion Process",
    "text": "1 Forward Diffusion Process\nThe forward process gradually adds Gaussian noise to data \\(\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)\\) over \\(T\\) timesteps:\n\\[\nq(\\mathbf{x}_t \\mid \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1-\\beta_t}\\,\\mathbf{x}_{t-1}, \\beta_t \\mathbf{I}),\n\\]\nwhere \\(\\{\\beta_t\\}_{t=1}^T\\) is a variance schedule. Using the reparameterization \\(\\alpha_t = 1 - \\beta_t\\) and \\(\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s\\), we can sample directly at any timestep:\n\\[\nq(\\mathbf{x}_t \\mid \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0, (1-\\bar{\\alpha}_t)\\mathbf{I}).\n\\]\nThis means \\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\boldsymbol{\\epsilon}\\), where \\(\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\)."
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html#reverse-denoising-process",
    "href": "posts_en/diffusion-models-intro.html#reverse-denoising-process",
    "title": "Introduction to Diffusion Models",
    "section": "2 Reverse Denoising Process",
    "text": "2 Reverse Denoising Process\nThe reverse process learns to denoise, starting from \\(\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\):\n\\[\np_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)).\n\\]\nThe joint distribution factorizes as:\n\\[\np_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t).\n\\]"
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html#training-objective",
    "href": "posts_en/diffusion-models-intro.html#training-objective",
    "title": "Introduction to Diffusion Models",
    "section": "3 Training Objective",
    "text": "3 Training Objective\nThe model is trained by maximizing the variational lower bound (ELBO):\n\\[\n\\mathcal{L} = \\mathbb{E}_q \\left[ -\\log p_\\theta(\\mathbf{x}_0 \\mid \\mathbf{x}_1) + \\sum_{t=2}^T D_{\\text{KL}}(q(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_t,\\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_t)) \\right].\n\\]\nIn practice, a simplified objective predicts the noise \\(\\boldsymbol{\\epsilon}\\):\n\\[\n\\mathcal{L}_{\\text{simple}} = \\mathbb{E}_{t, \\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\left[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\|^2 \\right],\n\\]\nwhere \\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\boldsymbol{\\epsilon}\\)."
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html#sampling",
    "href": "posts_en/diffusion-models-intro.html#sampling",
    "title": "Introduction to Diffusion Models",
    "section": "4 Sampling",
    "text": "4 Sampling\nTo generate new samples, we iterate the reverse process:\n\\[\n\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right) + \\sigma_t \\mathbf{z},\n\\]\nwhere \\(\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) and \\(\\sigma_t\\) controls stochasticity."
  },
  {
    "objectID": "posts_en/diffusion-models-intro.html#key-insights",
    "href": "posts_en/diffusion-models-intro.html#key-insights",
    "title": "Introduction to Diffusion Models",
    "section": "5 Key Insights",
    "text": "5 Key Insights\n\nGradual denoising: The model learns to reverse a slow noise corruption process.\nScore matching: The noise prediction \\(\\boldsymbol{\\epsilon}_\\theta\\) is related to the score function \\(\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})\\).\nFlexibility: Diffusion models support conditional generation, inpainting, and other downstream tasks.\n\nDiffusion models represent a principled approach to generative modeling with strong theoretical foundations and impressive empirical performance."
  },
  {
    "objectID": "posts_en/hello-quarto.html",
    "href": "posts_en/hello-quarto.html",
    "title": "Hello Quarto",
    "section": "",
    "text": "Welcome! This is a minimal post to confirm that listings, styling, and navigation work as expected.\nSome inline code like print(\"hello\") should be easy to read in dark mode.\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\nprint(greet(\"Quarto\"))\nThatâ€™s all for now â€” more technical posts coming soon."
  },
  {
    "objectID": "posts/bayesian-inference-primer.html",
    "href": "posts/bayesian-inference-primer.html",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "",
    "text": "We briefly illustrate Bayesian inference for Bernoulli data using a Beta prior. Let observations be \\(y_1,\\dots,y_n \\in \\{0,1\\}\\) with \\(y_i \\sim \\operatorname{Bernoulli}(p)\\) and prior \\(p \\sim \\operatorname{Beta}(\\alpha,\\beta)\\)."
  },
  {
    "objectID": "posts/bayesian-inference-primer.html#bayes-rule-and-likelihood",
    "href": "posts/bayesian-inference-primer.html#bayes-rule-and-likelihood",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "1 Bayesâ€™ Rule and Likelihood",
    "text": "1 Bayesâ€™ Rule and Likelihood\nBayesâ€™ rule states \\(p(p\\mid y) \\propto p(y\\mid p)\\,p(p)\\). For \\(k = \\sum_i y_i\\), the likelihood is\n\\[\np(y\\mid p) \\;=\\; p^{k}(1-p)^{n-k}.\n\\]"
  },
  {
    "objectID": "posts/bayesian-inference-primer.html#posterior-and-moments",
    "href": "posts/bayesian-inference-primer.html#posterior-and-moments",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "2 Posterior and Moments",
    "text": "2 Posterior and Moments\nUsing Betaâ€“Binomial conjugacy, the posterior is\n\\[\np(p\\mid y) \\;=\\; \\operatorname{Beta}(\\alpha + k,\\; \\beta + n - k),\n\\]\nwith posterior mean\n\\[\n\\mathbb{E}[p\\mid y] \\;=\\; \\frac{\\alpha + k}{\\alpha + \\beta + n}.\n\\]\nThe posterior predictive for a new label \\(\\tilde y\\) has\n\\[\n\\Pr(\\tilde y = 1 \\mid y) \\;=\\; \\mathbb{E}[p\\mid y]\n\\;=\\; \\frac{\\alpha + k}{\\alpha + \\beta + n}.\n\\]"
  },
  {
    "objectID": "posts/bayesian-inference-primer.html#minimal-code-example",
    "href": "posts/bayesian-inference-primer.html#minimal-code-example",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "3 Minimal Code Example",
    "text": "3 Minimal Code Example\ndef beta_binomial_posterior(alpha, beta, k, n):\n    post_a = alpha + k\n    post_b = beta + (n - k)\n    mean = post_a / (post_a + post_b)\n    return post_a, post_b, mean\n\n# Example: prior Beta(1, 1), observations with k=7 successes out of n=10\npa, pb, pm = beta_binomial_posterior(1.0, 1.0, k=7, n=10)\nprint(f\"Posterior: Beta({pa:.1f}, {pb:.1f})  mean={pm:.3f}\")"
  },
  {
    "objectID": "posts/bayesian-inference-primer.html#summary",
    "href": "posts/bayesian-inference-primer.html#summary",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "4 Summary",
    "text": "4 Summary\nThis compact primer uses inline math (e.g., \\(k, n, \\alpha, \\beta\\)) and block equations for conjugacy. The same .qmd can be rendered to HTML and exported to PDF."
  },
  {
    "objectID": "posts/hello-quarto.html",
    "href": "posts/hello-quarto.html",
    "title": "Hello Quarto",
    "section": "",
    "text": "Welcome! This is a minimal post to confirm that listings, styling, and navigation work as expected.\nSome inline code like print(\"hello\") should be easy to read in dark mode.\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\nprint(greet(\"Quarto\"))\nThatâ€™s all for now â€” more technical posts coming soon."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tech Notes",
    "section": "",
    "text": "Notes and experiments in AI/ML/DL, mathematics, physics, and quantitative research. Expect concise derivations, reproducible code, figures, and pragmatic takeaways.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference Primer â€” Betaâ€“Binomial\n\n\nLaTeX demo with conjugacy, posterior, and predictive for Bernoulli data.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Diffusion Models\n\n\nA brief introduction to diffusion probabilistic models with key mathematical formulations.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Notes â€” Gradient Descent and Convexity\n\n\nShort notes with LaTeX equations for gradient descent, convexity, and ridge regression.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code Demo\n\n\nA sample technical post demonstrating code blocks, math, and figures.\n\n\n\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHello Quarto\n\n\nA short hello-world style post to verify site structure and formatting.\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tags.html",
    "href": "tags.html",
    "title": "Tags",
    "section": "",
    "text": "Browse by tag/category. Click a tag above to filter posts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Notes â€” Gradient Descent and Convexity\n\n\n\noptimization\n\nmath\n\n\n\nShort notes with LaTeX equations for gradient descent, convexity, and ridge regression.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Diffusion Models\n\n\n\ndeep-learning\n\ngenerative-models\n\nmath\n\n\n\nA brief introduction to diffusion probabilistic models with key mathematical formulations.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference Primer â€” Betaâ€“Binomial\n\n\n\nbayes\n\nprobability\n\nmath\n\n\n\nLaTeX demo with conjugacy, posterior, and predictive for Bernoulli data.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\næ‰©æ•£æ¨¡å‹ç®€ä»‹\n\n\n\næ·±åº¦å­¦ä¹ \n\nç”Ÿæˆæ¨¡å‹\n\næ•°å­¦\n\n\n\næ‰©æ•£æ¦‚ç‡æ¨¡å‹çš„ç®€è¦ä»‹ç»ï¼ŒåŒ…å«æ ¸å¿ƒæ•°å­¦å…¬å¼ã€‚\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto\n\n\n\ndemo\n\ntutorial\n\ncn\n\n\n\nä¸€ç¯‡ä¸­æ–‡ç¤ºä¾‹æ–‡ç« ï¼Œç”¨äºéªŒè¯ä¸­è‹±æ–‡åˆ†æ ä¸æ ‡ç­¾ã€‚\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code Demo\n\n\n\ndemo\n\nmath\n\ncode\n\n\n\nA sample technical post demonstrating code blocks, math, and figures.\n\n\n\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHello Quarto\n\n\n\nsetup\n\nintro\n\n\n\nA short hello-world style post to verify site structure and formatting.\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts_en.html",
    "href": "posts_en.html",
    "title": "Posts (EN)",
    "section": "",
    "text": "Browse English posts below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Notes â€” Gradient Descent and Convexity\n\n\n\noptimization\n\nmath\n\n\n\nShort notes with LaTeX equations for gradient descent, convexity, and ridge regression.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Diffusion Models\n\n\n\ndeep-learning\n\ngenerative-models\n\nmath\n\n\n\nA brief introduction to diffusion probabilistic models with key mathematical formulations.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference Primer â€” Betaâ€“Binomial\n\n\n\nbayes\n\nprobability\n\nmath\n\n\n\nLaTeX demo with conjugacy, posterior, and predictive for Bernoulli data.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code Demo\n\n\n\ndemo\n\nmath\n\ncode\n\n\n\nA sample technical post demonstrating code blocks, math, and figures.\n\n\n\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHello Quarto\n\n\n\nsetup\n\nintro\n\n\n\nA short hello-world style post to verify site structure and formatting.\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/optimization-notes.html",
    "href": "posts/optimization-notes.html",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "",
    "text": "These short notes demonstrate LaTeX in Quarto for optimization topics. We use inline math like \\(\\eta\\) (step size) and \\(\\nabla f(x)\\) (gradient), and block equations for key identities."
  },
  {
    "objectID": "posts/optimization-notes.html#gradient-descent",
    "href": "posts/optimization-notes.html#gradient-descent",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "1 Gradient Descent",
    "text": "1 Gradient Descent\nThe basic update with learning rate \\(\\eta &gt; 0\\) is\n\\[\n\\mathbf{x}_{t+1}\n\\;=\\; \\mathbf{x}_t\n\\;-\\; \\eta\\, \\nabla f(\\mathbf{x}_t).\n\\]\nUnder \\(L\\)-smoothness, we have the upper bound\n\\[\nf(\\mathbf{y}) \\;\\le\\; f(\\mathbf{x})\n\\;+\\; \\langle \\nabla f(\\mathbf{x}),\n\\, \\mathbf{y} - \\mathbf{x} \\rangle\n\\;+\\; \\frac{L}{2} \\lVert \\mathbf{y} - \\mathbf{x} \\rVert^2.\n\\]"
  },
  {
    "objectID": "posts/optimization-notes.html#convexity",
    "href": "posts/optimization-notes.html#convexity",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "2 Convexity",
    "text": "2 Convexity\nA function \\(f\\) is convex if for any \\(\\theta \\in [0,1]\\) and any \\(\\mathbf{x},\\mathbf{y}\\),\n\\[\nf\\bigl(\\theta \\mathbf{x} + (1-\\theta)\\mathbf{y}\\bigr)\n\\;\\le\\; \\theta f(\\mathbf{x}) + (1-\\theta) f(\\mathbf{y}).\n\\]\nFor \\(\\mu\\)-strongly convex functions, gradient descent with small enough \\(\\eta\\) converges linearly."
  },
  {
    "objectID": "posts/optimization-notes.html#ridge-regression-closed-form",
    "href": "posts/optimization-notes.html#ridge-regression-closed-form",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "3 Ridge Regression (Closed Form)",
    "text": "3 Ridge Regression (Closed Form)\nWith features \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times d}\\) and targets \\(\\mathbf{y} \\in \\mathbb{R}^{n}\\), the ridge solution is\n\\[\n\\mathbf{w}^{\\star}\n\\;=\\; (\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^\\top \\mathbf{y}.\n\\]"
  },
  {
    "objectID": "posts/optimization-notes.html#minimal-code-example",
    "href": "posts/optimization-notes.html#minimal-code-example",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "4 Minimal Code Example",
    "text": "4 Minimal Code Example\nBelow is a tiny gradient-descent loop for a 1D convex function \\(f(x) = (x-3)^2 + 1\\) with \\(\\nabla f(x) = 2(x-3)\\):\ndef f(x):\n    return (x - 3.0)**2 + 1.0\n\ndef grad_f(x):\n    return 2.0 * (x - 3.0)\n\nx, eta = 0.0, 0.1\nfor t in range(20):\n    x = x - eta * grad_f(x)\n    if t % 5 == 0:\n        print(f\"iter={t:02d}, x={x:.4f}, f(x)={f(x):.5f}\")"
  },
  {
    "objectID": "posts/optimization-notes.html#summary",
    "href": "posts/optimization-notes.html#summary",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "5 Summary",
    "text": "5 Summary\nWe used inline math (e.g., \\(\\eta\\), \\(\\nabla f\\)) and block equations to express standard optimization results, suitable for export to PDF."
  },
  {
    "objectID": "posts/math-and-code-demo.html",
    "href": "posts/math-and-code-demo.html",
    "title": "Math and Code Demo",
    "section": "",
    "text": "This is a sample technical post. It demonstrates: - syntax-highlighted code blocks - inline and block math (LaTeX/MathJax) - an illustrative figure with a caption\nYou can use the same structure for more serious technical writing and export the same .qmd to PDF."
  },
  {
    "objectID": "posts/math-and-code-demo.html#code-example",
    "href": "posts/math-and-code-demo.html#code-example",
    "title": "Math and Code Demo",
    "section": "1 Code Example",
    "text": "1 Code Example\nBelow is a small Python snippet showing a Stable Softplus implementation (for numerical stability) and a simple mean-squared-error:\nimport math\n\ndef softplus(x: float) -&gt; float:\n    # Stable softplus: log(1 + exp(x))\n    if x &gt; 20:\n        return x  # exp(x) would overflow; asymptotically ~ x\n    return math.log1p(math.exp(x))\n\ndef mse(y_true, y_pred):\n    n = len(y_true)\n    return sum((a - b)**2 for a, b in zip(y_true, y_pred)) / n\n\nprint(softplus(0.0))\nprint(mse([1, 2, 3], [1.1, 2.2, 2.9]))"
  },
  {
    "objectID": "posts/math-and-code-demo.html#inline-math",
    "href": "posts/math-and-code-demo.html#inline-math",
    "title": "Math and Code Demo",
    "section": "2 Inline Math",
    "text": "2 Inline Math\nWe denote a modelâ€™s parameters by \\(\\theta\\) and a dataset by \\(\\mathcal{D}\\). A typical objective may minimize a loss \\(\\mathcal{L}(\\theta)\\) with gradient \\(\\nabla_\\theta \\, \\mathcal{L}(\\theta)\\)."
  },
  {
    "objectID": "posts/math-and-code-demo.html#block-math",
    "href": "posts/math-and-code-demo.html#block-math",
    "title": "Math and Code Demo",
    "section": "3 Block Math",
    "text": "3 Block Math\nFor example, the mean squared error (MSE) for targets \\(y_i\\) and predictions \\(\\hat y_i\\) is\n\\[\n\\mathcal{L}(\\theta)\n\\;=\\; \\frac{1}{N} \\sum_{i=1}^{N} \\bigl(y_i - \\hat y_i\\bigr)^2\n\\,.\n\\]\nAlternatively, a negative log-likelihood (NLL) under a Gaussian assumption (\\(\\sigma^2\\) fixed) is\n\\[\n\\mathcal{L}(\\theta)\n\\;=\\; \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} \\bigl(y_i - \\hat y_i\\bigr)^2\n\\;+\\; \\text{const}.\n\\]"
  },
  {
    "objectID": "posts/math-and-code-demo.html#figure-with-caption",
    "href": "posts/math-and-code-demo.html#figure-with-caption",
    "title": "Math and Code Demo",
    "section": "4 Figure with Caption",
    "text": "4 Figure with Caption\nHere is a placeholder image with a caption and constrained width:\n\n\n\nA demo figure with a placeholder image."
  },
  {
    "objectID": "posts/math-and-code-demo.html#summary",
    "href": "posts/math-and-code-demo.html#summary",
    "title": "Math and Code Demo",
    "section": "5 Summary",
    "text": "5 Summary\nThis post shows how to combine code, math, and figures in a single .qmd. The same source can be rendered to HTML for the blog and exported to PDF (via quarto render post.qmd --to pdf) as a chapter draft or paper section."
  },
  {
    "objectID": "posts_en/optimization-notes.html",
    "href": "posts_en/optimization-notes.html",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "",
    "text": "These short notes demonstrate LaTeX in Quarto for optimization topics. We use inline math like \\(\\eta\\) (step size) and \\(\\nabla f(x)\\) (gradient), and block equations for key identities."
  },
  {
    "objectID": "posts_en/optimization-notes.html#gradient-descent",
    "href": "posts_en/optimization-notes.html#gradient-descent",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "1 Gradient Descent",
    "text": "1 Gradient Descent\nThe basic update with learning rate \\(\\eta &gt; 0\\) is\n\\[\n\\mathbf{x}_{t+1}\n\\;=\\; \\mathbf{x}_t\n\\;-\\; \\eta\\, \\nabla f(\\mathbf{x}_t).\n\\]\nUnder \\(L\\)-smoothness, we have the upper bound\n\\[\nf(\\mathbf{y}) \\;\\le\\; f(\\mathbf{x})\n\\;+\\; \\langle \\nabla f(\\mathbf{x}),\n\\, \\mathbf{y} - \\mathbf{x} \\rangle\n\\;+\\; \\frac{L}{2} \\lVert \\mathbf{y} - \\mathbf{x} \\rVert^2.\n\\]"
  },
  {
    "objectID": "posts_en/optimization-notes.html#convexity",
    "href": "posts_en/optimization-notes.html#convexity",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "2 Convexity",
    "text": "2 Convexity\nA function \\(f\\) is convex if for any \\(\\theta \\in [0,1]\\) and any \\(\\mathbf{x},\\mathbf{y}\\),\n\\[\nf\\bigl(\\theta \\mathbf{x} + (1-\\theta)\\mathbf{y}\\bigr)\n\\;\\le\\; \\theta f(\\mathbf{x}) + (1-\\theta) f(\\mathbf{y}).\n\\]\nFor \\(\\mu\\)-strongly convex functions, gradient descent with small enough \\(\\eta\\) converges linearly."
  },
  {
    "objectID": "posts_en/optimization-notes.html#ridge-regression-closed-form",
    "href": "posts_en/optimization-notes.html#ridge-regression-closed-form",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "3 Ridge Regression (Closed Form)",
    "text": "3 Ridge Regression (Closed Form)\nWith features \\(\\mathbf{X} \\in \\mathbb{R}^{n\\times d}\\) and targets \\(\\mathbf{y} \\in \\mathbb{R}^{n}\\), the ridge solution is\n\\[\n\\mathbf{w}^{\\star}\n\\;=\\; (\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^\\top \\mathbf{y}.\n\\]"
  },
  {
    "objectID": "posts_en/optimization-notes.html#minimal-code-example",
    "href": "posts_en/optimization-notes.html#minimal-code-example",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "4 Minimal Code Example",
    "text": "4 Minimal Code Example\nBelow is a tiny gradient-descent loop for a 1D convex function \\(f(x) = (x-3)^2 + 1\\) with \\(\\nabla f(x) = 2(x-3)\\):\ndef f(x):\n    return (x - 3.0)**2 + 1.0\n\ndef grad_f(x):\n    return 2.0 * (x - 3.0)\n\nx, eta = 0.0, 0.1\nfor t in range(20):\n    x = x - eta * grad_f(x)\n    if t % 5 == 0:\n        print(f\"iter={t:02d}, x={x:.4f}, f(x)={f(x):.5f}\")"
  },
  {
    "objectID": "posts_en/optimization-notes.html#summary",
    "href": "posts_en/optimization-notes.html#summary",
    "title": "Optimization Notes â€” Gradient Descent and Convexity",
    "section": "5 Summary",
    "text": "5 Summary\nWe used inline math (e.g., \\(\\eta\\), \\(\\nabla f\\)) and block equations to express standard optimization results, suitable for export to PDF."
  },
  {
    "objectID": "posts_en/math-and-code-demo.html",
    "href": "posts_en/math-and-code-demo.html",
    "title": "Math and Code Demo",
    "section": "",
    "text": "This is a sample technical post. It demonstrates: - syntax-highlighted code blocks - inline and block math (LaTeX/MathJax) - an illustrative figure with a caption\nYou can use the same structure for more serious technical writing and export the same .qmd to PDF."
  },
  {
    "objectID": "posts_en/math-and-code-demo.html#code-example",
    "href": "posts_en/math-and-code-demo.html#code-example",
    "title": "Math and Code Demo",
    "section": "1 Code Example",
    "text": "1 Code Example\nBelow is a small Python snippet showing a Stable Softplus implementation (for numerical stability) and a simple mean-squared-error:\nimport math\n\ndef softplus(x: float) -&gt; float:\n    # Stable softplus: log(1 + exp(x))\n    if x &gt; 20:\n        return x  # exp(x) would overflow; asymptotically ~ x\n    return math.log1p(math.exp(x))\n\ndef mse(y_true, y_pred):\n    n = len(y_true)\n    return sum((a - b)**2 for a, b in zip(y_true, y_pred)) / n\n\nprint(softplus(0.0))\nprint(mse([1, 2, 3], [1.1, 2.2, 2.9]))"
  },
  {
    "objectID": "posts_en/math-and-code-demo.html#inline-math",
    "href": "posts_en/math-and-code-demo.html#inline-math",
    "title": "Math and Code Demo",
    "section": "2 Inline Math",
    "text": "2 Inline Math\nWe denote a modelâ€™s parameters by \\(\\theta\\) and a dataset by \\(\\mathcal{D}\\). A typical objective may minimize a loss \\(\\mathcal{L}(\\theta)\\) with gradient \\(\\nabla_\\theta \\, \\mathcal{L}(\\theta)\\)."
  },
  {
    "objectID": "posts_en/math-and-code-demo.html#block-math",
    "href": "posts_en/math-and-code-demo.html#block-math",
    "title": "Math and Code Demo",
    "section": "3 Block Math",
    "text": "3 Block Math\nFor example, the mean squared error (MSE) for targets \\(y_i\\) and predictions \\(\\hat y_i\\) is\n\\[\n\\mathcal{L}(\\theta)\n\\;=\\; \\frac{1}{N} \\sum_{i=1}^{N} \\bigl(y_i - \\hat y_i\\bigr)^2\n\\,.\n\\]\nAlternatively, a negative log-likelihood (NLL) under a Gaussian assumption (\\(\\sigma^2\\) fixed) is\n\\[\n\\mathcal{L}(\\theta)\n\\;=\\; \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} \\bigl(y_i - \\hat y_i\\bigr)^2\n\\;+\\; \\text{const}.\n\\]"
  },
  {
    "objectID": "posts_en/math-and-code-demo.html#figure-with-caption",
    "href": "posts_en/math-and-code-demo.html#figure-with-caption",
    "title": "Math and Code Demo",
    "section": "4 Figure with Caption",
    "text": "4 Figure with Caption\nHere is a placeholder image with a caption and constrained width:\n\n\n\nA demo figure with a placeholder image."
  },
  {
    "objectID": "posts_en/math-and-code-demo.html#summary",
    "href": "posts_en/math-and-code-demo.html#summary",
    "title": "Math and Code Demo",
    "section": "5 Summary",
    "text": "5 Summary\nThis post shows how to combine code, math, and figures in a single .qmd. The same source can be rendered to HTML for the blog and exported to PDF (via quarto render post.qmd --to pdf) as a chapter draft or paper section."
  },
  {
    "objectID": "posts_en/bayesian-inference-primer.html",
    "href": "posts_en/bayesian-inference-primer.html",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "",
    "text": "We briefly illustrate Bayesian inference for Bernoulli data using a Beta prior. Let observations be \\(y_1,\\dots,y_n \\in \\{0,1\\}\\) with \\(y_i \\sim \\operatorname{Bernoulli}(p)\\) and prior \\(p \\sim \\operatorname{Beta}(\\alpha,\\beta)\\)."
  },
  {
    "objectID": "posts_en/bayesian-inference-primer.html#bayes-rule-and-likelihood",
    "href": "posts_en/bayesian-inference-primer.html#bayes-rule-and-likelihood",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "1 Bayesâ€™ Rule and Likelihood",
    "text": "1 Bayesâ€™ Rule and Likelihood\nBayesâ€™ rule states \\(p(p\\mid y) \\propto p(y\\mid p)\\,p(p)\\). For \\(k = \\sum_i y_i\\), the likelihood is\n\\[\np(y\\mid p) \\;=\\; p^{k}(1-p)^{n-k}.\n\\]"
  },
  {
    "objectID": "posts_en/bayesian-inference-primer.html#posterior-and-moments",
    "href": "posts_en/bayesian-inference-primer.html#posterior-and-moments",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "2 Posterior and Moments",
    "text": "2 Posterior and Moments\nUsing Betaâ€“Binomial conjugacy, the posterior is\n\\[\np(p\\mid y) \\;=\\; \\operatorname{Beta}(\\alpha + k,\\; \\beta + n - k),\n\\]\nwith posterior mean\n\\[\n\\mathbb{E}[p\\mid y] \\;=\\; \\frac{\\alpha + k}{\\alpha + \\beta + n}.\n\\]\nThe posterior predictive for a new label \\(\\tilde y\\) has\n\\[\n\\Pr(\\tilde y = 1 \\mid y) \\;=\\; \\mathbb{E}[p\\mid y]\n\\;=\\; \\frac{\\alpha + k}{\\alpha + \\beta + n}.\n\\]"
  },
  {
    "objectID": "posts_en/bayesian-inference-primer.html#minimal-code-example",
    "href": "posts_en/bayesian-inference-primer.html#minimal-code-example",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "3 Minimal Code Example",
    "text": "3 Minimal Code Example\ndef beta_binomial_posterior(alpha, beta, k, n):\n    post_a = alpha + k\n    post_b = beta + (n - k)\n    mean = post_a / (post_a + post_b)\n    return post_a, post_b, mean\n\n# Example: prior Beta(1, 1), observations with k=7 successes out of n=10\npa, pb, pm = beta_binomial_posterior(1.0, 1.0, k=7, n=10)\nprint(f\"Posterior: Beta({pa:.1f}, {pb:.1f})  mean={pm:.3f}\")"
  },
  {
    "objectID": "posts_en/bayesian-inference-primer.html#summary",
    "href": "posts_en/bayesian-inference-primer.html#summary",
    "title": "Bayesian Inference Primer â€” Betaâ€“Binomial",
    "section": "4 Summary",
    "text": "4 Summary\nThis compact primer uses inline math (e.g., \\(k, n, \\alpha, \\beta\\)) and block equations for conjugacy. The same .qmd can be rendered to HTML and exported to PDF."
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "",
    "text": "æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelsï¼‰æ˜¯ä¸€ç±»å¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒåˆæˆã€éŸ³é¢‘ç”Ÿæˆç­‰é¢†åŸŸå–å¾—äº†æœ€å…ˆè¿›çš„æ•ˆæœã€‚æœ¬æ–‡ä»‹ç»å…¶æ ¸å¿ƒæ¦‚å¿µå’Œæ•°å­¦æ¡†æ¶ã€‚"
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#å‰å‘æ‰©æ•£è¿‡ç¨‹",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#å‰å‘æ‰©æ•£è¿‡ç¨‹",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "1 å‰å‘æ‰©æ•£è¿‡ç¨‹",
    "text": "1 å‰å‘æ‰©æ•£è¿‡ç¨‹\nå‰å‘è¿‡ç¨‹åœ¨ \\(T\\) ä¸ªæ—¶é—´æ­¥å†…é€æ­¥å‘æ•°æ® \\(\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)\\) æ·»åŠ é«˜æ–¯å™ªå£°ï¼š\n\\[\nq(\\mathbf{x}_t \\mid \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1-\\beta_t}\\,\\mathbf{x}_{t-1}, \\beta_t \\mathbf{I}),\n\\]\nå…¶ä¸­ \\(\\{\\beta_t\\}_{t=1}^T\\) æ˜¯æ–¹å·®è°ƒåº¦ã€‚ä»¤ \\(\\alpha_t = 1 - \\beta_t\\) å’Œ \\(\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s\\)ï¼Œå¯ä»¥ç›´æ¥åœ¨ä»»æ„æ—¶é—´æ­¥é‡‡æ ·ï¼š\n\\[\nq(\\mathbf{x}_t \\mid \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0, (1-\\bar{\\alpha}_t)\\mathbf{I}).\n\\]\nè¿™æ„å‘³ç€ \\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\boldsymbol{\\epsilon}\\)ï¼Œå…¶ä¸­ \\(\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\)ã€‚"
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#åå‘å»å™ªè¿‡ç¨‹",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#åå‘å»å™ªè¿‡ç¨‹",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "2 åå‘å»å™ªè¿‡ç¨‹",
    "text": "2 åå‘å»å™ªè¿‡ç¨‹\nåå‘è¿‡ç¨‹å­¦ä¹ å»å™ªï¼Œä» \\(\\mathbf{x}_T \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\) å¼€å§‹ï¼š\n\\[\np_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t)).\n\\]\nè”åˆåˆ†å¸ƒå¯ä»¥åˆ†è§£ä¸ºï¼š\n\\[\np_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t).\n\\]"
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#è®­ç»ƒç›®æ ‡",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#è®­ç»ƒç›®æ ‡",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "3 è®­ç»ƒç›®æ ‡",
    "text": "3 è®­ç»ƒç›®æ ‡\næ¨¡å‹é€šè¿‡æœ€å¤§åŒ–å˜åˆ†ä¸‹ç•Œï¼ˆELBOï¼‰è¿›è¡Œè®­ç»ƒï¼š\n\\[\n\\mathcal{L} = \\mathbb{E}_q \\left[ -\\log p_\\theta(\\mathbf{x}_0 \\mid \\mathbf{x}_1) + \\sum_{t=2}^T D_{\\text{KL}}(q(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_t,\\mathbf{x}_0) \\| p_\\theta(\\mathbf{x}_{t-1}\\mid\\mathbf{x}_t)) \\right].\n\\]\nå®è·µä¸­ï¼Œé‡‡ç”¨ç®€åŒ–ç›®æ ‡é¢„æµ‹å™ªå£° \\(\\boldsymbol{\\epsilon}\\)ï¼š\n\\[\n\\mathcal{L}_{\\text{simple}} = \\mathbb{E}_{t, \\mathbf{x}_0, \\boldsymbol{\\epsilon}} \\left[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\|^2 \\right],\n\\]\nå…¶ä¸­ \\(\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t}\\,\\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t}\\,\\boldsymbol{\\epsilon}\\)ã€‚"
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#é‡‡æ ·ç”Ÿæˆ",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#é‡‡æ ·ç”Ÿæˆ",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "4 é‡‡æ ·ç”Ÿæˆ",
    "text": "4 é‡‡æ ·ç”Ÿæˆ\nä¸ºç”Ÿæˆæ–°æ ·æœ¬ï¼Œè¿­ä»£æ‰§è¡Œåå‘è¿‡ç¨‹ï¼š\n\\[\n\\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right) + \\sigma_t \\mathbf{z},\n\\]\nå…¶ä¸­ \\(\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\)ï¼Œ\\(\\sigma_t\\) æ§åˆ¶éšæœºæ€§ã€‚"
  },
  {
    "objectID": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#æ ¸å¿ƒæ€æƒ³",
    "href": "posts_ch/æ‰©æ•£æ¨¡å‹ç®€ä»‹.html#æ ¸å¿ƒæ€æƒ³",
    "title": "æ‰©æ•£æ¨¡å‹ç®€ä»‹",
    "section": "5 æ ¸å¿ƒæ€æƒ³",
    "text": "5 æ ¸å¿ƒæ€æƒ³\n\næ¸è¿›å»å™ªï¼šæ¨¡å‹å­¦ä¹ é€†è½¬ç¼“æ…¢çš„å™ªå£°ç ´åè¿‡ç¨‹ã€‚\nåˆ†æ•°åŒ¹é…ï¼šå™ªå£°é¢„æµ‹ \\(\\boldsymbol{\\epsilon}_\\theta\\) ä¸åˆ†æ•°å‡½æ•° \\(\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})\\) ç›¸å…³ã€‚\nçµæ´»æ€§ï¼šæ‰©æ•£æ¨¡å‹æ”¯æŒæ¡ä»¶ç”Ÿæˆã€å›¾åƒä¿®å¤ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚\n\næ‰©æ•£æ¨¡å‹ä¸ºç”Ÿæˆå»ºæ¨¡æä¾›äº†åŸåˆ™æ€§æ–¹æ³•ï¼Œå…·æœ‰åšå®çš„ç†è®ºåŸºç¡€å’Œå‡ºè‰²çš„å®éªŒæ€§èƒ½ã€‚"
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Tech Notes",
    "section": "",
    "text": "Notes and experiments in AI/ML/DL, mathematics, physics, and quantitative research. Expect concise derivations, reproducible code, figures, and pragmatic takeaways.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference Primer â€” Betaâ€“Binomial\n\n\nLaTeX demo with conjugacy, posterior, and predictive for Bernoulli data.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Diffusion Models\n\n\nA brief introduction to diffusion probabilistic models with key mathematical formulations.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nOptimization Notes â€” Gradient Descent and Convexity\n\n\nShort notes with LaTeX equations for gradient descent, convexity, and ridge regression.\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code Demo\n\n\nA sample technical post demonstrating code blocks, math, and figures.\n\n\n\n\n\nNov 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHello Quarto\n\n\nA short hello-world style post to verify site structure and formatting.\n\n\n\n\n\nNov 11, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts_zh.html",
    "href": "posts_zh.html",
    "title": "Posts (ä¸­æ–‡)",
    "section": "",
    "text": "æµè§ˆä¸­æ–‡æ–‡ç« ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n\n\næ‰©æ•£æ¨¡å‹ç®€ä»‹\n\n\n\næ·±åº¦å­¦ä¹ \n\nç”Ÿæˆæ¨¡å‹\n\næ•°å­¦\n\n\n\næ‰©æ•£æ¦‚ç‡æ¨¡å‹çš„ç®€è¦ä»‹ç»ï¼ŒåŒ…å«æ ¸å¿ƒæ•°å­¦å…¬å¼ã€‚\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nä½ å¥½ï¼Œå¼€å§‹ä½¿ç”¨ Quarto\n\n\n\ndemo\n\ntutorial\n\ncn\n\n\n\nä¸€ç¯‡ä¸­æ–‡ç¤ºä¾‹æ–‡ç« ï¼Œç”¨äºéªŒè¯ä¸­è‹±æ–‡åˆ†æ ä¸æ ‡ç­¾ã€‚\n\n\n\n\n\nNov 13, 2025\n\n\n\n\n\nNo matching items"
  }
]