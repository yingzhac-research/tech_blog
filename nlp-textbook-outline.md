# NLP：从符号到智能的演进之路
## *A Pain-Driven History of Natural Language Processing*

> **设计理念**：以「痛点驱动」的历史视角，讲述NLP模型与算法的演进。每一次技术进步都是对上一代问题的回应。理论与工程实践并重。
>
> **读者定位**：研究生/PhD，偏向研究——强调理论基础、方法论、边界条件与开放问题

---

## 第零部分：导论

### 第0章：如何阅读NLP研究

> *写给即将开始NLP研究的你*

- 0.1 NLP论文的典型结构
  - Introduction的套路：痛点→贡献→结果预告
  - Related Work怎么读：找到positioning
  - Method怎么读：先看图，再看公式
  - Experiments怎么读：哪些是关键ablation
- 0.2 如何判断一篇论文的价值
  - 区分"增量改进"和"范式转变"
  - 警惕benchmark刷分论文
  - 看引用网络：这篇文章在学术图谱中的位置
- 0.3 如何复现论文
  - 为什么复现是最好的学习方式
  - 复现时的常见坑
  - 没有官方代码怎么办
- 0.4 本书的阅读建议
  - 核心章节 vs 可跳过章节
  - 数学基础的前置要求
  - 配套论文阅读顺序

---

## 第一部分：前深度学习时代（速览）

> *目标：建立"为什么需要深度学习"的动机，不深入技术细节*

### 第1章：语言理解的早期探索

- 1.1 符号主义的辉煌与幻灭（规则系统、专家系统）
- 1.2 统计革命：从规则到概率
- 1.3 N-gram与语言模型基础
- 1.4 序列标注：HMM → CRF 的演进
- 1.5 **核心痛点**：特征工程的诅咒
- 1.6 工程实践：传统NLP pipeline体验

### 第2章：NLP核心任务全景

> *先看清问题，再看模型如何解题*
>
> **核心论点**：理解NLP的任务版图，是理解模型演进的前提

- 2.1 **为什么需要一张任务地图？**
  - 从输入/输出模式看任务分类
- 2.2 文本分类与语义匹配
  - 情感分析（SST-2）
  - 自然语言推理（SNLI/MNLI）
  - 主题分类与其他分类任务
- 2.3 序列标注任务
  - 词性标注（POS Tagging）
  - 命名实体识别（NER，CoNLL-2003）
  - 序列标注的传统痛点
- 2.4 序列到序列任务
  - 机器翻译（WMT，BLEU/COMET）
  - 文本摘要（CNN/DailyMail，ROUGE）
  - 对话系统
  - 序列到序列的传统痛点
- 2.5 结构预测与信息抽取
  - 句法分析（依存/成分，UAS/LAS）
  - 信息抽取（关系抽取、事件抽取）
  - 共指消解
  - 结构预测的传统痛点
- 2.6 问答与阅读理解
  - 抽取式问答（SQuAD，EM/F1）
  - 生成式问答与开放域问答
  - 评测基准的演进（GLUE → SuperGLUE → LLM时代）
- 2.7 从任务专用到通用模型：一条演进主线
  - **任务-模型-评测速查表**（全书交叉参考表，12个核心任务）

### 第3章：表示学习的觉醒

- 3.1 **关键洞察**：让机器自己学习特征
- 3.2 Word2Vec：分布式语义的突破
- 3.3 GloVe与FastText：词向量的改进
- 3.4 **痛点**：静态词向量无法处理一词多义
- 3.5 工程实践：词向量训练与可视化

### 第4章：Tokenization与数据基础

> *被低估的基础设施：如何将文本切分为模型可处理的单元*
>
> **核心论点**：Tokenizer不是预处理工具，它是模型架构的隐藏维度

- 4.1 **核心问题**：什么是一个"词"？
  - 中文分词的挑战
  - 形态丰富语言（德语、土耳其语）的困境
- 4.2 词级别Tokenization的痛点
  - OOV（Out-of-Vocabulary）问题
  - 词汇表爆炸
- 4.3 字符级别的尝试
  - **痛点**：序列太长、语义碎片化
- 4.4 子词方法的崛起
  - BPE（Byte Pair Encoding）：从数据压缩到NLP
  - WordPiece：BERT的选择
  - Unigram LM：概率视角的子词分割
  - SentencePiece：语言无关的统一方案
- 4.5 Byte-level BPE
  - GPT-2的创新：彻底解决未知字符
  - **洞察**：为什么现代LLM都用byte-level？
- 4.6 **Tokenizer是模型的一部分**
  - 计算效率：同样文本，不同tokenizer序列长度差2-3倍
  - 多语言公平性：英文1 token，中文可能2-3 token
  - 数学/代码能力：数字切分直接影响算术推理
  - 安全：Prompt injection的切分边界问题
- 4.7 数据质量：清洗、去重与污染
  - **痛点**：Garbage in, garbage out
  - 数据去重的重要性（Chinchilla发现）
  - 训练数据与测试数据的污染问题
- 4.8 **开放问题**：最优tokenizer存在吗？
- 4.9 工程实践：Hugging Face Tokenizers库使用

---

## 第二部分：序列建模与注意力的萌芽

### 第5章：循环神经网络时代

- 5.1 RNN：时间维度上的权重共享
- 5.2 **痛点**：梯度消失/爆炸
- 5.3 LSTM的门控设计智慧
- 5.4 GRU：简化的探索
- 5.5 Seq2Seq：Encoder-Decoder架构
- 5.6 **痛点**：信息瓶颈——所有信息压缩到一个向量？
- 5.7 工程实践：LSTM文本分类与生成

---

## 第三部分：注意力机制的演进（重点）

> *从"辅助机制"到"核心架构"的转变*

### 第6章：注意力机制的诞生与演进

> *从信息瓶颈到动态聚焦：Bahdanau加性注意力与Luong乘性注意力的完整故事*

- 6.1 **核心洞察**：不同位置的重要性不同
- 6.2 Bahdanau Attention (2014)：加性注意力
  - 动机：Seq2Seq的信息瓶颈
  - Alignment model的设计
  - 注意力权重的可解释性
- 6.3 Luong Attention (2015)：乘性注意力
  - Dot-product vs General vs Concat
  - **洞察**：计算效率与表达能力的权衡
- 6.4 注意力变体的谱系
  - Local vs Global Attention
  - Hard vs Soft Attention
  - 可微分性的重要性
- 6.5 注意力可视化：模型在"看"什么？
- 6.6 **痛点**：注意力仍然依附于RNN，能否独立？
- 6.7 工程实践：带Attention的Seq2Seq翻译

### 第7章：Self-Attention的突破

- 7.1 **关键问题**：序列内部元素如何相互关注？
- 7.2 从Seq2Seq Attention到Self-Attention
- 7.3 Memory Networks的启示
- 7.4 **痛点**：Self-Attention丢失了位置信息
- 7.5 位置编码的各种尝试

### 第8章：Transformer——注意力即一切

- 8.1 **革命性洞察**：完全抛弃循环结构
- 8.2 Scaled Dot-Product Attention
  - 为什么要除以√d_k？（数学推导）
- 8.3 Multi-Head Attention
  - **洞察**：多个子空间捕获不同模式
  - Head数量的选择与影响
- 8.4 位置编码的设计
  - 正弦编码的数学优雅
  - 可学习位置编码
- 8.5 FFN层的角色（被低估的组件）
- 8.6 残差连接与Layer Normalization
- 8.7 Encoder vs Decoder的结构差异
- 8.8 **理论分析**：Transformer的表达能力与归纳偏置
- 8.9 工程实践：从零实现Transformer

### 第9章：高效注意力——复杂度优化

> *O(n²)的第一次反击*

- 9.1 **痛点**：O(n²)的计算复杂度
- 9.2 Sparse Attention系列
  - Longformer的滑动窗口
  - BigBird的随机+局部+全局
- 9.3 Linear Attention的尝试
  - Performer与核方法近似
  - **理论分析**：为什么Linear Attention有性能损失？
- 9.4 **边界条件**：稀疏/线性注意力的适用场景
- 9.5 工程实践：高效注意力实现对比

---

## 第四部分：预训练范式的演进（重点）

> *从词向量到基础模型的范式革命*

### 第10章：预训练思想的起源

- 10.1 迁移学习的基本思想
- 10.2 Word2Vec作为"预训练"的雏形
- 10.3 **痛点**：词向量是静态的、与下游任务脱节
- 10.4 计算机视觉的启示：ImageNet预训练

### 第11章：上下文词向量——ELMo

- 11.1 **核心洞察**：词的表示应该依赖上下文
- 11.2 双向LSTM的设计
- 11.3 特征拼接策略
- 11.4 **痛点**：双向是分离的，不是真正的融合
- 11.5 工程实践：ELMo特征提取

### 第12章：GPT——自回归预训练路线

- 12.1 **设计决策**：为什么选择Transformer Decoder？
- 12.2 因果语言建模（Causal LM）
- 12.3 模型架构与GELU激活函数
- 12.4 **从概率分布到文本：解码策略**
  - Greedy Decoding与Beam Search
  - Temperature Scaling：控制概率分布的"尖锐度"
  - Top-k Sampling (Fan et al., 2018)
  - Nucleus / Top-p Sampling (Holtzman et al., 2020)
  - Repetition Penalty与退化问题
  - **洞察**：解码策略 = 质量-多样性的权衡
- 12.5 预训练 + 微调的范式确立
- 12.6 **痛点**：单向注意力限制了理解能力？
- 12.7 工程实践：GPT微调实战

### 第13章：BERT——双向预训练路线

- 13.1 **核心洞察**：理解任务需要双向上下文
- 13.2 Masked Language Model (MLM)
  - 为什么是15%？为什么80-10-10？
- 13.3 Next Sentence Prediction (NSP)
  - **后来的争议**：NSP真的有用吗？
- 13.4 [CLS]和[SEP]的设计
- 13.5 预训练数据的选择
- 13.6 工程实践：BERT微调各类任务

### 第14章：预训练目标的演进

- 14.1 **反思**：MLM的局限性是什么？
- 14.2 XLNet：排列语言建模
  - 保持自回归 + 获得双向
- 14.3 ELECTRA：更高效的预训练
  - 替换词检测 vs 生成词
  - **洞察**：判别式预训练的优势
- 14.4 T5：统一的Text-to-Text
  - Span Corruption目标
- 14.5 对比学习在NLP中的应用
- 14.6 预训练目标设计的原则总结

### 第15章：预训练模型的工程优化

- 15.1 RoBERTa：训练策略的系统研究
  - 更多数据、更大batch、去掉NSP
- 15.2 ALBERT：参数效率
  - 跨层参数共享
  - Embedding分解
- 15.3 DistilBERT：知识蒸馏
- 15.4 **痛点**：模型越来越大，普通人用不起
- 15.5 工程实践：模型压缩与部署

### 第16章：GPT vs BERT——两条路线的分化与融合

- 16.1 理解 vs 生成：任务导向的选择
- 16.2 Encoder-only vs Decoder-only vs Encoder-Decoder
- 16.3 T5/BART：尝试统一
- 16.4 **历史转折**：为什么Decoder-only最终胜出？
- 16.5 从"预训练+微调"到"预训练+提示"

---

## 第五部分：大语言模型时代（重点）

> *规模、涌现、对齐的三重革命*

### 第17章：规模的力量——Scaling Laws

- 17.1 GPT-2：模型规模的初步探索
  - "Too dangerous to release"的争议
- 17.2 **关键发现**：Scaling Laws (Kaplan et al., 2020)
  - 损失与模型大小、数据量、计算量的关系
- 17.3 Chinchilla Scaling Laws：数据的重要性
- 17.4 **洞察**：规模带来的不只是量变
- 17.5 工程挑战预告：如何训练这么大的模型？

### 第18章：训练稳定性与数值工程

> *让百亿参数的训练不崩溃*

- 18.1 **核心问题**：为什么大模型训练容易不稳定？
- 18.2 优化器的演进
  - SGD → Momentum → Adam：自适应学习率的胜利
  - AdamW：权重衰减的正确方式
  - Adafactor：内存优化的Adam
  - 8-bit Adam / Lion：最新探索
  - **理论视角**：为什么Adam更适合Transformer？
- 18.3 学习率策略
  - Warmup的必要性（理论解释）
  - Cosine Annealing vs Linear Decay
  - 大batch训练的学习率缩放
- 18.4 混合精度训练
  - FP16 / BF16 的权衡
  - Loss Scaling技巧
  - **洞察**：为什么BF16成为LLM标配？
- 18.5 训练稳定性诊断
  - Loss spike的原因与处理
  - 梯度范数的监控
  - Checkpoint策略
- 18.6 **风险卡片**：训练稳定性问题

| 维度 | 内容 |
|------|------|
| **常见症状** | Loss spike、NaN、训练后期震荡 |
| **典型原因** | 学习率过大、数值溢出、数据异常、梯度爆炸 |
| **诊断方法** | 监控梯度范数、激活值分布、loss曲线 |
| **防护措施** | Gradient clipping、warmup、BF16、数据清洗 |

- 18.7 工程实践：训练监控与调试

### 第19章：分布式训练系统

> *从单卡到万卡*

- 19.1 **核心问题**：单张GPU装不下一个大模型
- 19.2 并行训练策略
  - 数据并行（Data Parallelism）
  - 模型并行（Tensor Parallelism）
  - 流水线并行（Pipeline Parallelism）
  - 序列并行（Sequence Parallelism）
  - **理论分析**：通信复杂度与扩展效率
- 19.3 ZeRO：内存优化的革命
  - ZeRO-1/2/3 的递进设计
  - ZeRO-Offload：利用CPU内存
  - FSDP：PyTorch的原生实现
  - **数学推导**：每阶段的内存节省
- 19.4 混合并行策略
  - 3D并行：DP + TP + PP
  - 如何选择并行策略？
- 19.5 **边界条件**：不同规模下的最优策略
- 19.6 工程实践：用DeepSpeed/FSDP训练模型

### 第20章：GPT-3与In-Context Learning

- 20.1 175B参数：规模的质变
- 20.2 **涌现现象**：Few-shot/Zero-shot能力
- 20.3 In-Context Learning的神秘性
  - 模型真的在"学习"吗？
  - **理论探索**：ICL的机制是什么？
- 20.4 Prompt Engineering的诞生
- 20.5 **痛点**：不稳定、昂贵、难以控制
- 20.6 工程实践：Prompt设计技巧

### 第21章：涌现能力与思维链推理

- 21.1 **关键发现**：能力的相变现象
- 21.2 Chain-of-Thought (CoT) Prompting
  - **洞察**：让模型"展示工作过程"
- 21.3 Zero-shot CoT："Let's think step by step"
- 21.4 Self-Consistency：多数投票
- 21.5 Tree of Thoughts与更复杂的推理结构
- 21.6 **争议**：涌现是真实的还是度量的假象？
- 21.7 **开放问题**：LLM真的在"推理"吗？
- 21.8 工程实践：CoT在实际任务中的应用

### 第22章：评测方法论——如何判断模型变好了？

> *没有评测护栏，对齐就是玄学*

- 22.1 **核心问题**：Benchmark越刷越高，模型真的越来越强吗？
- 22.2 传统评测的困境
  - 静态benchmark的泄漏与过拟合
  - BLEU/ROUGE等自动指标的局限
- 22.3 理解能力的评测演进
  - GLUE → SuperGLUE → MMLU
  - BigBench/HELM：涌现能力的探测
- 22.4 生成式评测的新范式
  - LLM-as-Judge：原理、偏差、缓解方法
  - Arena/Chatbot Arena：人类偏好的众包
  - **理论问题**：评测者偏差的形式化
- 22.5 数据污染与科学诚实
  - 训练-测试泄漏的检测方法
  - 去污染的工程实践
  - **案例分析**：著名的数据污染事件
- 22.6 可靠性评测
  - 事实性：如何衡量幻觉？
  - 一致性：同一问题不同问法
  - 拒答质量：该拒绝时是否拒绝？
  - 越狱鲁棒性
- 22.7 **开放问题**：什么是好的评测？
- 22.8 工程实践：评测pipeline搭建

### 第23章：指令微调——让模型听话

- 23.1 **痛点**：GPT-3能力强但不好用
- 23.2 FLAN：指令微调的先驱
- 23.3 指令数据的构建
  - 人工构建 vs 模型生成（Self-Instruct）
- 23.4 多任务指令微调的设计
- 23.5 Alpaca/Vicuna：开源指令微调
- 23.6 工程实践：构建指令微调数据集

### 第24章：RLHF——从能力到对齐

- 24.1 **核心问题**：模型的目标与人类意图的差距
- 24.2 InstructGPT的三阶段训练
  - SFT → Reward Model → PPO
- 24.3 奖励模型的训练
  - 人类偏好数据的收集
  - Bradley-Terry模型
- 24.4 PPO算法在LLM中的应用
  - **工程挑战**：稳定性问题
- 24.5 **风险卡片**：RLHF

| 维度 | 内容 |
|------|------|
| **主要修复** | 让模型输出更符合人类偏好（更有帮助、更少有害） |
| **典型副作用** | 奖励黑客、过度拒答、风格漂移、sycophancy |
| **工程防护** | KL约束、回归集、红队测试、参考模型 |
| **开放问题** | 人类标注者偏好 ≠ 真正的人类价值 |

- 24.6 **痛点**：RLHF太复杂、太贵
- 24.7 工程实践：用TRL库实现RLHF

### 第25章：对齐技术的演进

- 25.1 **简化尝试**：能否绕过RL？
- 25.2 DPO：Direct Preference Optimization
  - 数学推导：从RLHF到闭式解
  - **理论分析**：DPO与RLHF的等价性与差异
- 25.3 **风险卡片**：DPO

| 维度 | 内容 |
|------|------|
| **主要修复** | 简化RLHF流程，无需单独训练奖励模型 |
| **典型副作用** | 对数据质量更敏感、可能过度优化偏好 |
| **工程防护** | 高质量偏好数据、early stopping |
| **开放问题** | 离线优化 vs 在线优化的根本差异 |

- 25.4 ORPO, SimPO, KTO等变体
- 25.5 Constitutional AI：自我改进
- 25.6 对齐的本质讨论
  - **理论框架**：什么是"对齐"的形式化定义？
- 25.7 **开放问题**：Scalable oversight与超级对齐

### 第26章：长上下文与高效推理

> *从算法到系统的完整链条*
>
> **演进脉络**：O(n²)太贵 → 位置编码外推 → 系统级优化

- 26.1 **核心问题**：如何支持超长序列？
- 26.2 位置编码的演进
  - 绝对位置编码的局限
  - 相对位置编码的尝试
  - RoPE：旋转位置编码
    - 数学原理与几何直觉
    - **理论分析**：为什么RoPE有外推潜力？
  - ALiBi：位置偏置
- 26.3 长度外推技术
  - Position Interpolation (PI)
  - NTK-aware Scaling
  - YaRN：统一框架
  - **边界条件**：外推的理论极限
- 26.4 Flash Attention：硬件感知的算法
  - IO-aware的计算优化
  - **洞察**：算法与硬件的协同设计
  - Flash Attention 2/3的改进
- 26.5 KV Cache优化
  - 为什么KV Cache是推理瓶颈？
  - PagedAttention (vLLM)
  - Multi-Query/Grouped-Query Attention
- 26.6 Ring Attention与分布式长序列
- 26.7 **开放问题**：无限上下文可能吗？
- 26.8 工程实践：长上下文模型部署

### 第27章：Mixture of Experts——稀疏激活的智慧 [待写 - Window 4a]

> *Dense Transformer的第一个根本挑战：所有参数对每个token都激活，计算浪费*
>
> **演进脉络**：Dense FFN → 稀疏Expert → 动态路由 → 大规模MoE部署

- 27.1 **核心洞察**：不是每个token都需要激活所有参数
  - Dense model的浪费：一个关于烹饪的token需要激活"数学知识"的参数吗？
  - **痛点**：模型越大，推理成本线性增长
- 27.2 MoE的基本架构
  - Expert层替代FFN层
  - Gate/Router：如何决定token去哪个expert？
  - Top-k routing策略
- 27.3 MoE的演进
  - 早期探索：Jacobs et al. (1991)，Shazeer et al. (2017)
  - GShard (2020)：大规模MoE的工程化
  - Switch Transformer (2021)：Top-1 routing的简化
  - ST-MoE (2022)：稳定训练的最佳实践
- 27.4 现代MoE里程碑
  - Mixtral 8x7B (2023)：开源MoE的标杆（46.7B总参数，12.9B激活参数）
  - DeepSeek-V2/V3 (2024)：细粒度expert设计 + 共享expert策略
- 27.5 MoE的核心挑战
  - 负载均衡（Load Balancing）
  - 路由崩塌（Routing Collapse）
  - 训练不稳定性
  - 工程挑战：expert分布在不同GPU上的通信开销
- 27.6 **理论分析**：MoE的scaling特性
  - MoE的scaling law与dense model有何不同？
  - 参数量 vs 激活参数量 vs 计算量的解耦
- 27.7 工程实践：Mixtral模型的使用与部署

### 第28章：状态空间模型——序列建模的另一条路 [待写 - Window 4b]

> *Dense Transformer的第二个根本挑战：O(n²)注意力是序列建模的唯一选择吗？*
>
> **演进脉络**：线性系统 → S4 → Mamba → 混合架构

- 28.1 **核心洞察**：序列建模不一定需要attention
  - 回顾：RNN → Attention → Transformer 的演进
  - 反思：我们是否过早抛弃了recurrence？
- 28.2 从线性系统到S4
  - 连续时间状态空间模型的数学框架（dx/dt = Ax + Bu, y = Cx + Du）
  - 离散化：从连续到离散的转换
  - S4 (2021)：HiPPO初始化 + 结构化矩阵
  - S4的突破：长程依赖建模能力
- 28.3 Mamba：选择性状态空间
  - **痛点**：S4的参数是时间不变的（time-invariant），无法根据输入内容调整
  - 关键创新：选择性机制（Selection Mechanism），让B, C, Δ依赖于输入
  - 硬件感知的实现（Scan算法并行化）
  - 性能：在语言建模上匹配同规模Transformer
- 28.4 Mamba-2与理论进展
  - 状态空间对偶性（State Space Duality）
  - SSM与线性注意力的理论联系
- 28.5 混合架构的兴起
  - Jamba (AI21, 2024)：Mamba + Transformer + MoE
  - 为什么混合架构可能是最优解？
  - 不同层使用不同机制的设计理念
- 28.6 **开放问题**：Attention vs SSM，什么任务适合什么架构？
- 28.7 工程实践：Mamba模型的使用与部署

### 第29章：开源大模型的演进

- 29.1 LLaMA：开源的里程碑
- 29.2 LLaMA 2/3的改进
- 29.3 Mistral系列：效率优先
- 29.4 Qwen、DeepSeek等：多极化发展
- 29.5 开源 vs 闭源的博弈
- 29.6 工程实践：本地部署开源模型

### 第30章：高效微调技术的演进

- 30.1 **痛点**：全参数微调的不可承受之重
- 30.2 Adapter：插入式微调
- 30.3 Prefix Tuning与Prompt Tuning
- 30.4 LoRA：低秩适配
  - 数学原理：为什么低秩有效？
  - **理论分析**：LoRA的表达能力边界
- 30.5 QLoRA：量化+LoRA
- 30.6 DoRA, LoRA+等改进
- 30.7 不同方法的对比与选择
- 30.8 工程实践：PEFT库使用指南

### 第31章：推理优化

- 31.1 **痛点**：推理成本与延迟
- 31.2 量化技术
  - INT8, INT4, GPTQ, AWQ, GGUF
  - **理论分析**：量化误差的传播
- 31.3 投机解码（Speculative Decoding）
  - 数学原理：为什么能加速？
- 31.4 持续批处理
- 31.5 模型并行推理
- 31.6 **边界条件**：速度-质量权衡
- 31.7 工程实践：vLLM/TGI部署

---

## 第六部分：应用范式与前沿

### 第32章：检索增强生成（RAG）

- 32.1 **痛点**：参数化知识的局限
- 32.2 RAG架构的演进
- 32.3 检索器的选择与优化
- 32.4 Chunk策略与上下文构建
- 32.5 高级RAG技术（Query改写、Re-ranking）
- 32.6 **理论问题**：检索 vs 参数化记忆的权衡
- 32.7 工程实践：构建生产级RAG系统

### 第33章：LLM作为Agent

- 33.1 从语言模型到自主代理
- 33.2 工具使用与Function Calling
- 33.3 规划能力（ReAct, Plan-and-Execute）
- 33.4 记忆系统设计
- 33.5 多Agent协作
- 33.6 **开放问题**：Agent的可靠性与安全性
- 33.7 工程实践：Agent框架对比

### 第34章：多模态大模型

- 34.1 CLIP：对比学习连接模态
- 34.2 视觉编码器的选择
- 34.3 LLaVA：视觉指令微调
- 34.4 GPT-4V/4o的多模态能力
- 34.5 **开放问题**：统一多模态架构
- 34.6 工程实践：构建多模态应用

### 第35章：研究前沿地图

> *帮助你找到自己的研究方向*

- 35.1 **当前最活跃的研究方向**
  - Reasoning与System 2思维
  - 长上下文与无限记忆
  - 多模态统一架构
  - 高效训练与推理
  - 对齐与安全
  - World Models与具身智能
- 35.2 **每个方向的核心问题**
  - 什么问题被认为是重要的？
  - 当前的技术瓶颈在哪里？
  - 有哪些promising的方向？
- 35.3 **研究品味的培养**
  - 什么样的问题值得做？
  - 如何判断一个方向是否过度拥挤？
  - 如何找到自己的niche
- 35.4 **给PhD新生的建议**
  - 第一年应该读哪些论文？
  - 如何找到第一个研究问题？
  - 如何与导师/社区互动
- 35.5 **开放的大问题**
  - 幻觉问题与事实性
  - 推理能力的本质
  - 效率的极限在哪里？
  - AGI之路的思考

---

## 附录

### 附录A：数学基础速览

- A.1 线性代数核心概念
- A.2 概率与信息论
- A.3 优化方法基础
  - SGD与动量
  - Adam家族
  - 学习率调度

### 附录B：环境配置与框架选择

- B.1 GPU环境搭建
- B.2 PyTorch vs TensorFlow
- B.3 Hugging Face生态系统
- B.4 分布式训练框架（DeepSpeed, FSDP, Megatron）
- B.5 训练调优检查清单

### 附录C：里程碑论文阅读清单

按演进顺序排列的必读论文：

| 年份 | 论文 | 核心贡献 | 重点阅读 |
|------|------|----------|----------|
| 2013 | Word2Vec | 分布式词表示 | Skip-gram公式推导 |
| 2014 | GloVe | 全局词向量 | 矩阵分解视角 |
| 2014 | Seq2Seq | Encoder-Decoder架构 | 架构设计 |
| 2014 | Bahdanau Attention | 注意力机制 | Attention计算 |
| 2015 | Luong Attention | 注意力变体 | 三种变体对比 |
| 2016 | BPE for NMT | 子词分词 | 算法流程 |
| 2017 | Transformer | Self-Attention架构 | 全文精读 |
| 2018 | ELMo | 上下文词向量 | 双向表示 |
| 2018 | GPT | 自回归预训练 | 预训练目标 |
| 2018 | BERT | 双向预训练 | MLM设计 |
| 2019 | GPT-2 | 规模化探索 | Zero-shot实验 |
| 2019 | RoBERTa | 预训练优化 | 消融实验 |
| 2019 | XLNet | 排列语言模型 | 理论推导 |
| 2019 | T5 | Text-to-Text统一 | 实验对比 |
| 2019 | ZeRO | 内存优化训练 | 三阶段设计 |
| 2020 | GPT-3 | In-Context Learning | Few-shot实验 |
| 2020 | Scaling Laws | 规模定律 | 公式与拟合 |
| 2021 | CLIP | 视觉-语言对比学习 | 对比目标 |
| 2021 | LoRA | 高效微调 | 低秩分解 |
| 2021 | RoPE | 旋转位置编码 | 数学推导 |
| 2022 | InstructGPT | RLHF对齐 | 三阶段训练 |
| 2022 | Chain-of-Thought | 思维链推理 | Prompting技巧 |
| 2022 | Chinchilla | 数据规模定律 | 最优分配 |
| 2023 | LLaMA | 开源大模型 | 训练配置 |
| 2023 | DPO | 简化对齐 | 数学推导 |
| 2023 | Flash Attention 2 | 高效注意力 | IO分析 |

### 附录D：常见面试题与思考题

每章配套思考题，按四个层次组织：
1. **概念理解**：基本概念的掌握
2. **数学推导**：关键公式的推导能力
3. **工程实践**：实现与调试能力
4. **研究思考**：开放问题的思考

### 附录E：评测基准演进参考

| 时期 | 评测基准 | 评测目标 | 局限性 |
|------|----------|----------|--------|
| 统计时代 | BLEU, ROUGE | 翻译/摘要质量 | 与人类判断相关性低 |
| 预训练时代 | GLUE, SuperGLUE | 多任务理解能力 | 已被刷满 |
| 大模型时代 | MMLU, HELM, BigBench | 涌现能力、推理能力 | 数据污染风险 |
| 当前 | LLM-as-Judge, Arena | 生成式评测、人类偏好 | 评测者偏差 |

---

## 章节分布统计

| 部分 | 章节数 | 章节范围 | 内容 |
|------|--------|----------|------|
| 第零部分：导论 | 1章 | Ch0 | 如何阅读NLP研究 |
| 第一部分：前深度学习 | 4章 | Ch1-Ch4 | 历史 + 任务全景 + 表示学习 + Tokenization |
| 第二部分：序列建模 | 1章 | Ch5 | RNN/LSTM |
| 第三部分：注意力机制 | 4章 | Ch6-Ch9 | 注意力演进（重点） |
| 第四部分：预训练范式 | 7章 | Ch10-Ch16 | 预训练演进（重点） |
| 第五部分：大语言模型 | 15章 | Ch17-Ch31 | LLM时代（重点，MoE+SSM各独立一章） |
| 第六部分：应用与前沿 | 4章 | Ch32-Ch35 | 实践应用 + 研究前沿 |
| **总计** | **36章** | Ch0-Ch35 | |

---

## 核心设计原则

1. **痛点驱动**：每章都有明确的"上一代方法的局限性"作为引入动机
2. **演进脉络清晰**：
   - Tokenization：词级别 → 字符级别 → 子词（BPE/WordPiece）→ Byte-level
   - 注意力：Additive → Multiplicative → Self → Multi-Head → Efficient
   - 预训练：Word2Vec → ELMo → GPT/BERT → 目标改进 → 规模化
   - 大模型：Scaling Laws → 大规模训练 → ICL → 指令微调 → RLHF → DPO
   - 训练系统：单卡 → 数据并行 → 模型并行 → ZeRO → 混合并行
   - 长上下文：位置编码 → 外推技术 → Flash Attention → KV Cache优化
3. **理论与工程并重**：关键章节都有工程实践部分
4. **研究者导向**：每章包含理论分析、边界条件、开放问题
5. **详略得当**：早期内容作为背景，核心技术深入展开

---

## v3.0 更新说明

### 新增/重组章节

| 章节 | 变化 | 理由 |
|------|------|------|
| **第0章** | 新增 | 研究方法论导论，帮助PhD读者学习"如何做研究" |
| **第4章（原第3章）** | 强化 | 增加"Tokenizer是模型一部分"的核心论点 |
| **第18-19章** | 拆分 | 原第18章内容过密，拆为"数值稳定性"和"分布式训练" |
| **第22章** | 新增 | 评测方法论提到主线，为对齐章节做铺垫 |
| **第24-25章** | 增加风险卡片 | 对齐技术的失败模式显式化 |
| **第26章** | 收束 | 长上下文相关内容（位置编码、外推、Flash Attention、KV Cache）合并 |
| **第34章（原第33章）** | 扩展 | 从"开放问题"扩展为"研究前沿地图" |

### 研究者定位的体现

- 每章增加 **理论分析** 小节
- 每章增加 **边界条件/失效条件** 讨论
- 每章增加 **开放研究问题**
- 延伸阅读以论文为核心，标注"重点阅读"部分
- 对齐章节配套 **风险卡片**

---

*文档更新时间：2026-01-27*
*版本：v3.3（v3.2基础上拆分MoE/SSM为独立两章）*

### v3.1 重构变化（Window 1）

| 变化 | 说明 |
|------|------|
| **合并 Ch5+Ch6** | 原"注意力机制的诞生"和"注意力变体演进"合并为新Ch6"注意力机制的诞生与演进" |
| **新增 Ch2 占位** | "NLP核心任务全景"大纲占位 |
| **新增 Ch27 占位** | "超越Dense Transformer: SSM/MoE"大纲占位 |
| **章节重编号** | 原Ch2→Ch3, Ch3→Ch4, Ch4→Ch5; 原Ch27-Ch33→Ch28-Ch34 |
| **总章数** | 34→35 |

### v3.2 重构变化（Window 2 + Window 3）

| 变化 | 说明 |
|------|------|
| **Ch12 扩充解码策略** | 新增"从概率分布到文本：解码策略" section（Greedy, Beam Search, Temperature, Top-k, Top-p, Repetition Penalty） |
| **Ch2 完成写作** | "NLP核心任务全景"全文完成，更新大纲结构匹配实际内容 |
| **Ch1/Ch3 衔接更新** | Ch1 结尾→Ch2 预告，Ch3 开头→回指 Ch1+Ch2 |

### v3.3 重构变化（MoE/SSM 拆分）

| 变化 | 说明 |
|------|------|
| **Ch27 拆分为两章** | 原"超越Dense Transformer"拆为 Ch27（MoE：稀疏激活）和 Ch28（SSM/Mamba：状态空间模型） |
| **Ch28-Ch34 重编号** | 全部 +1 → Ch29-Ch35 |
| **总章数** | 35→36 |
